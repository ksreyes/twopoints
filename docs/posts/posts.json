[
  {
    "path": "posts/2022-12-21-avatar/",
    "title": "Somehow, Avatar has returned",
    "description": "The highest grossing movie of all time got to the top gradually rather than all at once",
    "author": [],
    "date": "2022-12-21",
    "categories": [],
    "contents": "\r\nIn 2009, I watched James Cameron’s Avatar and thought, wait a minute, this is just Atlantis: The Lost Empire but with blue people. Then I didn’t think about Avatar again for the next 13 years.\r\nLast week, Avatar: The Way of Water was released, the second in what will now be a five-film, billion-dollar epic. What! In a way, this makes perfect sense: Avatar is somehow still the highest grossing movie of all time. Someone must’ve wanted this, and if you were that someone, then good for you! Your 13-year wait is over, good God.\r\nBut I still find it baffling that Avatar has made more money than, say, Avengers: Endgame, despite a far more subdued cultural presence. How did it do this? And can James Cameron pull it off again with Way of Water?\r\nIn this post, I visualize the box office trajectories of Avatar, Endgame, and two other blockbusters, Star Wars: The Force Awakens and Spider-Man: No Way Home, to see if anything sets Avatar apart. I add the receipts so far of Way of Water to check if it is on track to repeat its predecessor’s success. And for additional context, I’m also including the would-be blockbuster Batman v Superman, which started strong but quickly fizzled out.\r\nThe data was scraped from BoxOfficeMojo.com using the rvest package. There was unfortunately no daily data for worldwide box office receipts so I confined myself to daily U.S. receipts.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(rvest)\r\nlibrary(magrittr)\r\n\r\nfilms <- c(\"2691925505\",   # Star Wars: The Force Awakens\r\n           \"3059975681\",   # Avengers: Endgame\r\n           \"2869659137\",   # Spider-Man: No Way Home\r\n           \"2238875137\",   # Batman v Superman\r\n           \"876971521\",    # Avatar \r\n           \"3372254721\")   # Avatar: The Way of Water\r\n\r\nurls <- paste0(\"https://www.boxofficemojo.com/release/rl\", films)\r\n\r\nnames(urls) <- c(\"Star Wars: The Force Awakens\", \r\n                 \"Avengers: Endgame\", \r\n                 \"Spider-Man: No Way Home\", \r\n                 \"Batman v Superman\",\r\n                 \"Avatar\",\r\n                 \"Avatar: The Way of Water\")\r\n\r\ndf <- tibble(title = NULL, day = NULL, todate = NULL)\r\n\r\nfor (i in 1:length(urls)) {\r\n  \r\n  df_i <- read_html(urls[i]) %>%\r\n    html_nodes(\"table\") %>%\r\n    extract2(1) %>%\r\n    html_table() %>%\r\n    mutate(title = names(urls)[i],\r\n           todate = gsub(\"[\\\\$,]\", \"\", `To Date`) %>% as.numeric()) %>%\r\n    select(title, day = Day, todate)\r\n  \r\n  df <- bind_rows(df, df_i)\r\n}\r\n\r\ndf <- df %>% mutate(title = factor(title, levels = names(urls)))\r\n\r\n\r\nThe following shows cumulative receipts for the first 90 days of each film’s original theatrical run:\r\n\r\n\r\nShow code\r\n\r\nggplot(df %>% filter(day < 91), \r\n       aes(x = day, y = todate / 1000000, group = title, color = title)) +\r\n  geom_line(linewidth = 1.1) +\r\n  \r\n  # Labels\r\n  labs(title = \"The way of Avatar I\",\r\n       subtitle = \"Cumulative U.S. box office receipts\") +\r\n  scale_x_continuous(name = \"Days since release\",\r\n                     breaks = c(0, 30, 60, 90)) +\r\n  scale_y_continuous(breaks = seq(0, 900, 300),\r\n                     labels = c(\"\", 300, 600, \"$900 mn\")) +\r\n  \r\n  # Legend\r\n  scale_color_manual(values = hcl.colors(n = 6, palette = \"Spectral\")) +\r\n  guides(color = guide_legend(nrow = 3, ncol = 2,\r\n                              keyheight = unit(1, \"lines\"))) +\r\n  \r\n  # Themes\r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(plot.title = element_text(family = \"karla\", size = 16, face = \"bold\", hjust = .5),\r\n        plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 10)),\r\n        axis.ticks = element_blank(),\r\n        axis.title.x = element_text(size = 12, margin = margin(t = 5)),\r\n        axis.title.y = element_blank(),\r\n        axis.text.x = element_text(size = 11, margin = margin(t = 5)),\r\n        axis.text.y = element_text(size = 11, margin = margin(r = 5)),\r\n        legend.position = c(.6, .15),\r\n        legend.title = element_blank(),\r\n        legend.text = element_text(size = 12, margin = margin(r = 10)),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_line(linewidth = .5, color = \"white\"),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nThe Disney marketing machinery is evident in the trajectories of its three movies here. When these came out, they were all anybody could talk about, all anybody wanted to see, and as people flocked to cinemas these movies made a boatload of money very quickly. But the hype started to die down at around the 30-day mark, and receipts plateaued thereafter.\r\nWarner Bros.’ Batman v Superman had a similar start. The pre-release hype was intense, saturating the pop culture landscape in a major way (and in the year 2016 no less!). People rushed to see it and it broke box office records. The only problem was that it was bad, bad, bad. The chart shows how its receipts plateaued immediately, and after just 84 days, it was unceremoniously pulled from theaters.\r\nAvatar did not have a splashy start, but what it had was staying power. Long after the other blockbusters entered their plateaus, Avatar’s cumulative receipts were still growing.\r\nHere is another chart that makes this more apparent. I have segmented each film’s theatrical run into fortnightly (two-week) periods and plotted their cumulative receipts for each fortnight.\r\n\r\n\r\nShow code\r\n\r\ndf1 <- df %>%\r\n  group_by(title) %>%\r\n  mutate(todate_lag = lag(todate),\r\n         fortnight = (day - 1) %/% 14) %>%\r\n  replace_na(list(todate_lag = 0)) %>%\r\n  group_by(title, fortnight) %>%\r\n  mutate(day2 = 1:n(),\r\n         todate2 = todate - min(todate_lag)) %>%\r\n  ungroup()\r\n  \r\nggplot(df1 %>% filter(title != \"Avatar: The Way of Water\"), \r\n       aes(x = day2, y = todate2 / 1000000, group = fortnight, color = fortnight)) +\r\n  geom_line(linewidth = .8) +\r\n  facet_wrap(~ title, nrow = 2, scales = \"free_y\") +\r\n  \r\n  # Labels\r\n  scale_y_continuous(name = \"$ million\") +\r\n  labs(title = \"The way of Avatar II\",\r\n       subtitle = \"Cumulative U.S. box office receipts, by fortnight\") +\r\n  \r\n  # Legend\r\n  scale_color_gradient2(low = \"#d11f00\", mid = \"#f2e38c\", high = \"white\", \r\n                        midpoint = 8,\r\n                        guide = \"colorbar\") +\r\n  guides(color = guide_colorbar(title = \"Fortnights since release\",\r\n                                title.position = \"top\",\r\n                                title.vjust = 0,\r\n                                title.hjust = .5,\r\n                                direction = \"horizontal\",\r\n                                barwidth = unit(8, \"lines\"),\r\n                                barheight = unit(.75, \"lines\"),\r\n                                ticks = FALSE)) +\r\n  \r\n  # Themes\r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\r\n        plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\r\n        axis.ticks = element_blank(),\r\n        axis.title.x = element_blank(),\r\n        axis.title.y = element_text(size = 12),\r\n        axis.text.x = element_blank(),\r\n        axis.text.y = element_text(size = 10, margin = margin(r = 2)),\r\n        legend.position = c(.84, .24),\r\n        legend.title = element_text(size = 12, face = \"bold\"),\r\n        legend.text = element_text(size = 10),\r\n        strip.background = element_rect(fill = \"#1046b1\", color = NA),\r\n        strip.text = element_text(size = 10, face = \"bold\", color = \"white\"),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_line(linewidth = .5, color = \"white\"),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nAvatar certainly stands out. In a way, it marked the end of the pre-MCU blockbuster era when the installments of a franchise didn’t come just months or even weeks apart. Such an onslaught of content inevitably detracts from the experience of viewing any single release. Avatar was neither buoyed nor hobbled by its belonging to a mega-franchise, which might go some ways in explaining why people kept seeing it in cinemas for so long.\r\nInterestingly however, James Cameron now appears to be adopting the mega-franchise model as he mass-produces four Avatar sequels slated for biannual releases until 2028. Good luck with that. The franchise game is a crowded space these days, and The Way of Water has apparently already underperformed. But will it go on to have the same staying power as the first Avatar? Or will it fizzle out like BvS?\r\nThe stakes are… hilariously high? From Variety:\r\n\r\nCameron apparently told Disney and 20th Century Studios executives that his sequel budget was so high it represented “the worst business case in movie history.” According to the director’s estimates, “you have to be the third or fourth highest-grossing film in history. That’s your threshold. That’s your break even.”\r\n\r\nI am no business genius, but if you need your enterprise to be the third or fourth most successful in history just to avoid financial ruin then maybe rethink your strategy. Maybe hedge a little!\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-12-21-avatar/avatar_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-12-23T14:53:17+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 960
  },
  {
    "path": "posts/2022-12-15-mountains/",
    "title": "Luzon's hiking trails",
    "description": "Creating a stylized map of mountains using ridgelines",
    "author": [],
    "date": "2022-12-15",
    "categories": [],
    "contents": "\r\nI have lately been experimenting with R’s map-making capabilities, and as a project I wanted to try visualizing the great mountain ranges of Luzon. The Philippines has some remarkable mountain ranges, and hiking through them is a unique sort of pleasure that I only discovered recently.\r\nAn obvious approach would be to make a relief map, with colors corresponding to elevation, but to make it more interesting I decided to create a more stylized ridgeline-style map. A ridge plot is… hard to describe. Look up the album cover of Joy Division’s Unknown Pleasures and you’ll understand. I am indebted to dieghernan’s tutorial on mapping with ridgelines.1\r\nLet’s start by loading up the basic packages.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(sf)\r\nlibrary(terra)\r\n\r\n\r\nThe coastline of the Philippines can be obtained from the rnaturalearth package.\r\n\r\n\r\nlibrary(rnaturalearth)\r\n\r\nph <- ne_countries(scale = 10, country = \"Philippines\", returnclass = \"sf\")\r\n\r\nluzon <- ph %>%\r\n  st_crop(xmin = st_bbox(ph)$xmin %>% as.numeric(), \r\n          xmax = st_bbox(ph)$xmax %>% as.numeric(), \r\n          ymin = 13.5, \r\n          ymax = 18.5) %>%\r\n  st_transform(25391)\r\n\r\n\r\nThis returns a simple features or sf object, which has a geometry column that draws the coastline of the Philippines. The st_crop() function subsets the polygon to our area of interest while the st_transform() function sets the coordinate reference system to “Luzon 1911 / Philippines zone I” (EPSG code 25391).\r\nBecause this only draws the coastline, the major Luzon lakes of Laguna de Bay and Taal are not defined. We can load their polygons from rnaturalearth as well:\r\n\r\n\r\nlakes <- ne_download(scale = 10, type = \"lakes\", category = \"physical\", returnclass = \"sf\") %>%\r\n  mutate(in_luzon = str_detect(name, \"Laguna de Bay|Taal\")) %>%\r\n  filter(in_luzon == TRUE) %>%\r\n  st_transform(25391) %>% \r\n  summarize()\r\n\r\nOGR data source with driver: ESRI Shapefile \r\nSource: \"C:\\Users\\Kenneth Anthony\\AppData\\Local\\Temp\\RtmpktG7Qa\", layer: \"ne_10m_lakes\"\r\nwith 1355 features\r\nIt has 41 fields\r\nInteger64 fields read as strings:  scalerank ne_id \r\n\r\nWe can then use lakes to “punch holes” into the luzon polygon:\r\n\r\n\r\nluzon <- st_difference(st_geometry(luzon), st_geometry(lakes))\r\n\r\nplot(luzon)\r\n\r\n\r\n\r\nTo draw the ridges that symbolize Luzon’s mountain ranges, we need elevation raster data. This is taken from the elevatr package using the get_elev_raster() function.\r\n\r\n\r\nlibrary(elevatr)\r\n\r\ndem <- get_elev_raster(luzon, z = 7, clip = \"bbox\", expand = NULL) %>%\r\n  rast() %>%\r\n  mask(vect(luzon))\r\n\r\nnames(dem) <- \"elev\"\r\n\r\n\r\nThe rast() function converts it into a SpatRaster object, which is native to the terra package. The mask() function removes all cells outside the luzon polygon.\r\nThis raster actually provides more granularity than we want, so we aggregate the cells up to get a lower resolution. Then we convert it to a data.frame for plotting with ggplot2.\r\n\r\n\r\ndem_agg <- aggregate(dem, round(nrow(dem) / 200))\r\ndem_df <- as.data.frame(dem_agg, xy = TRUE, na.rm = FALSE)\r\n\r\n\r\nThe luzon polygon is plotted using geom_sf() while the ridgelines obtained from elevated data are plotted using geom_ridgeline() from the ggridges packages.\r\n\r\n\r\nlibrary(ggplot2)\r\nlibrary(ggridges)\r\n\r\n# Set expanded boundaries\r\ncoords <- st_bbox(c(xmin = 118.75, xmax = 125.75, ymin = 13.75, ymax = 18.25),\r\n                  crs = 4326) %>%\r\n  st_as_sfc() %>%\r\n  st_transform(25391) %>%\r\n  st_coordinates()\r\n\r\nmap <- ggplot() +\r\n  geom_sf(data = luzon, color = NA, fill = \"#069801\") +\r\n  geom_ridgeline(data = dem_df, \r\n                 aes(x = x, y = y, group = y, height = elev),\r\n                 scale = 25, fill = \"#84502e\", color = \"#4f3321\") +\r\n  coord_sf(xlim = coords[c(1, 2), 1],\r\n           ylim = coords[c(2, 3), 2],\r\n           expand = FALSE) +\r\n  theme_ridges() +\r\n  theme(plot.margin = margin(0, 0, 0, 0),\r\n        panel.background = element_rect(fill = \"#b8dfff\"),\r\n        panel.grid.major = element_line(color = \"#a5d0f3\"),\r\n        axis.title = element_blank(),\r\n        axis.text = element_blank())\r\nmap\r\n\r\n\r\n\r\nYou can see how vividly the ridgelines capture Luzon’s mountains. It’s practically 3D!\r\nI now want to add markers for some of the more famous hiking trails in Luzon. I can easily get their coordinates using Google Maps, but a complication to deal with is that the coordinate reference system (CRS) of Google Maps is different from the one I’m using here. I must therefore use st_transform() to reproject them first.\r\n\r\n\r\nspots <- read_csv(\"spots.csv\") %>%\r\n  mutate(label = toupper(label))\r\n\r\ncoords <- spots %>%\r\n  st_as_sf(agr = \"constant\", coords = c(\"x\", \"y\"), crs = 4326) %>%\r\n  st_transform(25391) %>%\r\n  st_coordinates()\r\n\r\nspots <- cbind(spots, coords)\r\n\r\n\r\nFinally, I downloaded some Google fonts for some added fanciness. Here is the final chart:\r\n\r\n\r\nShow code\r\n\r\nlibrary(ggrepel)\r\n\r\nmap +\r\n  geom_point(data = spots, \r\n             aes(x = X, y = Y),\r\n             size = 2.5, shape = 24, linewidth = .75, color = \"white\", fill = \"black\") +\r\n  geom_label_repel(data = spots, \r\n                   aes(x = X, y = Y, label = label),\r\n                   family = \"karla\", fontface = \"bold\", size = 8/.pt, \r\n                   hjust = .5, vjust = .5, nudge_x = 10000, min.segment.length = 1, label.r = unit(0, \"lines\"), label.size = NA, label.padding = unit(.2, \"lines\"), alpha = .6) +\r\n  \r\n  # Fancy plot title\r\n  annotate(\"text\", x = 1.27 * 10^6, y = 1.855 * 10^6, hjust = .5,\r\n           label = \"HIKING DESTINATIONS\", family = \"lora\", size = 12/.pt) +\r\n  annotate(\"text\", x = 1.27 * 10^6, y = 1.835 * 10^6, hjust = .5,\r\n           label = \"in\", family = \"lora\", fontface = \"italic\", size = 12/.pt) +\r\n  annotate(\"text\", x = 1.27 * 10^6, y = 1.803 * 10^6, hjust = .5,\r\n           label = \"L U Z O N\", family = \"lora\", size = 30/.pt)\r\n\r\n\r\n\r\nMy one hiking experience so far was at Nagpatong Rock, near Masungi. It was arduous and muddy and I slept for 12 hours afterwards. But for that brief moment at the peak, as I sipped cold coffee and braced myself against the wind, I looked out at the view and found it absolutely grand.\r\n\r\n\r\n\r\nStay elevated!\r\n\r\nAnd let me just say that learning to make maps in R has been bewilderingly difficult. I have found Geocomputation with R useful, but much of it remains mysterious to me.↩︎\r\n",
    "preview": "posts/2022-12-15-mountains/mountains_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2022-12-23T16:45:07+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 960
  },
  {
    "path": "posts/2022-12-07-im-gonna-carry-that-weight/",
    "title": "I'm gonna carry that weight",
    "description": "Using a massive dataset of powerlifting competitors to set my gym goals for next year",
    "author": [],
    "date": "2022-12-07",
    "categories": [],
    "contents": "\r\nThe pandemic (and turning 30) made me really start paying more attention to my health, and one of my resolutions was to go to the gym more consistently. It’s now been a little over a year. At the moment, my one-rep max for squats is about 1.5x my body weight, while for bench, it’s about 1.15x. As a motivator, I thought I’d look for benchmarks to work towards this coming year.\r\nMy basis will be this Kaggle dataset that contains the lifting records of over 400,000 powerlifting competitors, as listed in OpenPowerlifting.org. I might be setting the bar(bell) a bit high for myself here since I am by no means a competitive powerlifter, but consider that most people who join powerlifting comps aren’t particularly good. In fact, most of them lose! In the aggregate, the dataset will probably be a good sample of the population I’m looking to compare myself against—men who lift regularly.\r\nHere are its columns:\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\nread_csv(\"openpowerlifting.csv\") %>% names()\r\n\r\n [1] \"Name\"            \"Sex\"             \"Event\"          \r\n [4] \"Equipment\"       \"Age\"             \"AgeClass\"       \r\n [7] \"Division\"        \"BodyweightKg\"    \"WeightClassKg\"  \r\n[10] \"Squat1Kg\"        \"Squat2Kg\"        \"Squat3Kg\"       \r\n[13] \"Squat4Kg\"        \"Best3SquatKg\"    \"Bench1Kg\"       \r\n[16] \"Bench2Kg\"        \"Bench3Kg\"        \"Bench4Kg\"       \r\n[19] \"Best3BenchKg\"    \"Deadlift1Kg\"     \"Deadlift2Kg\"    \r\n[22] \"Deadlift3Kg\"     \"Deadlift4Kg\"     \"Best3DeadliftKg\"\r\n[25] \"TotalKg\"         \"Place\"           \"Wilks\"          \r\n[28] \"McCulloch\"       \"Glossbrenner\"    \"IPFPoints\"      \r\n[31] \"Tested\"          \"Country\"         \"Federation\"     \r\n[34] \"Date\"            \"MeetCountry\"     \"MeetState\"      \r\n[37] \"MeetName\"       \r\n\r\nI’ll subset this to keep it as relevant as possible to myself: I’ll retain males lifters only (Sex == \"M\"); I’ll remove records from competitions that do not require drug testing (Test == \"Yes\"); and I’ll remove all failed attempts, which are recorded as negative of the weight attempted (Best3SquatKg > 0 & Best3BenchKg > 0). I will then compute the ratios of the maximum weight lifted in the squat and bench press to the lifter’s body weight.\r\n\r\n\r\ndf <- read_csv(\"openpowerlifting.csv\") %>%\r\n  filter(Sex == \"M\" & Tested == \"Yes\" & Best3SquatKg > 0 & Best3BenchKg > 0) %>%\r\n  select(Name, Age, Date, BodyweightKg, Best3SquatKg, Best3BenchKg) %>%\r\n  mutate(Ratio_Squat = Best3SquatKg / BodyweightKg,\r\n         Ratio_Bench = Best3BenchKg / BodyweightKg) %>%\r\n  arrange(Name, Date) %>%\r\n  drop_na()\r\n\r\n\r\nI am left with 234,174 observations on 76,233 lifters. To get an idea of what the data looks like, here are the records of some arbitrary guy I picked out named Linh Vu:\r\n\r\n\r\nlibrary(knitr)\r\n\r\ndf %>% filter(Name == \"Linh Vu\") %>% kable()\r\n\r\nName\r\nAge\r\nDate\r\nBodyweightKg\r\nBest3SquatKg\r\nBest3BenchKg\r\nRatio_Squat\r\nRatio_Bench\r\nLinh Vu\r\n26.5\r\n2010-09-19\r\n82.40\r\n155.0\r\n90.0\r\n1.881068\r\n1.092233\r\nLinh Vu\r\n26.5\r\n2010-11-28\r\n82.65\r\n160.0\r\n90.0\r\n1.935874\r\n1.088929\r\nLinh Vu\r\n27.5\r\n2011-03-26\r\n82.68\r\n157.5\r\n92.5\r\n1.904935\r\n1.118771\r\nLinh Vu\r\n27.5\r\n2011-06-26\r\n87.85\r\n170.0\r\n105.0\r\n1.935117\r\n1.195219\r\nLinh Vu\r\n28.5\r\n2012-11-25\r\n82.20\r\n170.0\r\n90.0\r\n2.068126\r\n1.094890\r\nLinh Vu\r\n29.5\r\n2013-05-26\r\n82.10\r\n175.0\r\n95.0\r\n2.131547\r\n1.157126\r\nLinh Vu\r\n29.5\r\n2013-08-18\r\n81.05\r\n177.5\r\n105.0\r\n2.190006\r\n1.295497\r\nLinh Vu\r\n29.5\r\n2013-12-01\r\n73.85\r\n162.5\r\n105.0\r\n2.200406\r\n1.421801\r\nLinh Vu\r\n30.5\r\n2014-04-27\r\n73.80\r\n160.0\r\n105.0\r\n2.168022\r\n1.422764\r\nLinh Vu\r\n30.5\r\n2014-11-23\r\n73.80\r\n175.0\r\n102.5\r\n2.371274\r\n1.388889\r\nLinh Vu\r\n31.5\r\n2015-04-26\r\n73.40\r\n182.5\r\n107.5\r\n2.486376\r\n1.464578\r\nLinh Vu\r\n31.5\r\n2015-08-14\r\n72.25\r\n190.0\r\n107.5\r\n2.629758\r\n1.487889\r\n\r\nI want to get a sense of how ratios are distributed across the population, so I’ll have to keep just one record from lifters with multiple records. I thought about taking the average, but instead I opted to just choose one at random.\r\n\r\n\r\ndf1 <- df %>%\r\n  group_by(Name) %>%\r\n  slice_sample(n = 1) %>%\r\n  ungroup()\r\n\r\n\r\nSince we’re looking at the distribution of two variables, a good plot use is a 2D histogram, implemented using geom_bin_2d from ggplot.\r\n\r\n\r\nShow code\r\n\r\nlibrary(ggplot2)\r\n\r\n# Number of observations in comma-separated format\r\nn <- df$Name %>% \r\n  unique() %>% \r\n  length() %>% \r\n  prettyNum(big.mark = \",\", scientific = FALSE)\r\n\r\nggplot(df1, aes(x = Ratio_Squat, y = Ratio_Bench)) + \r\n  geom_bin_2d(binwidth = .1) +\r\n  \r\n  # Label: Me\r\n  geom_rect(xmin = 1.5, xmax = 1.6, ymin = 1.1, ymax = 1.2, \r\n            fill = \"#cc0700\", color = \"#8c0803\", linewidth = .75) +\r\n  annotate(\"text\", x = 1.6 + .2, y = 1.1 - .4, hjust = 0, vjust = 1, \r\n           label = \"Me!\", size = 14/.pt, family = \"karla\", fontface = \"bold\", color = \"#cc0700\") + \r\n  geom_segment(x = 1.6 - .01, xend = 1.6 + .15, y = 1.1 - .07, yend = 1.1 - .37, \r\n               color = \"#cc0700\", linewidth = .5) +\r\n  \r\n  # Label: Mode\r\n  geom_rect(xmin = 2.1, xmax = 2.2, ymin = 1.4, ymax = 1.5, \r\n            fill = NA, color = \"black\", linewidth = .75) +\r\n  annotate(\"text\", x = 2.2 + .5, y = 1.4, hjust = 0, vjust = 1, \r\n           label = \"Mode\", size = 14/.pt, family = \"karla\", fontface = \"bold\", color = \"black\") + \r\n  geom_segment(x = 2.2 + .07, xend = 2.2 + .45, y = 1.4 + .04, yend = 1.4 - .05, \r\n               color = \"black\", linewidth = .5) +\r\n  \r\n  # Labels\r\n  labs(title = \"Ratio of max weight lifted to body weight\",\r\n       subtitle = paste0(\"Data on \", n, \" natural male lifters\")) +\r\n  scale_x_continuous(name = \"Squat\", limits = c(.2, 5.5), breaks = 1:6) +\r\n  scale_y_continuous(name = \"Bench\", limits = c(.2, 3.5), breaks = 1:4) +\r\n  \r\n  # Legend\r\n  scale_fill_gradient(low = \"gray94\", high = \"#1046b1\", guide = \"colorbar\",\r\n                      breaks = c(250, 500, 750, 1000)) +\r\n  guides(fill = guide_colorbar(title = \"Count\",\r\n                               title.position = \"top\", title.vjust = 1, title.hjust = .5,\r\n                               barwidth = unit(.75, \"lines\"),\r\n                               barheight = unit(8, \"lines\"),\r\n                               ticks = FALSE)) +\r\n  \r\n  # Theme\r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\r\n        plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 15)),\r\n        axis.ticks = element_blank(),\r\n        axis.title.x = element_text(size = 12, margin = margin(t = 10)),\r\n        axis.title.y = element_text(size = 12, margin = margin(r = 10)),\r\n        axis.text.x = element_text(size = 12, margin = margin(t = 5)),\r\n        axis.text.y = element_text(size = 12, margin = margin(r = 5)),\r\n        legend.position = \"right\",\r\n        legend.title = element_text(size = 12, face = \"bold\"),\r\n        legend.text = element_text(size = 10),\r\n        panel.background = element_rect(fill = \"gray98\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_blank(),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nThe mode is 2.1-2.2x for squat and 1.4-1.5x for bench. I’m some ways off from the histogram’s central tendency, but not as far as I thought! Getting to that dark blue region is totally doable. I’ll revisit this chart a year from now and see where I am.\r\nAs a bonus, it might also be interesting to divide the lifters into age brackets and see how the distribution changes. My guess is that lifters in their mid-20s would be stronger than lifters in their late 30s. However, here is what I get:\r\n\r\n\r\nShow code\r\n\r\nlibrary(cowplot)\r\n\r\n# Common plot elements\r\n\r\nbin <- geom_bin_2d(binwidth = .1)\r\nme_box <- geom_rect(xmin = 1.5, xmax = 1.6, ymin = 1.1, ymax = 1.2, \r\n                    fill = \"#cc0700\", color = \"#8c0803\", linewidth = .25)\r\nfill <- scale_fill_gradient(low = \"gray94\", high = \"#1046b1\")\r\nx_axis <- scale_x_continuous(name = \"Squat\", limits = c(.5, 4), breaks = 1:4)\r\ny_axis <- scale_y_continuous(name = \"Bench\", limits = c(.5, 4), breaks = 1:4)\r\ntheme <- theme_minimal(base_family = \"karla\") +\r\n  theme(panel.background = element_rect(fill = \"gray98\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_blank(),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        axis.title.x = element_text(size = 8, margin = margin(t = 5)),\r\n        axis.title.y = element_text(size = 8, margin = margin(r = 5)),\r\n        axis.text = element_text(size = 8),\r\n        legend.position = \"none\")\r\n\r\n# Plots\r\n\r\np1 <- ggplot(df1 %>% filter(Age %in% 26:30), \r\n             aes(x = Ratio_Squat, y = Ratio_Bench)) +\r\n  bin + me_box + fill + x_axis + y_axis + theme +\r\n  annotate(\"text\", x = 1.2, y = 2.2, size = 8/.pt, hjust = .5, vjust = .5, \r\n           label = \"Me!\", family = \"karla\", fontface = \"bold\", color = \"#cc0700\") + \r\n  geom_segment(x = 1.5, xend = 1.3, y = 1.2 + .1, yend = 2.2 - .25, \r\n               color = \"#cc0700\", linewidth = .25)\r\n\r\np2 <- ggplot(df1 %>% filter(Age %in% 31:35), \r\n             aes(x = Ratio_Squat, y = Ratio_Bench)) +\r\n  bin + me_box + fill + x_axis + y_axis + theme\r\n\r\np3 <- ggplot(df1 %>% filter(Age %in% 36:40), \r\n             aes(x = Ratio_Squat, y = Ratio_Bench)) +\r\n  bin + me_box + fill + x_axis + y_axis + theme\r\n\r\n# Consolidate\r\n\r\ntitle <- ggdraw() + \r\n  draw_label(\"Ratio of max weight lifted to body weight, by age group\", \r\n             fontfamily = \"karla\", fontface = \"bold\", x = .5, hjust = .5, size = 11) +\r\n  theme(plot.margin = margin(t = -15, b = 10))\r\n\r\nplots <- plot_grid(p1, p2, p3, nrow = 1, \r\n                   labels = c(\"Aged 26-30\", \"Aged 31-35\", \"Aged 36-40\"),\r\n                   label_size = 9, label_fontfamily = \"karla\", label_fontface = \"plain\", \r\n                   hjust = -1.4, vjust = -.9)\r\n\r\nplot_grid(title, plots, ncol = 1, rel_heights = c(.2, 1))\r\n\r\n\r\n\r\nThe histograms don’t actually differ all that much. It’s possible that the bodily disadvantages of age are offset by the skills advantages of more training and experience. Just look at Linh Vu!\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-12-07-im-gonna-carry-that-weight/benchmark_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2022-12-23T16:09:05+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 998
  },
  {
    "path": "posts/2022-12-03-war-is-over/",
    "title": "War is over (if you want it?)",
    "description": "A tally of active armed conflicts as of Christmas Day, since 1946",
    "author": [],
    "date": "2022-12-03",
    "categories": [],
    "contents": "\r\nPeople’s feelings about the Christmas season span a wide range, from very positive to very negative.\r\nAs for where I fall, well:\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\n\r\ndf <- read_csv(\"ucdp-prio-acd-221.csv\") %>%\r\n  select(conflict_id, location, year, type_of_conflict, region, ep_end_date, region) %>%\r\n  mutate(type_of_conflict = factor(type_of_conflict),\r\n         xmas = as.Date(paste0(year, \"-12-25\")),\r\n         count = ifelse(!(ep_end_date > xmas), 0, 1)) %>%\r\n  replace_na(list(count = 1))\r\n\r\nconflicts <- df %>%\r\n  group_by(year, type_of_conflict) %>%\r\n  summarize(count = sum(count)) %>%\r\n  ungroup()\r\n\r\nggplot(conflicts, aes(x = year, y = count, fill = type_of_conflict)) + \r\n  geom_bar(stat = \"identity\", position = \"stack\", width = .7) +\r\n  geom_hline(yintercept = 0, linewidth = .25, color = \"black\") + \r\n  labs(title = \"Another year over\",\r\n       subtitle = \"Active armed conflicts as of Christmas Day, 1946-2021\") +\r\n  scale_fill_manual(name = \"Type of conflict\",\r\n                    labels = c(\"Extrasystemtic\", \"Interstate\", \"Intrastate\", \"Internationalized intrastate\"),\r\n                    values = rev(c(\"#1046b1\", \"#c52e9b\", \"#ff505b\", \"#ffa600\"))) +\r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\r\n        plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 15)),\r\n        axis.ticks = element_blank(),\r\n        axis.title = element_blank(),\r\n        axis.text.x = element_text(size = 12, margin = margin(t = 5)),\r\n        axis.text.y = element_text(size = 12, margin = margin(r = 5)),\r\n        legend.position = \"bottom\",\r\n        legend.title = element_text(size = 11, face = \"bold\", margin = margin(r = 10)),\r\n        legend.text = element_text(size = 11),\r\n        legend.key.size = unit(.4, \"lines\"),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_line(color = \"white\"),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nThe data is from the UCDP/PRIO Armed Conflict Dataset version 22.1. I’ll go through how I constructed the above chart.\r\nFirst, some words about the dataset. Each observation is a conflict-year. A conflict is dated from its first battle-related death, but only active “episodes”—defined as 25 battle-related deaths—are recorded in the database. For example, the Basque conflict has the following entries:\r\n\r\n\r\nlibrary(knitr)\r\n\r\nread_csv(\"ucdp-prio-acd-221.csv\") %>%\r\n  select(conflict_id, side_a, side_b, year, start_date, start_date2, ep_end_date) %>%\r\n  filter(conflict_id == \"342\") %>%\r\n  kable()\r\n\r\nconflict_id\r\nside_a\r\nside_b\r\nyear\r\nstart_date\r\nstart_date2\r\nep_end_date\r\n342\r\nGovernment of Spain\r\nETA\r\n1978\r\n1968-06-07\r\n1978-10-22\r\nNA\r\n342\r\nGovernment of Spain\r\nETA\r\n1979\r\n1968-06-07\r\n1978-10-22\r\nNA\r\n342\r\nGovernment of Spain\r\nETA\r\n1980\r\n1968-06-07\r\n1978-10-22\r\nNA\r\n342\r\nGovernment of Spain\r\nETA\r\n1981\r\n1968-06-07\r\n1978-10-22\r\nNA\r\n342\r\nGovernment of Spain\r\nETA\r\n1982\r\n1968-06-07\r\n1978-10-22\r\n1982-12-29\r\n342\r\nGovernment of Spain\r\nETA\r\n1985\r\n1968-06-07\r\n1985-12-23\r\nNA\r\n342\r\nGovernment of Spain\r\nETA\r\n1986\r\n1968-06-07\r\n1985-12-23\r\nNA\r\n342\r\nGovernment of Spain\r\nETA\r\n1987\r\n1968-06-07\r\n1985-12-23\r\n1987-12-31\r\n342\r\nGovernment of Spain\r\nETA\r\n1991\r\n1968-06-07\r\n1991-06-28\r\n1991-12-13\r\n\r\nWhile it is recorded as starting on 7 June 1968, its first active episode started on 22 October 1978 and lasted until 29 December 1982. A second episode occurred from 23 December 1985 to 31 December 1987, then a third from 28 June to 13 December 1991. For my purposes, this would count as an active conflict for the Christmas Days of 1978-1982 and 1985-1987. Not 1991 however, since that episode ended right before Christmas.\r\nFor each conflict-year, I therefore need to construct a dummy to indicate whether it is a Christmas conflict or not. I do it in three steps. First, I construct the variable xmas to set the Christmas Day for each year. Second, I set the variable count to 0 if the conflict-year’s ep_end_date occurs before Christmas. Finally, for all cases where ep_end_date is NA, I set count to 1.\r\n\r\n\r\ndf <- read_csv(\"ucdp-prio-acd-221.csv\") %>%\r\n  mutate(xmas = as.Date(paste0(year, \"-12-25\")),\r\n         count = ifelse(!(ep_end_date > xmas), 0, 1)) %>%\r\n  replace_na(list(count = 1))\r\n\r\n\r\nThen it’s a simple matter of counting the active conflicts per year and constructing a bar chart. to illustrate the depressing fact that Christmas 2021 saw an all-time high in active conflicts worldwide.\r\nTo end, here’s the song that inspired this post. Have a bad Christmas season everybody.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-12-03-war-is-over/war-is-over_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2022-12-23T16:16:48+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 864
  },
  {
    "path": "posts/2022-11-26-migration/",
    "title": "More on the great post-1500 migrations",
    "description": "Which countries have the most diverse ancestors? Which countries have the most descendants around the world today?",
    "author": [],
    "date": "2022-11-26",
    "categories": [],
    "contents": "\r\nIn my last post I brought up the World Migration Matrix, an ambitious dataset constructed in 2009 by Louis Putterman and David N. Weil that attempts to trace the ancestral origins of the present-day populations of nearly every country on Earth. It’s a complete matrix, so that you can pick any pair of countries and obtain the share of one country’s ancestors that originated from the other, and vice versa. It’s a deeply fascinating dataset and I thought I’d play around with it some more. (It’s also a chance to familiarize myself further with Highcharts.)\r\nPreviously, I plotted the immigrant share of each country, i.e. the share of its current population whose ancestors were not living in that country in the year 1500 (using modern borders). A related question to ask is, what is the ancestral diversity of each country? We encountered cases like Taiwan where nearly all inhabitants have “foreign” ancestors, but since a huge portion come from China, its resulting ancestral diversity is quite low. Contrast that with, say, the United States, where both the immigrant share is high and the ancestral country sources are very diverse.\r\nTo quantify this more formally, I use 1 minus the HH index as a measure of ancestral diversity. It takes a bit of data processing so I’m hiding the code below.\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\nlibrary(countrycode)\r\n\r\nmm_raw <- read_excel(\"matrix version 1.1.xls\") %>%\r\n  select(-update) %>%\r\n  pivot_longer(cols = !c(wbcode, wbname),\r\n               names_to = \"origin\",\r\n               values_to = \"share\")\r\n\r\n# Convert to ISO names and codes\r\n\r\nmm <- mm_raw %>%\r\n  mutate(origin = toupper(origin),\r\n         country_iso3 = countrycode(wbcode, \"wb\", \"iso3c\"),\r\n         origin_iso3 = countrycode(origin, \"wb\", \"iso3c\"))\r\n\r\nmm$country_iso3[mm$wbcode == \"ZAR\"] <- mm$origin_iso3[mm$origin == \"ZAR\"] <- \"COD\"\r\nmm$country_iso3[mm$wbcode == \"TMP\"] <- mm$origin_iso3[mm$origin == \"TMP\"] <- \"TLS\"\r\nmm$country_iso3[mm$wbcode == \"ROM\"] <- mm$origin_iso3[mm$origin == \"ROM\"] <- \"ROU\"\r\nmm$country_iso3[mm$wbcode == \"OAN\"] <- mm$origin_iso3[mm$origin == \"OAN\"] <- \"TWN\"\r\n\r\nmm <- mm %>%\r\n  mutate(country_name = countrycode(country_iso3, \"iso3c\", \"country.name\"),\r\n         origin_name = countrycode(origin_iso3, \"iso3c\", \"country.name\"),\r\n         country_region = countrycode(country_iso3, \"iso3c\", \"continent\"),\r\n         origin_region = countrycode(origin_iso3, \"iso3c\", \"continent\")) %>%\r\n  select(country_iso3, country_name, country_region, origin_iso3, origin_name, origin_region, share) %>%\r\n  drop_na() \r\n\r\n# Compute immigrant share\r\n\r\nmm_immig <- mm %>%\r\n  filter(country_iso3 == origin_iso3) %>%\r\n  mutate(immig = 1 - share) %>%\r\n  select(country_iso3, country_name, country_region, immig)\r\n\r\n# Compute ancestral diversity\r\n\r\nmm_hhi <- mm %>%\r\n  mutate(share2 = share^2) %>%\r\n  group_by(country_iso3, country_name, country_region) %>%\r\n  summarize(hhi = 1 - sum(share2)) %>%\r\n  ungroup()\r\n\r\nmm_immig_hhi <- mm_immig %>%\r\n  left_join(mm_hhi)\r\n\r\n\r\nThe following scatter plots ancestral diversity against the immigrant share of ancestors. They go hand-in-hand up to a point, and then we encounter enormous variety. I was surprised to find that the country with the most diverse set of ancestors is Jamaica, followed very closely by the United States. The other panels below showcase the ancestral origins of Jamaica and the U.S.\r\n\r\nImmigrant share vs diversity\r\n\r\n\r\nShow code\r\n\r\nlibrary(highcharter)\r\n\r\nx <- c(\"Country\", \"Continent\", \"Immigrant share of ancestors\", \"Ancestral diversity\")\r\ny <- c(\"{point.country_name:s}\", \"{point.country_region:s}\", \"{point.immig:.2f}\", \"{point.hhi:.2f}\")\r\ntltip <- tooltip_table(x, y)\r\n\r\nhchart(mm_immig_hhi, \"scatter\", \r\n       hcaes(x = immig, y = hhi, group = country_region),\r\n       color = c(\"#1046b1\", \"#a835a6\", \"#f0307d\", \"#ff6549\", \"#ffa600\"),\r\n       stickyTracking = FALSE,\r\n       jitter = list(x = .005, y = .005)) %>%\r\n  hc_xAxis(title = list(text = \"Immigrant share of ancestors\"),\r\n           gridLineWidth = 1) %>%\r\n  hc_yAxis(title = list(text = \"Ancestral diversity\"),\r\n           gridLineWidth = 1) %>%\r\n  hc_tooltip(useHTML = TRUE,\r\n             pointFormat = tltip,\r\n             headerFormat = \"\")\r\n\r\n\r\n\r\nJamaica’s ancestors\r\n\r\n\r\nShow code\r\n\r\njamaica <- mm %>%\r\n  filter(country_name == \"Jamaica\")\r\n\r\nformattp <- JS(\"function() {\r\n  if (this.point.value < 0.01) {\r\n    return '<b>' + this.point.name + '<\/b>: <0.01';\r\n  }\r\n  else {\r\n    return '<b>' + this.point.name + '<\/b>: ' + Highcharts.numberFormat(this.point.value, 2);\r\n  }\r\n}\")\r\n\r\nhcmap(map = \"custom/world-highres3\", \r\n      data = jamaica,\r\n      name = \"origin_name\",\r\n      value = \"share\",\r\n      borderWidth = .5,\r\n      joinBy = c(\"iso-a3\", \"origin_iso3\")) %>%\r\n  hc_mapNavigation(enabled = TRUE) %>%\r\n  hc_legend(align = \"left\",\r\n            title = list(text = \"Ancestral contribution to Jamaica's population\")) %>%\r\n  hc_tooltip(headerFormat = \"\",\r\n             formatter = formattp)\r\n\r\n\r\n\r\nAmerica’s ancestors\r\n\r\n\r\nShow code\r\n\r\nusa <- mm %>%\r\n  filter(country_name == \"United States\")\r\n\r\nhcmap(map = \"custom/world-highres3\", \r\n      data = usa,\r\n      name = \"origin_name\",\r\n      value = \"share\",\r\n      borderWidth = .5,\r\n      joinBy = c(\"iso-a3\", \"origin_iso3\")) %>%\r\n  hc_mapNavigation(enabled = TRUE) %>%\r\n  hc_legend(align = \"left\",\r\n            title = list(text = \"Ancestral contribution to U.S. population\")) %>%\r\n  hc_tooltip(headerFormat = \"\",\r\n             formatter = formattp)\r\n\r\n\r\n\r\n\r\nNow let’s flip things around: which countries contributed the most to the immigrant share of populations worldwide? Here are the top 10 in terms of absolute amounts:\r\n\r\n\r\nShow code\r\n\r\nlibrary(WDI)\r\n\r\npop <- WDI(country = \"all\",\r\n          indicator = c(\"pop\" = \"SP.POP.TOTL\"),\r\n          start = 2009,\r\n          end = 2009,) %>% \r\n  as_tibble() %>%\r\n  select(iso3c, pop) %>%\r\n  bind_rows(tibble(iso3c = \"TWN\",\r\n                   pop = 23119772))\r\n\r\nmm_origin <- mm %>%\r\n  left_join(pop, by = c(\"country_iso3\" = \"iso3c\")) %>%\r\n  mutate(absolute = share * pop,\r\n         absolute_out = ifelse(country_iso3 == origin_iso3, 0, share * pop))\r\n\r\nmm_origin_sum <- mm_origin %>%\r\n  group_by(origin_iso3, origin_name, origin_region) %>%\r\n  summarize(share = mean(share),\r\n            absolute = sum(absolute),\r\n            absolute_out = sum(absolute_out)) %>%\r\n  ungroup() %>%\r\n  filter(absolute_out > 0) %>%\r\n  arrange(-absolute_out) %>%\r\n  slice(1:10)\r\n\r\nmm_origin_sum <- mm_origin_sum %>%\r\n  mutate(origin_name = factor(origin_name, levels = mm_origin_sum$origin_name))\r\n\r\nhchart(mm_origin_sum, \"bar\", \r\n       hcaes(y = absolute_out, x = origin_name),\r\n       color = \"#1046b1\",\r\n       stickyTracking = FALSE) %>%\r\n  hc_yAxis(title = list(text = \"Global descendants outside of own country\"),\r\n           gridLineWidth = 1) %>%\r\n  hc_xAxis(title = list(text = \"\")) %>%\r\n  hc_tooltip(useHTML = TRUE,\r\n             pointFormat = \"{point.absolute_out:,.0f}\",\r\n             headerFormat = \"\")\r\n\r\n\r\n\r\nAround the world, some 167 million people1 not living in Spain have ancestors who lived in Spain in the year 1500. It speaks to the legacy of European colonization and migration that the top 5 largest sources of immigrant ancestry are European countries.\r\nWhere did the descendants of these prolific exporters of people settle? Here are some more maps to give you an idea.\r\n\r\nSpain\r\n\r\n\r\nShow code\r\n\r\nlibrary(CoordinateCleaner)\r\n\r\ncentroids <- as_tibble(countryref) %>%\r\n  filter(type == \"country\") %>%\r\n  select(iso3, centroid.lon, centroid.lat) %>%\r\n  group_by(iso3) %>%\r\n  summarize(lon = mean(centroid.lon),\r\n            lat = mean(centroid.lat)) %>%\r\n  ungroup()\r\n\r\nspain <- mm_origin %>%\r\n  filter(origin_name == \"Spain\") %>%\r\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %>%\r\n  mutate(z = absolute_out)\r\n\r\nhcmap(map = \"custom/world\", \r\n      borderWidth = .5,\r\n      showInLegend = FALSE) %>%\r\n  hc_add_series(data = spain, \r\n                type = \"mapbubble\",\r\n                maxSize = \"40\", \r\n                minSize = \"0\",\r\n                showInLegend = FALSE,\r\n                color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\r\n                tooltip = list(headerFormat = \"\",\r\n                               pointFormat = \"<b>{point.country_name}<\/b>: {point.absolute_out:,.0f}\")) %>%\r\n  hc_title(text = \"Distribution of Spanish descendants\")\r\n\r\n\r\n\r\nPortugal\r\n\r\n\r\nShow code\r\n\r\nportugal <- mm_origin %>%\r\n  filter(origin_name == \"Portugal\") %>%\r\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %>%\r\n  mutate(z = absolute_out)\r\n\r\nhcmap(map = \"custom/world\", \r\n      borderWidth = .5,\r\n      showInLegend = FALSE) %>%\r\n  hc_add_series(data = portugal, \r\n                type = \"mapbubble\",\r\n                maxSize = \"40\", \r\n                minSize = \"0\",\r\n                showInLegend = FALSE,\r\n                color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\r\n                tooltip = list(headerFormat = \"\",\r\n                               pointFormat = \"<b>{point.country_name}<\/b>: {point.absolute_out:,.0f}\")) %>%\r\n  hc_title(text = \"Distribution of Portuguese descendants\")\r\n\r\n\r\n\r\nUnited Kingdom\r\n\r\n\r\nShow code\r\n\r\nuk <- mm_origin %>%\r\n  filter(origin_name == \"United Kingdom\") %>%\r\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %>%\r\n  mutate(z = absolute_out)\r\n\r\nhcmap(map = \"custom/world\", \r\n      borderWidth = .5,\r\n      showInLegend = FALSE) %>%\r\n  hc_add_series(data = uk, \r\n                type = \"mapbubble\",\r\n                maxSize = \"40\", \r\n                minSize = \"0\",\r\n                showInLegend = FALSE,\r\n                color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\r\n                tooltip = list(headerFormat = \"\",\r\n                               pointFormat = \"<b>{point.country_name}<\/b>: {point.absolute_out:,.0f}\")) %>%\r\n  hc_title(text = \"Distribution of British descendants\")\r\n\r\n\r\n\r\nChina\r\n\r\n\r\nShow code\r\n\r\nchina <- mm_origin %>%\r\n  filter(origin_name == \"China\") %>%\r\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %>%\r\n  mutate(z = absolute_out)\r\n\r\nhcmap(map = \"custom/world\", \r\n      borderWidth = .5,\r\n      showInLegend = FALSE) %>%\r\n  hc_add_series(data = china, \r\n                type = \"mapbubble\",\r\n                maxSize = \"40\", \r\n                minSize = \"0\",\r\n                showInLegend = FALSE,\r\n                color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\r\n                tooltip = list(headerFormat = \"\",\r\n                               pointFormat = \"<b>{point.country_name}<\/b>: {point.absolute_out:,.0f}\")) %>%\r\n  hc_title(text = \"Distribution of Chinese descendants\")\r\n\r\n\r\n\r\nIndia\r\n\r\n\r\nShow code\r\n\r\nindia <- mm_origin %>%\r\n  filter(origin_name == \"India\") %>%\r\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %>%\r\n  mutate(z = absolute_out)\r\n\r\nhcmap(map = \"custom/world\", \r\n      borderWidth = .5,\r\n      showInLegend = FALSE) %>%\r\n  hc_add_series(data = india, \r\n                type = \"mapbubble\",\r\n                maxSize = \"40\", \r\n                minSize = \"0\",\r\n                showInLegend = FALSE,\r\n                color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\r\n                tooltip = list(headerFormat = \"\",\r\n                               pointFormat = \"<b>{point.country_name}<\/b>: {point.absolute_out:,.0f}\")) %>%\r\n  hc_title(text = \"Distribution of Indian descendants\")\r\n\r\n\r\n\r\nAngola\r\n\r\n\r\nShow code\r\n\r\nangola <- mm_origin %>%\r\n  filter(origin_name == \"Angola\") %>%\r\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %>%\r\n  mutate(z = absolute_out)\r\n\r\nhcmap(map = \"custom/world\", \r\n      borderWidth = .5,\r\n      showInLegend = FALSE) %>%\r\n  hc_add_series(data = angola, \r\n                type = \"mapbubble\",\r\n                maxSize = \"40\", \r\n                minSize = \"0\",\r\n                showInLegend = FALSE,\r\n                color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\r\n                tooltip = list(headerFormat = \"\",\r\n                               pointFormat = \"<b>{point.country_name}<\/b>: {point.absolute_out:,.0f}\")) %>%\r\n  hc_title(text = \"Distribution of Angolan descendants\")\r\n\r\n\r\n\r\n\r\n\r\nNot meant to be literal since a person can be of mixed ancestry. Perhaps it is more proper to say there are 167 million “people-equivalent” whose ancestors came from Spain. But hey, we’re just having fun here!↩︎\r\n",
    "preview": "posts/2022-11-26-migration/immigrant.jpg",
    "last_modified": "2022-11-28T22:41:19+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-25-roots/",
    "title": "The roots of economic development",
    "description": "Visualizing some key results in Spolaore and Wacziarg's 2013 survey",
    "author": [],
    "date": "2022-11-25",
    "categories": [],
    "contents": "\r\nOne of the most interesting economics papers I’ve ever read is the 2013 survey by Enrico Spolaore and Romain Wacziarg (SW) titled “How Deep Are the Roots of Economic Development?” There has long been an active, highly contentious discussion over why some countries today are rich while others are poor. As a citizen of a “poor” country, this was a big motivation for me to study economics.1\r\nThe proximate causes are relatively uncontroversial—Solow had it all laid out in 1956. Production turns inputs into output. More inputs mean more output. Some output are consumed, some are saved (“invested”) and turned into capital, which are then used as inputs to produce more output. You can keep accumulating capital to grow your output, but over time, for a given state of technology, capital accumulation will hit diminishing returns. You will then need to move up the technological ladder to continue increasing output. Repeat until rich.\r\nThe Solow model is elegant, but it has the flavor of saying that a business is successful because it makes a lot of money. The deeper question is why some countries have managed to perform these pro-growth activities while others have not. Is it something in their culture? Maybe their geography? Maybe they had a Great Leader who put all the pieces in place?\r\nThis has been the research agenda of a number of empirical economic historians. Their work supplements that of traditional economic historians by quantifying the evidence for various hypothesized root causes of development. SW survey their findings as of 2013 using a unified dataset available here. What I want to do is chart some of the more interesting results.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(foreign)\r\n\r\ndf <- read.dta(\"2013_longterm.dta\") %>%\r\n  as_tibble()\r\n\r\n\r\nGeography is a natural candidate for explaining the relative wealth of nations. Ever notice that cold countries tend to be richer than hot ones? In fact, it’s empirically well-founded:\r\n\r\n\r\nShow code\r\n\r\nlibrary(highcharter)\r\nlibrary(broom)\r\n\r\npretty <- function(n, d = 0) {\r\n  n <- format( round(n, digits = d), nsmall = d )\r\n  prettyNum(n, big.mark = \",\", scientific = FALSE)\r\n}\r\n\r\ndf1 <- df %>%\r\n  select(country, rgdpch_2005, avelat) %>%\r\n  drop_na() %>%\r\n  mutate(rgdpch_2005_pretty = pretty(rgdpch_2005, 0))\r\n\r\nfit <- lm(log10(rgdpch_2005) ~ avelat, data = df1) %>%\r\n  augment() %>%\r\n  arrange(avelat) %>%\r\n  slice(c(1, nrow(df1)))\r\n\r\nx <- c(\"Country\", \"GDP per capita\", \"Absolute latitude\")\r\ny <- c(\"{point.country:s}\", \"${point.rgdpch_2005_pretty:s}\", \"{point.avelat:.1f}\")\r\ntltip <- tooltip_table(x, y)\r\n\r\nhchart(df1, \"scatter\", \r\n       hcaes(x = avelat, y = rgdpch_2005),\r\n       color = hex_to_rgba(\"#1046b1\", 0.5),\r\n       size = 20,\r\n       stickyTracking = FALSE) %>%\r\n  hc_xAxis(title = list(text = \"Absolute latitude\"),\r\n           gridLineWidth = 1) %>%\r\n  hc_yAxis(title = list(text = \"GDP per capita 2005\"),\r\n           type = \"logarithmic\", \r\n           gridLineWidth = 1) %>%\r\n  hc_tooltip(useHTML = TRUE,\r\n             pointFormat = tltip,\r\n             headerFormat = \"\") %>%\r\n  hc_add_series(data = fit, \r\n                type = \"spline\",\r\n                hcaes(x = avelat, y = 10^.fitted),\r\n                color = \"black\",\r\n                lineWidth = 1,\r\n                marker = FALSE,\r\n                enableMouseTracking = FALSE)\r\n\r\n\r\n\r\nWhat explains this intriguing correlation? SW divide proposed mechanisms into direct and indirect channels. Geography may have a direct influence on economic development through the effects of climate and diseases on agricultural and labor productivity. Or in cruder form, this is the argument that hotter weather makes for lazier people, which Rizal refuted in “The Indolence of the Filipino”.\r\nArguments for an indirect channel are, for me, more convincing. Geography influenced x, and x in turn influenced economic development. There may even be additional layers (x influenced y, y influenced z, etc.). A famous hypothesis comes from Jared Diamond’s 1997 book Guns, Germs, and Steel, which argues that climate and the ecosystems it supported influenced the onset of agriculture and domestication in a society, what is known as the Neolithic Revolution. In turn, societies that transitioned earlier would have had a head start in technological progress and centralized governments. This explains why Europeans had the advantage of “guns, germs, and steel” as they were conquering the civilizations of New World America in the 16th century.\r\nTo illustrate the Diamond hypothesis, the following plots population density in the year 1500 against the years since a country had undergone its Neolithic Revolution—population density being the best proxy available for relative economic development in a pre-industrial world. Again, a positive correlation is established.\r\n\r\n\r\nShow code\r\n\r\ndf1 <- df %>%\r\n  select(country, pd1500, agyears) %>%\r\n  drop_na() %>%\r\n  mutate(pd1500_pretty = pretty(pd1500, 2),\r\n         agyears_pretty = pretty(agyears, 0))\r\n\r\nfit <- lm(log10(pd1500) ~ agyears, data = df1) %>%\r\n  augment() %>%\r\n  arrange(agyears) %>%\r\n  slice(c(1, nrow(df1)))\r\n\r\nx <- c(\"Country\", \"Population density in 1500\", \"Years since Neolithic Revolution\")\r\ny <- c(\"{point.country:s}\", \"{point.pd1500_pretty:s}\", \"{point.agyears_pretty:s}\")\r\ntltip <- tooltip_table(x, y)\r\n\r\nhchart(df1, \"scatter\", \r\n       hcaes(x = agyears, y = pd1500),\r\n       color = hex_to_rgba(\"#1046b1\", 0.5),\r\n       size = 20,\r\n       stickyTracking = FALSE) %>%\r\n  hc_xAxis(title = list(text = \"Years since Neolithic Revolution\"),\r\n           gridLineWidth = 1) %>%\r\n  hc_yAxis(title = list(text = \"Population density 1500\"),\r\n           type = \"logarithmic\", \r\n           gridLineWidth = 1) %>%\r\n  hc_tooltip(useHTML = TRUE,\r\n             pointFormat = tltip,\r\n             headerFormat = \"\") %>%\r\n  hc_add_series(data = fit, \r\n                type = \"spline\",\r\n                hcaes(x = agyears, y = 10^.fitted),\r\n                color = \"black\",\r\n                lineWidth = 1,\r\n                marker = FALSE,\r\n                enableMouseTracking = FALSE)\r\n\r\n\r\n\r\nThere is another reason why it makes more sense to use economic development as of 1500 rather than as of today. If geography shapes economic destinies, then how do we account for countries whose peoples are, in the grand scale of things, relative newcomers to the environments they now inhabit? These include European migrants to the New World as well as African slaves forcibly transported to New World colonies. If it takes thousands of years for geography to shape human cultures and institutions, then an English colonist who settled in what is now the United States would have been influenced by English rather than American geography.\r\nIn short, one must take into account the historical composition of a given country’s population when correlating geographic factors to contemporary development. This motivates the World Migration Matrix constructed by Louis Putterman and David N. Weil, which, for 165 countries, gives “an estimate of the proportion of the ancestors in 1500 of that country’s population today that were living within what are now the borders of that and each of the other countries”. To take one example, among the present-day inhabitants of Cuba, Putterman and Weil estimate that 63% of their ancestors originate from Spain, 5.6% from Nigeria, 5.1% from Ghana, 4.9% from Angola, and so on. Cuba today would exhibit the effects of the weighted average of all these different geographies.\r\nThe following map shows the countries with the highest proportion of “immigrants” relative to their present-day populations. In countries like Australia, Singapore, Taiwan, and Jamaica, very few of their current citizens have ancestors that were living in that country in 1500. On the opposite extreme are countries like China, Japan, Algeria, and Greece.\r\n\r\n\r\nShow code\r\n\r\nlibrary(readxl)\r\nlibrary(countrycode)\r\n\r\nmm <- read_excel(\"matrix version 1.1.xls\") %>%\r\n  pivot_longer(cols = !c(wbcode, wbname),\r\n               names_to = \"ancestry\",\r\n               values_to = \"share\") %>%\r\n  mutate(ancestry = toupper(ancestry)) %>%\r\n  filter(wbcode == ancestry) %>%\r\n  mutate(immigrant = 1 - share,\r\n         iso_3 = countrycode(wbcode, \"wb\", \"iso3c\")) %>%\r\n  select(iso_3, wbname, immigrant)\r\n\r\nmm$iso_3[mm$wbname == \"Congo, Dem. Rep.\"] <- \"COD\"\r\nmm$iso_3[mm$wbname == \"East Timor\"] <- \"TLS\"\r\nmm$iso_3[mm$wbname == \"Romania\"] <- \"ROU\"\r\nmm$iso_3[mm$wbname == \"Taiwan, China\"] <- \"TWN\"\r\n\r\nformattp <- JS(\"function() {\r\n  if (this.point.value < 0.01) {\r\n    return '<b>' + this.point.name + '<\/b>: <0.01';\r\n  }\r\n  else {\r\n    if (this.point.value > 0.99) {\r\n      return '<b>' + this.point.name + '<\/b>: >0.99';\r\n    }\r\n    else {\r\n      return '<b>' + this.point.name + '<\/b>: ' + Highcharts.numberFormat(this.point.value, 2);\r\n    }\r\n  }\r\n}\")\r\n\r\nhcmap(map = \"custom/world-highres3\", \r\n      data = mm,\r\n      name = \"Share of population that arrived after 1500\",\r\n      value = \"immigrant\",\r\n      borderWidth = .5,\r\n      joinBy = c(\"iso-a3\", \"iso_3\")) %>%\r\n  hc_legend(align = \"left\",\r\n            title = list(text = \"Share of population that arrived after 1500\")) %>%\r\n  hc_mapNavigation(enabled = TRUE) %>%\r\n  hc_tooltip(headerFormat = \"\",\r\n             formatter = formattp)\r\n\r\n\r\n\r\nApplying an “ancestry adjustment” to the Diamond hypothesis makes a significant difference. The first chart below plots GDP per capita today and the years since the Neolithic Revolution. There is a positive correlation, albeit a weak one. The second chart plots GDP per capita against the ancestry-adjusted years since the Neolithic Revolution. Doing this strengthens the correlation. This suggests that (1) people were shaped by their environment, and (2) they brought their cultures and institutions with them during the great post-1500 migrations.\r\n\r\nUnadjusted\r\n\r\n\r\nShow code\r\n\r\ndf1 <- df  %>%\r\n  select(country, rgdpch_2005, agyears) %>%\r\n  drop_na() %>%\r\n  mutate(rgdpch_2005_pretty = pretty(rgdpch_2005, 0),\r\n         agyears_pretty = pretty(agyears, 0))\r\n\r\nfit <- lm(log10(rgdpch_2005) ~ agyears, data = df1) %>%\r\n  augment() %>%\r\n  arrange(agyears) %>%\r\n  slice(c(1, nrow(df1)))\r\n\r\nx <- c(\"Country\", \"GDP per capita\", \"Years since Neolithic Revolution\")\r\ny <- c(\"{point.country:s}\", \"${point.rgdpch_2005_pretty:s}\", \"{point.agyears_pretty:s}\")\r\ntltip <- tooltip_table(x, y)\r\n\r\nhchart(df1, \"scatter\", \r\n       hcaes(x = agyears, y = rgdpch_2005),\r\n       color = hex_to_rgba(\"#1046b1\", 0.5),\r\n       size = 20,\r\n       stickyTracking = FALSE) %>%\r\n  hc_xAxis(title = list(text = \"Years since Neolithic Revolution\"),\r\n           gridLineWidth = 1,\r\n           min = 0, max = 11000) %>%\r\n  hc_yAxis(title = list(text = \"GDP per capita 2005\"),\r\n           type = \"logarithmic\", \r\n           gridLineWidth = 1) %>%\r\n  hc_tooltip(useHTML = TRUE,\r\n             pointFormat = tltip,\r\n             headerFormat = \"\") %>%\r\n  hc_add_series(data = fit, \r\n                type = \"spline\",\r\n                hcaes(x = agyears, y = 10^.fitted),\r\n                color = \"black\",\r\n                lineWidth = 1,\r\n                marker = FALSE,\r\n                enableMouseTracking = FALSE)\r\n\r\n\r\n\r\nAncestry-adjusted\r\n\r\n\r\nShow code\r\n\r\ndf1 <- df  %>%\r\n  select(country, rgdpch_2005, adjagyears) %>%\r\n  drop_na() %>%\r\n  mutate(rgdpch_2005_pretty = pretty(rgdpch_2005, 0),\r\n         adjagyears_pretty = pretty(adjagyears, 0))\r\n\r\nfit <- lm(log10(rgdpch_2005) ~ adjagyears, data = df1) %>%\r\n  augment() %>%\r\n  arrange(adjagyears) %>%\r\n  slice(c(1, nrow(df1)))\r\n\r\nx <- c(\"Country\", \"GDP per capita\", \"Years since Neolithic Revolution\")\r\ny <- c(\"{point.country:s}\", \"${point.rgdpch_2005_pretty:s}\", \"{point.adjagyears_pretty:s}\")\r\ntltip <- tooltip_table(x, y)\r\n\r\nhchart(df1, \"scatter\", \r\n       hcaes(x = adjagyears, y = rgdpch_2005),\r\n       color = hex_to_rgba(\"#1046b1\", 0.5),\r\n       size = 20,\r\n       stickyTracking = FALSE) %>%\r\n  hc_xAxis(title = list(text = \"Years since Neolithic Revolution (ancestry-adjusted)\"),\r\n           gridLineWidth = 1,\r\n           min = 0, max = 11000) %>%\r\n  hc_yAxis(title = list(text = \"GDP per capita 2005\"),\r\n           type = \"logarithmic\", \r\n           gridLineWidth = 1) %>%\r\n  hc_tooltip(useHTML = TRUE,\r\n             pointFormat = tltip,\r\n             headerFormat = \"\") %>%\r\n  hc_add_series(data = fit, \r\n                type = \"spline\",\r\n                hcaes(x = adjagyears, y = 10^.fitted),\r\n                color = \"black\",\r\n                lineWidth = 1,\r\n                marker = FALSE,\r\n                enableMouseTracking = FALSE)\r\n\r\n\r\n\r\n\r\nThe correlations above provide pretty fascinating insights. But they are all flawed, of course. Countries are not random realizations of a well-defined stochastic process. Nor are they equal: when generalizing about long-run economic development, it’s not clear that the experiences of a Singapore or a Cape Verde should hold equal weight to the experiences of an India or a China. Which are the exceptions and which are the rules? Do rules even exist?\r\nThe field of empirical economic history has done much to extend, refine, and qualify the basic results shown here. Hopefully I’ll write about them in future posts.\r\n\r\nTen years later and I still don’t have clear answers.↩︎\r\n",
    "preview": "posts/2022-11-25-roots/ancestry.jpg",
    "last_modified": "2022-11-29T12:25:17+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-19-the-emotional-shape-of-novels/",
    "title": "The emotional shape of novels",
    "description": "Using sentiment analysis, I chart the emotional highs and lows of three classic novels",
    "author": [],
    "date": "2022-11-19",
    "categories": [],
    "contents": "\r\nNovels can take you for such a ride.\r\nToday I’m experimenting with sentiment analysis on some novels I’ve recently read. I’ll be using tidytext with data from gutenbergr (i.e. Project Gutenberg), which means I’m restricted to the classics. I read three this year: Swann’s Way by Marcel Proust, Tess of the d’Urbervilles by Thomas Hardy, and The Age of Innocence by Edith Wharton.\r\nQuick review of each. (1) It takes a certain mood to be reading Proust. I got through Within a Budding Grove but found halfway through that oops I’m not in the mood anymore, so I stopped searching for that lost time. (2) While I enjoyed Hardy’s Far from the Madding Crowd, Tess was such an unrelenting depression parade that I was feeling numb by the end of it. (3) Ah, Age of Innocence is one of my all-time favorites. I have been, at various points in my life, Newland, Ellen, and May. My God, I might have even been a Julius Beaufort.\r\nLet’s load up these works.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\nlibrary(gutenbergr)\r\n\r\n# Get the IDs\r\ngutenberg_works(title %in% c(\"Swann's Way\", \r\n                             \"Tess of the d'Urbervilles: A Pure Woman\", \r\n                             \"The Age of Innocence\"))\r\n\r\n# A tibble: 3 × 8\r\n  gutenberg_id title     author guten…¹ langu…² guten…³ rights has_t…⁴\r\n         <int> <chr>     <chr>    <int> <chr>   <chr>   <chr>  <lgl>  \r\n1          110 Tess of … Hardy…      23 en      Banned… Publi… TRUE   \r\n2          541 The Age … Whart…     104 en      Movie … Publi… TRUE   \r\n3         7178 Swann's … Prous…     987 en      <NA>    Publi… TRUE   \r\n# … with abbreviated variable names ¹​gutenberg_author_id, ²​language,\r\n#   ³​gutenberg_bookshelf, ⁴​has_text\r\n\r\nbooks <- gutenberg_download(c(110, 541, 7178)) %>%\r\n  filter(text != \"\") %>%\r\n  group_by(gutenberg_id) %>%\r\n  mutate(line = row_number()) %>%\r\n  ungroup() %>%\r\n  left_join(tibble(gutenberg_id = c(110, 541, 7178),\r\n                   title = c(\"Tess of the d'Urbervilles\", \r\n                             \"The Age of Innocence\", \r\n                             \"Swann's Way\"))) %>%\r\n  select(title, line, text)\r\n\r\n\r\nLines refer to lines on the printed page. What I want to do is split each work into 100 equal sized groups of lines, quantify the sentiment of each, and map the emotional shape of the novel. I’m using the AFINN lexicon, which assigns a score between -5 and 5 to about 2500 English words. More negative scores imply more negative sentiments, and vice nersa.\r\nThe following code breaks up the works so that each row corresponds to one word. Uninteresting words like “the” are removed with anti_join(stop_words). The remaining words are then assigned a sentiment score according to AFINN.\r\n\r\n\r\nbooks_df <- books %>%\r\n  unnest_tokens(word, text) %>%\r\n  anti_join(stop_words) %>%\r\n  inner_join(get_sentiments(\"afinn\"))\r\n\r\n\r\nLet’s try it out first with Tess. It has 13,776 lines, so I split it into 100 chunks of 138 lines.\r\n\r\n\r\n\r\nIt worked! But the chart is ugly! The problem is that net sentiment swings so wildly up and down from chunk to chunk that the result looks more like a seismograph than the “shape” of the novel.\r\nLet’s try a different approach. When you read a chapter and it’s a happy one, you enter the next chapter starting from a position of positive sentiment. Then maybe the next chapter is a sad one, so it brings down your overall sentiment back to something like neutral. The point is, the emotional weight of a novel builds, it doesn’t reset every chapter. Working off this idea, let’s try and map cumulative sentiment across the novel instead of the isolated sentiment of each chunk.\r\nThe chart that works best for this is a waterfall chart, for which the waterfalls package will be helpful.\r\n\r\n\r\nlibrary(waterfalls)\r\n\r\ntess <- tess %>%\r\n  mutate(chunk = factor(chunk),\r\n         fill = ifelse(sentiment >= 0, \"#1046b1\", \"#d1241a\"))\r\n\r\nwf <- waterfall(tess, \r\n                rect_width = 1, \r\n                rect_border = NA, \r\n                rect_text_labels = rep(NA, nrow(tess)),\r\n                draw_axis.x = \"none\",\r\n                fill_by_sign = FALSE, \r\n                fill_colours = tess$fill) + \r\n  geom_hline(yintercept = 0, color = \"gray50\", size = .5, linetype = \"dashed\") + \r\n  scale_y_continuous(name = \"Sentiment (AFINN lexicon)\") + \r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(axis.title = element_blank(),\r\n        axis.title.x = element_blank(),\r\n        axis.title.y = element_text(size = 12, margin = margin(r = 10)),\r\n        axis.text.x = element_blank(),\r\n        axis.text.y = element_text(size = 12),\r\n        axis.ticks = element_blank(),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major = element_blank(),\r\n        panel.grid.minor = element_blank())\r\nwf\r\n\r\n\r\n\r\nNow the shape is more discernible. You can see the ups and downs of Tess’ life (it’s mostly downs). By the end of the book, you are at about a -600 sentiment score.\r\nFor a bit of extra fanciness let’s annotate the chart with the book’s title, author, and cover, the last one taken from Goodreads.\r\n\r\n\r\nlibrary(cowplot)\r\nlibrary(magick)\r\n\r\nggdraw(wf) + \r\n  draw_image(\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1543250144l/42959097._SY475_.jpg\",\r\n             x = .15, y = .1, halign = 0, valign = 0, scale = .4) + \r\n  draw_label(\"Tess of the d'Urbervilles\",\r\n             x = .15 + .16, y = .1 + .17, hjust = 0, vjust = .5, \r\n             size = 14, fontfamily = \"karla\", fontface = \"bold\") + \r\n  draw_label(\"by Thomas Hardy\",\r\n             x = .15 + .16, y = .1 + .10, hjust = 0, vjust = .5, \r\n             size = 12, fontfamily = \"karla\")\r\n\r\n\r\n\r\nLet’s do the same for The Age of Innocence.\r\n\r\n\r\nShow code\r\n\r\nage <- books_df %>%\r\n  filter(title == \"The Age of Innocence\") %>%\r\n  group_by(chunk = line %/% 94) %>% \r\n  summarise(sentiment = sum(value)) %>%\r\n  mutate(chunk = factor(chunk),\r\n         fill = ifelse(sentiment >= 0, \"#1046b1\", \"#d1241a\"))\r\n\r\nwf <- waterfall(age, \r\n                rect_width = 1, \r\n                rect_border = NA, \r\n                rect_text_labels = rep(NA, nrow(age)),\r\n                draw_axis.x = \"none\",\r\n                fill_by_sign = FALSE, \r\n                fill_colours = age$fill) + \r\n  geom_hline(yintercept = 0, color = \"gray50\", size = .5, linetype = \"dashed\") + \r\n  scale_y_continuous(name = \"Sentiment (AFINN lexicon)\") + \r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(axis.title = element_blank(),\r\n        axis.title.x = element_blank(),\r\n        axis.title.y = element_text(size = 12, margin = margin(0, 10, 0, 0)),\r\n        axis.text.x = element_blank(),\r\n        axis.text.y = element_text(size = 11),\r\n        axis.ticks = element_blank(),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major = element_blank(),\r\n        panel.grid.minor = element_blank())\r\n\r\nggdraw(wf) + \r\n  draw_image(\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1320402548l/545294.jpg\",\r\n             x = .53, y = .18, halign = 0, valign = 0, scale = .4) + \r\n  draw_label(\"The Age of Innocence\",\r\n             x = .53 + .16, y = .18 + .17, hjust = 0, vjust = .5, \r\n             size = 14, fontfamily = \"karla\", fontface = \"bold\") + \r\n  draw_label(\"by Edith Wharton\",\r\n             x = .53 + .16, y = .18 + .10, hjust = 0, vjust = .5, \r\n             size = 12, fontfamily = \"karla\")\r\n\r\n\r\n\r\nIt’s a reasonably happy ride for the first half of the novel as we follow Madame Olenska’s disruptions of the self-satisfied New York upper-class society of the 19th century. The turning point is right about where Newland Archer decides not to call her from up the hill. There’s a steady descent as passions clash with idealistic notions of the world before ending on a bittersweet note. You end the book on a net positive, and all in all I’d say that makes sense.\r\nFinally, here is Swann’s Way.\r\n\r\n\r\nShow code\r\n\r\nswann <- books_df %>%\r\n  filter(title == \"Swann's Way\") %>%\r\n  group_by(chunk = line %/% 159) %>% \r\n  summarise(sentiment = sum(value)) %>%\r\n  mutate(chunk = factor(chunk),\r\n         fill = ifelse(sentiment >= 0, \"#1046b1\", \"#d1241a\"))\r\n\r\nwf <- waterfall(swann, \r\n                rect_width = 1, \r\n                rect_border = NA, \r\n                rect_text_labels = rep(NA, nrow(swann)),\r\n                draw_axis.x = \"none\",\r\n                fill_by_sign = FALSE, \r\n                fill_colours = swann$fill) + \r\n  geom_hline(yintercept = 0, color = \"gray50\", size = .5, linetype = \"dashed\") + \r\n  scale_y_continuous(name = \"Sentiment (AFINN lexicon)\") + \r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(axis.title = element_blank(),\r\n        axis.title.x = element_blank(),\r\n        axis.title.y = element_text(size = 12, margin = margin(0, 10, 0, 0)),\r\n        axis.text.x = element_blank(),\r\n        axis.text.y = element_text(size = 11),\r\n        axis.ticks = element_blank(),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major = element_blank(),\r\n        panel.grid.minor = element_blank())\r\n\r\nggdraw(wf) + \r\n  draw_image(\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1657565006l/133539._SY475_.jpg\",\r\n             x = .15, y = .3, halign = 0, valign = 0, scale = .4) + \r\n  draw_label(\"Swann's Way\",\r\n             x = .15 + .16, y = .3 + .17, hjust = 0, vjust = .5, \r\n             size = 14, fontfamily = \"karla\", fontface = \"bold\") + \r\n  draw_label(\"by Marcel Proust\",\r\n             x = .15 + .16, y = .3 + .10, hjust = 0, vjust = .5, \r\n             size = 12, fontfamily = \"karla\")\r\n\r\n\r\n\r\nThis one surprised me. Odette’s unending torment of Swann didn’t strike me as particularly happy? I guess this demonstrates the limitations of literal-minded approaches to coding sentiments. If the work is heavy on irony, a word-based lexicon like AFINN wouldn’t really be able to catch that.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-19-the-emotional-shape-of-novels/shape-of-novels_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2022-12-23T16:31:07+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 768
  },
  {
    "path": "posts/2022-11-15-ftx/",
    "title": "That FTX balance sheet",
    "description": "SBF shops around for investors with a balance sheet that is emphatically not GAAP",
    "author": [],
    "date": "2022-11-15",
    "categories": [],
    "contents": "\r\nI was reading Matt Levine’s entertaining walkthrough of the FTX balance sheet and I thought it’d be fun to visualize this, um, unique financial document. FTX is a crypto exchange that collapsed spectacularly last week. There are already plans for a movie adaptation and I hope Sorkin and Fincher reunite for it.\r\nThe balance sheet in question is dated 10 November and appears to have been constructed by SBF himself. It sent prospective investors running the other way. Per Levine: “It’s an Excel file full of the howling of ghosts and the shrieking of tortured souls. If you look too long at that spreadsheet, you will go insane.”\r\nFor this visualization, I want to show the assets and liabilities in two bars, with the assets bar broken down into the various weird things that FTX counted as assets. I will be employing a lot of visual trickery in this chart and I’d like to walk you through my process.\r\nFirst, here is how I gathered the numbers into a dataset. Doing it in this “long” format makes it easier to chart.\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\ndf <- read_csv(\"ftx.csv\")\r\ndf\r\n\r\n# A tibble: 12 × 3\r\n   group1      group2            billions\r\n   <chr>       <chr>                <dbl>\r\n 1 liabilities total                8.86 \r\n 2 assets      total                9.58 \r\n 3 assets      liquid               0.900\r\n 4 assets      liquid-robinhood     0.472\r\n 5 assets      liquid-others        0.428\r\n 6 assets      lessliquid           5.45 \r\n 7 assets      lessliquid-ftt       0.554\r\n 8 assets      lessliquid-serum     2.19 \r\n 9 assets      lessliquid-sol       0.982\r\n10 assets      lessliquid-maps      0.616\r\n11 assets      lessliquid-others    1.11 \r\n12 assets      illiquid             3.23 \r\n\r\nHere’s a first stab:\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\ndf1 <- df %>%\r\n  filter(group2 %in% c(\"total\", \"liquid\", \"lessliquid\", \"illiquid\"), !(group1 == \"assets\" & group2 == \"total\"))\r\n  \r\nggplot(df1, aes(x = group1, y = billions, fill = group2)) + \r\n  geom_bar(stat = \"identity\", position = \"stack\") + \r\n  theme(axis.title = element_blank(),\r\n        axis.text.y = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        panel.background = element_blank(),\r\n        panel.grid = element_blank())\r\n\r\n\r\n\r\nAtrocious but you get the idea.\r\nI’m going to annotate these bars with subcategories of interest, so I’ll need some space on the sides. To get this, I’ll add phantom categories to the “group1” column.\r\n\r\n\r\ndf1 <- df1 %>%\r\n  bind_rows(tibble(group1 = c(\"space_l\", \"space_r\"), \r\n                   group2 = \"total\", value = 0)) %>%\r\n  mutate(group1 = factor(group1, levels = c(\"space_l\", \"assets\", \"liabilities\", \"space_r\")))\r\n\r\nplot <- ggplot(df1, aes(x = group1, y = billions, fill = group2)) + \r\n  geom_bar(stat = \"identity\", position = \"stack\", width = .7) + \r\n  theme(axis.title = element_blank(),\r\n        axis.text.y = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        panel.background = element_blank(),\r\n        panel.grid = element_blank())\r\nplot\r\n\r\n\r\n\r\nFor the annotations, we will be using geom_rect(), geom_segment(), annotate(), and a significant amount of trial and error. Let me demonstrate by annotating the portion of the “less liquid” assets that comprise the stuff FTX “made up” (FTT, SRM, SOL, and MAPS tokens). We’ll first need to identify some coordinates in the plot space:\r\n\r\n\r\nh1 <- df$billions[df$group2 == \"liquid\"]\r\nh2 <- h1 + df$billions[df$group2 == \"lessliquid\"]\r\nh3 <- h1 + df$billions[df$group2 == \"lessliquid-others\"]\r\nh4 <- df$billions[df$group1 == \"assets\" & df$group2 == \"total\"]\r\n\r\n\r\nNow we add to the plot:\r\n\r\n\r\nbw <- .35\r\n\r\nplot + \r\n  geom_rect(xmin = 2 - bw, xmax = 2 + bw, ymin = h3, ymax = h2, \r\n            data = df1[1, ], fill = NA, color = \"black\") + \r\n  geom_segment(x = 2 - bw, xend = 2 - 1.5 * bw, y = h2 - 1, yend = h2 - .8, \r\n               color = \"black\") +\r\n  annotate(\"text\", x = 2 - 1.8 * bw, y = h2 - .65, hjust = 1,\r\n           label = \"Stuff we made up\")\r\n\r\n\r\n\r\nNote that all the positioning values were discovered through trial and error. So if you’re doing something like this, try and organize your values around fundamental constants of the chart. For example, bw here is half the width of the bars.\r\nNow let’s add all the other annotations, and while we’re at it let’s tweak the aesthetics of the chart. There’s also the question of where to place the 8-billion-dollar “hidden, poorly internally labeled ‘fiat@’ account”. No one’s really sure what to do with this. Writes Matt Levine:\r\n\r\nIf you try to calculate the equity of a balance sheet with an entry for HIDDEN POORLY INTERNALLY LABELED ACCOUNT, Microsoft Clippy will appear before you in the flesh, bloodshot and staggering, with a knife in his little paper-clip hand, saying “just what do you think you’re doing Dave?” You cannot apply ordinary arithmetic to numbers in a cell labeled “HIDDEN POORLY INTERNALLY LABELED ACCOUNT.” The result of adding or subtracting those numbers with ordinary numbers is not a number; it is prison.\r\n\r\nGiven this expert advice, I’ve decided to give it its own accurately sized bar that kind of just hovers over the liabilities bar, like a ghoul.\r\nHere’s the final chart:\r\n\r\n\r\nShow code\r\n\r\nggplot(df1, aes(x = group1, y = billions, fill = group2)) + \r\n  geom_bar(stat = \"identity\", position = \"stack\", width = .7) + \r\n  \r\n  # Hidden poorly internally labeled account\r\n  geom_rect(xmin = 3-.8 * bw, xmax = 3+1.2*bw, ymin = 1.2, ymax = 1.2+8, \r\n            data = df1[1, ], fill = \"gray80\", alpha = .5) + \r\n  annotate(\"text\", x = 3-1.1*bw, y = 8+1.45, family = \"karla\", size = 10/.pt, vjust = 0, hjust = 0, color = \"gray50\",\r\n           label = \"Hidden, poorly internally labeled account: -$8 billion\") + \r\n  \r\n  # Robinhood shares\r\n  geom_rect(xmin = 2-bw, xmax = 2+bw, ymin = h1-.472, ymax = h1, \r\n            data = df1[1, ], fill = NA, color = \"black\", linewidth = 1) + \r\n  geom_segment(x = 2-bw, xend = 2-1.4 * bw, y = h1-.472/2, yend = h1-.4, \r\n               linewidth = .5, color = \"black\") +\r\n  annotate(\"text\", x = 2-1.6*bw, y = h1-.4, family = \"karla\", size = 12/.pt, hjust = 1,\r\n           label = \"Robinhood shares\") + \r\n  \r\n  # Stuff we made up\r\n  geom_rect(xmin = 2-bw, xmax = 2+bw, ymin = h3, ymax = h2, \r\n            data = df1[1, ], fill = NA, color = \"black\", linewidth = 1) + \r\n  geom_segment(x = 2-bw, xend = 2-1.4*bw, y = h2-.9, yend = h2-.76, \r\n               linewidth = .5, color = \"black\") +\r\n  annotate(\"text\", x = 2-1.6*bw, y = h2-.6, family = \"karla\", size = 12/.pt, hjust = 1,\r\n           label = \"Stuff we made up\") + \r\n  \r\n  # TRUMPLOSE\r\n  geom_rect(xmin = 2-.8*bw, xmax = 2-.7*bw, ymin = h4-1.15, ymax = h4-1, \r\n            data = df1[1, ], fill = NA, color = \"black\", linewidth = 1) + \r\n  geom_segment(x = 2-.8*bw, xend = 2-1.5*bw, y = h4-1.075, yend = h4-1.2, \r\n               linewidth = .5, color = \"black\") +\r\n  annotate(\"text\", x = 2-1.7*bw, y = h4-1.15, family = \"karla\", size = 12/.pt, hjust = 1,\r\n           label = \"TRUMPLOSE\") + \r\n  \r\n  # Labels and legend\r\n  labs(title = \"There were many things I wish I could do differently than I did\", \r\n       caption = \"Note: all of these are rough values and could be slightly off; there is also obviously a chance of typos etc.\") + \r\n  scale_fill_manual(labels = c(\"Illiquid: $3.2bn\", \"Less liquid: $5.4bn\", \"Liquid: $900mn\", \"\"), \r\n                    values = c(\"#a4b1ff\", \"#6679d8\", \"#1046b1\", \"#d1241a\")) + \r\n  scale_x_discrete(labels = c(\"\", \"Assets\\n\\\"$9.6bn\\\"\", \"Liabilities\\n-$8.9bn\", \"\")) +\r\n  guides(fill = guide_legend(keywidth = unit(.8, \"lines\"),\r\n                             keyheight = unit(.8, \"lines\"),\r\n                             byrow = TRUE,\r\n                             override.aes = list(alpha = c(1, 1, 1, 0)))) + \r\n  \r\n  # Theme\r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(plot.title = element_text(size = 16, face = \"bold\", hjust = .5, margin = margin(b = 10)),\r\n        plot.caption = element_text(size = 10, hjust = .5, margin = margin(t = 15)),\r\n        axis.title = element_blank(),\r\n        axis.text.x = element_text(size = 14, color = \"black\", margin = margin(t = 8)),\r\n        axis.text.y = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        legend.position = c(.02, .45),\r\n        legend.background = element_blank(),\r\n        legend.justification = c(0, 1),\r\n        legend.title = element_blank(),\r\n        legend.text = element_text(size = 12),\r\n        legend.spacing.y = unit(.4, \"lines\"),\r\n        legend.key = element_blank(),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid = element_blank())\r\n\r\n\r\n\r\nI think this exercise really brings out the “grid” nature of ggplot. It may be painstaking but as long as you can place your rectangle or line or textbox in the x-y coordinate system, you can modify your chart in all sorts of fun ways.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-15-ftx/ftx_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2022-12-23T11:11:02+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 960
  },
  {
    "path": "posts/2022-11-13-elon/",
    "title": "Visualizing Elon Musk's Twitter addiction",
    "description": "The world's busiest billionaire finds the time to tweet at all hours of the day",
    "author": [],
    "date": "2022-11-13",
    "categories": [],
    "contents": "\r\nElon Musk tweets a lot. Like, a lot. We can quantify it using this Kaggle dataset that contains all of Musk’s tweets between 27 January and 27 October 2022.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\nlibrary(ggplot2)\r\n\r\ndf <- read_csv(\"rawdata.csv\") %>%\r\n  arrange(Date) %>%\r\n  mutate(hour(Date) <- hour(Date) + 1)\r\n\r\n# Switch from UTC to UTC-6 (Texas)\r\nhour(df$Date) <- hour(df$Date) - 6\r\n\r\ndf <- df %>%\r\n  mutate(date = date(Date),\r\n         hour = hour(Date),\r\n         gap = difftime(Date, lag(Date), units = \"mins\"))\r\n\r\n# Tweets per day: nrow(df) / as.numeric(as.Date(\"2022-10-27\") - as.Date(\"2022-01-27\"))\r\n# Average time between tweets: mean(df$gap[-1])\r\n\r\n\r\nThe timestamps were in UTC, but since Musk seems to reside mostly in Texas, I switched the time zone to UTC-6.\r\nDuring this 10-month period, Musk sent out about 11 tweets per day. Put another way, he tweeted every 2 hours and 8 minutes for 10 months. Some of the tweets dabble in great power diplomacy, some are poop emojis.\r\nLooking at the sheer volume of tweets Musk produces, I got to wondering: when does this guy work? Elon Musk is famously a workaholic who claims to work 80-90 hours a week. But… is he just tweeting the whole time? Let’s investigate.\r\nFirst let’s chart his tweets per day to see what we’re dealing with.\r\n\r\n\r\nShow code\r\n\r\nggplot(df %>% count(date), aes(x = date, y = n)) + \r\n  geom_bar(stat = \"identity\", width = 1, fill = \"#1046b1\") +\r\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\") + \r\n  scale_y_continuous(breaks = c(0, 20, 40)) + \r\n  theme(axis.title = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\r\n        axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\r\n        panel.background = element_rect(fill = \"gray97\"),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nInterestingly, Musk does take breaks from time to time, like a 10-day stretch in late June. Maybe work picked up?\r\nNow let’s plot an hourly histogram of his tweets.\r\n\r\n\r\nShow code\r\n\r\nggplot(df, aes(x = hour)) +\r\n  geom_histogram(aes(y = after_stat(density)), \r\n                 binwidth = 1, fill = \"#1046b1\", color = \"gray97\", linewidth = 2) + \r\n  scale_x_continuous(breaks = 0:23) + \r\n  scale_y_continuous(labels = function(x) paste0(100 * x, \"%\")) + \r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(axis.title = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\r\n        axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_line(color = \"white\"),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nWow. It looks like he tweets at pretty much all waking hours of the day. He also seems to not be getting much sleep, with the lull in tweets spanning just 3am to 6am.\r\nLooking through the dataset, what’s more remarkable is that most of his tweets are replies to other tweets. Anyone can tweet 11 tweets per day, but what Musk is doing involves actually browsing Twitter, reading other people’s tweets, and reacting to them. Constantly. All day. Everyday. I suppose an argument can be made that one so thoroughly immersed in the platform (to the point of crippling addiction) is actually well-placed to run said platform. But an argument can also be made that no, what, are you crazy, that’d be a horrible idea.\r\nHere’s a fun data viz exercise to end. Let’s color the bars according to the time of day, with nighttime in blue and daytime in yellow.\r\n\r\n\r\ndaycolors <- c(rep(\"#1046b1\", 5),  # 12am to 4am\r\n               rep(\"#9696d2\", 3),  # 5am to 7am\r\n               rep(\"#ffa600\", 12), # 8am to 7pm\r\n               rep(\"#9696d2\", 3),  # 8pm to 10pm\r\n               rep(\"#1046b1\", 1))  # 11pm\r\n\r\nggplot(df, aes(x = hour)) +\r\n  geom_histogram(aes(y = after_stat(density)), \r\n                 binwidth = 1, fill = daycolors, color = \"gray97\", linewidth = 2.5) + \r\n  labs(title = \"Hourly distribution of Elon Musk's tweets\",\r\n       subtitle = \"January to October 2022\") + \r\n  scale_x_continuous(breaks = 0:23, \r\n                     label = paste0(c(12, 1:12, 1:11), \":00\")) + \r\n  scale_y_continuous(labels = function(x) paste0(100 * x, \"%\")) + \r\n  theme_minimal(base_family = \"karla\") +\r\n  theme(plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\r\n        plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(0, 0, 15, 0)),\r\n        axis.title = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        axis.text.x = element_text(size = 12, angle = 90, hjust = 1, vjust = .5, margin = margin(5, 0, 0, 0)),\r\n        axis.text.y = element_text(size = 12, margin = margin(0, 5, 0, 0)),\r\n        legend.position = \"none\",\r\n        panel.background = element_rect(fill = \"gray97\", color = NA),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_line(color = \"white\"),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-13-elon/elon_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2022-12-23T16:35:10+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 864
  },
  {
    "path": "posts/2022-11-10-dual-wield/",
    "title": "Should you dual wield y axes?",
    "description": "Points to keep in mind when resorting to a secondary axis",
    "author": [],
    "date": "2022-11-10",
    "categories": [],
    "contents": "\r\nConsider this: all charts are essentially squiggles on a Cartesian plane. There’s a horizontal, or x, axis and there’s a vertical, or y, axis. This implies that the underlying datasets ever only need two columns, corresponding to the two axes. Many chart enthusiasts seem to be guided by this principle, which is why they detest charts that violate this setup, like pie charts.\r\nAnother chart that maybe violates this setup are those with two different y axes, or dual axis charts. These are very popular. Today, Planning Secretary Arsenio Balisacan accompanied his tweet on the Philippine third quarter GDP numbers with this chart:\r\n\r\n\r\n\r\n\r\n\r\n\r\nWhat’s wrong with it?\r\nThe first problem is that there isn’t really a reason why it has to be a dual axis chart at all. The level of real GDP is not meaningful to most people and visualizing it doesn’t provide much insight.\r\nThe second problem is that it’s sloppily made. In the legend, “Real GDP” (the bars) is on the left and “GDP growth” (the line) is on the right, so the natural inclination is to use the left axis for the bars and the right axis for the line. But woe to you if you do—the positions are reversed. This is because for “combo charts” in Excel (i.e. where you combine two chart types), bar layers always go first before lines, hence they are listed first in the legend.1 But you can choose which axis the bar series is assigned to, so it should have been assigned to the left one.\r\nMore importantly: the two axes clash. Look at 5.0 on the left axis. If you follow the grid line all the way to the right axis, you get… 4.something. You quickly realize that the grid lines really just mark the axis labels on the left, not the right. The right axis exists in its own parallel grid in the nether regions of the chart. That’s confusing! This is again a trait of Excel. If you tick the check box that puts a series on the secondary axis, it automatically scales its axis independent of the primary axis. So you basically end up with two charts sharing the same x axis superimposed on top of each other.\r\nBelow is my own quick fix of the chart (data source here).\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(tsibble)\r\nlibrary(ggplot2)\r\n\r\ndf <- read_csv(\"phgdp.csv\") %>%\r\n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"), \r\n         quarter = yearquarter(date),\r\n         qtr = as.character(quarter),\r\n         growth = 100 * (gdp / lag(gdp, 4) - 1))\r\n\r\nggplot(subset(df, date >= \"2019-03-01\")) + \r\n  geom_bar(aes(x = qtr, y = gdp / 1000000, fill = \"LHS - Real GDP (in constant 2018 trillion pesos)\"), stat = \"identity\", width = .5) + \r\n  geom_line(aes(x = qtr, y = growth / 5 + 4, color = \"RHS - GDP growth (in %)\"), group = 1, size = 1.5) + \r\n  geom_point(aes(x = qtr, y = growth / 5 + 4, color = \"RHS - GDP growth (in %)\", line = \"RHS - GDP growth (in %)\"), size = 3.5) + \r\n  geom_hline(yintercept = 0, size = .25, color = \"gray25\") + \r\n  scale_fill_manual(values = \"#fcc954\") +\r\n  scale_color_manual(values = \"#0b3f90\") + \r\n  guides(fill = guide_legend(order = 1)) + \r\n  scale_y_continuous(limits = c(0, 7), breaks = 0:7,\r\n                     sec.axis = sec_axis(~ (. - 4) * 5, breaks = seq(-20, 15, 5))) + \r\n  theme(axis.title = element_blank(),\r\n        axis.text.x = element_text(size = 10, angle = 90, margin = margin(-3, 0, 0, 0)),\r\n        axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\r\n        axis.ticks = element_blank(),\r\n        legend.position = \"top\",\r\n        legend.title = element_blank(),\r\n        legend.key = element_blank(),\r\n        legend.key.height = unit(.75, \"lines\"),\r\n        legend.key.width = unit(1.5, \"lines\"),\r\n        legend.text = element_text(size = 11),\r\n        panel.background = element_blank(),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.major.y = element_line(size = .25, color = \"gray85\"),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nThere’s still one last problem with this chart, which is that the right y axis really ought to cross the x axis at zero. Positive growth rates fundamentally differ from negative growth rates, but a quick glance at the chart gives the impression that Philippine growth just took a dip in 2020. But! If you cross the right y axis at zero, the left y axis will have to extend to the negative numbers. This would make no sense for GDP. So there’s the dilemma: one y axis ends up compromising the other. I don’t know if there’s a way to fix this.\r\nI personally don’t have anything against dual axis charts, and I have used them a lot in my work. What I am against are sloppily made charts, and perhaps, by being inherently more complex, sloppiness in dual axis charts tends to be extra noticeable.\r\nOne essential to keep in mind is that both y axes must coexist in the same Cartesian plane, meaning one is just a transformation of the other. In the chart I made, \\(y_{\\text{right}} = ( y_{\\text{left}} - 4 ) \\times 5\\). This is something you manually have to specify in ggplot, making it harder to make dual axis charts there. But that’s by design. Excel makes it too easy, and so you get people hitting that secondary axis check box and calling it a day.\r\n\r\nFor some reason, Excel is adamant that you should never be able to change the order of chart layers, or the order of legend items.↩︎\r\n",
    "preview": "posts/2022-11-10-dual-wield/dual-wield_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-11-29T10:12:19+08:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 768
  },
  {
    "path": "posts/2022-11-08-metro-manila-subway/",
    "title": "Mapping the Metro Manila subway",
    "description": "In a fit of wishful thinking, I use Leaflet to map the Metro Manila subway as if it existed",
    "author": [],
    "date": "2022-11-08",
    "categories": [],
    "contents": "\r\nToday I’ll experiment with making maps via leaflet, which I’m using for the first time. I’m relying mainly on this tutorial.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(leaflet)\r\n\r\n\r\nBelow is a map pointing out some of the planned stations of the future Metro Manila Subway, which will be built… sometime… maybe? Back in June the first tunnel boring machine was “ceremonially lowered” but no digging has actually taken place.\r\nAnyway, I map the stations from Quirino Highway to 11th Avenue in BGC. I got the locations from trawling through news articles and project documents, then I used Google Maps to get their coordinates.\r\n\r\n\r\nleaflet(options = leafletOptions(minZoom = 10, maxZoom = 15)) %>%\r\n  addTiles() %>%\r\n  addMarkers(lng=121.028460, lat=14.689541, label=\"Quirino Highway Station\") %>%\r\n  addMarkers(lng=121.032355, lat=14.676936, label=\"Tandang Sora Station\") %>%\r\n  addMarkers(lng=121.035685, lat=14.654850, label=\"North Avenue Station\") %>%\r\n  addMarkers(lng=121.037591, lat=14.644747, label=\"Quezon Avenue Station\") %>%\r\n  addMarkers(lng=121.051628, lat=14.640692, label=\"East Avenue Station\") %>%\r\n  addMarkers(lng=121.065282, lat=14.627151, label=\"Anonas Station\") %>%\r\n  addMarkers(lng=121.069868, lat=14.613690, label=\"Camp Aguinaldo Station\") %>%\r\n  addMarkers(lng=121.063565, lat=14.588103, label=\"Ortigas Station\") %>%\r\n  addMarkers(lng=121.061238, lat=14.575162, label=\"Shaw Station\") %>%\r\n  addMarkers(lng=121.055859, lat=14.558327, label=\"11th Avenue Station\")\r\n\r\n\r\n\r\nAnd here’s the map! It’s fine? It’s a little busy, so let’s change the map tile from the default OpenStreetMap to a nice minimalist one from this list.\r\n\r\n\r\nleaflet(options = leafletOptions(minZoom = 10, maxZoom = 15)) %>%\r\n  addProviderTiles(providers$CartoDB.Voyager) %>%\r\n  addMarkers(lng=121.028460, lat=14.689541, label=\"Quirino Highway Station\") %>%\r\n  addMarkers(lng=121.032355, lat=14.676936, label=\"Tandang Sora Station\") %>%\r\n  addMarkers(lng=121.035685, lat=14.654850, label=\"North Avenue Station\") %>%\r\n  addMarkers(lng=121.037591, lat=14.644747, label=\"Quezon Avenue Station\") %>%\r\n  addMarkers(lng=121.051628, lat=14.640692, label=\"East Avenue Station\") %>%\r\n  addMarkers(lng=121.065282, lat=14.627151, label=\"Anonas Station\") %>%\r\n  addMarkers(lng=121.069868, lat=14.613690, label=\"Camp Aguinaldo Station\") %>%\r\n  addMarkers(lng=121.063565, lat=14.588103, label=\"Ortigas Station\") %>%\r\n  addMarkers(lng=121.061238, lat=14.575162, label=\"Shaw Station\") %>%\r\n  addMarkers(lng=121.055859, lat=14.558327, label=\"11th Avenue Station\")\r\n\r\n\r\n\r\nNeat. I’ll revisit this later on to see what else I can add.\r\nUpdate 17 November 2022: Transportation Undersecretary Cesar Chavez has said that “the actual excavation is on December 12”. He added: “Actually, this is for real. The excavation is real.” Well, there you have it. The excavation is “real”.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-08-metro-manila-subway/subwaymap.jpg",
    "last_modified": "2022-11-29T10:05:26+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-05-wdi/",
    "title": "Exercises in plotting WDI data",
    "description": "Pull the data with R instead of downloading spreadsheet after spreadsheet",
    "author": [],
    "date": "2022-11-05",
    "categories": [],
    "contents": "\r\nIn the old days I used to download WDI datasets in Excel format and point-and-click my way to a neat little chart. Now I want to try using the WDI package and some ggplot wizardry.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(ggplot2)\r\nlibrary(WDI)\r\n\r\n\r\nTo start, let’s try plotting the GDP per capita of the Philippines and Vietnam in constant 2015 US$.\r\n\r\n\r\ndf <- WDI(country = c(\"PH\",\"VN\"),\r\n          indicator = \"NY.GDP.PCAP.KD\",\r\n          start = 1990) %>% \r\n  as_tibble()\r\n\r\nggplot(df, aes(x = year, y = NY.GDP.PCAP.KD, color = country)) +\r\n  geom_line()\r\n\r\n\r\n\r\nGreat. Now let’s try to get a cleaner chart by removing everything we don’t need: the axis labels, the legend title, the vertical grid lines, the tick marks. Let’s also add a chart title.\r\n\r\n\r\nggplot(df, aes(x = year, y = NY.GDP.PCAP.KD, color = country)) +\r\n  geom_line() +\r\n  labs(title = \"GDP per capita in constant 2015 US$\") +\r\n  theme(axis.title = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        legend.position = \"right\",\r\n        legend.title = element_blank(),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nIt’s a serviceable chart, but not a particularly attractive chart. Let’s spend some more time glamming it up. The numbers on the y-axis could use a thousands separator. The plot lines could be a little thicker. We can also make tweaks to the text sizes, the colors, the margins, and so forth.\r\n\r\n\r\nShow code\r\n\r\nggplot(df, aes(x = year, y = NY.GDP.PCAP.KD, color = country)) +\r\n  geom_line(size = 1) +\r\n  labs(title = \"GDP per capita in constant 2015 US$\") +\r\n  scale_color_manual(values = c(\"#076fe4\", \"#f2500d\")) + \r\n  scale_y_continuous(label = function(x) prettyNum(x, big.mark = \",\", scientific = FALSE)) + \r\n  theme(aspect.ratio = .7,\r\n        axis.title = element_blank(),\r\n        axis.ticks = element_blank(),\r\n        axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\r\n        axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\r\n        plot.title = element_text(size = 12, hjust = .5, face = \"bold\", margin = margin(0, 0, 10, 0)),\r\n        legend.position = \"right\",\r\n        legend.title = element_blank(),\r\n        legend.text = element_text(size = 11),\r\n        panel.background = element_rect(fill = \"gray97\"),\r\n        panel.grid.major.x = element_blank(),\r\n        panel.grid.minor.x = element_blank(),\r\n        panel.grid.minor.y = element_blank())\r\n\r\n\r\n\r\nNow this to me is pleasing to the eye. A document populated with charts like this—as opposed to charts like the first two above—would be much more motivating to read.\r\nHere’s a second exercise. I think one useful way to categorize countries is according to whether they are big and rich, big and poor, small and rich, or small and poor. We can visualize this in a scatterplot with population on one axis and GDP per capita on the other. Let’s load up the data and plot the scatter.\r\n\r\n\r\ndf <- WDI(country = \"all\",\r\n          indicator = c(\"gpc\" = \"NY.GDP.PCAP.KD\", \r\n                        \"pop\" = \"SP.POP.TOTL\"),\r\n          start = 2015,\r\n          end = 2015,\r\n          extra = TRUE) %>% \r\n  as_tibble() %>%\r\n  filter(region != \"Aggregates\") %>%\r\n  select(country, gpc, pop) %>%\r\n  drop_na()\r\n\r\nggplot(df, aes(x = pop, y = gpc)) +\r\n  geom_point()\r\n\r\n\r\n\r\nWhat an atrocious chart! To make it comprehensible, we’ll need to re-express the axes in log scale first.\r\n\r\n\r\nggplot(df, aes(x = log10(pop), y = log2(gpc))) +\r\n  geom_point() + \r\n  scale_x_continuous(name = \"Population\",\r\n                     breaks = c(log10(10^4), log10(10^5), log10(10^6), log10(10^7), log10(10^8), log10(10^9)),\r\n                     label = c(\"10,000\", \"100,000\", \"1 million\", \"10 million\", \"100 million\", \"1 billion\")) +\r\n  scale_y_continuous(name = \"GDP per capita constant 2015 US$\",\r\n                     breaks = c(log2(500), log2(1500), log2(10000), log2(30000)),\r\n                     label = function(x) prettyNum(2^x, big.mark = \",\", scientific = FALSE))\r\n\r\n\r\n\r\nBetter! Let’s make further tweaks to the colors and so on to make it more attractive. In addition, let’s include some dividing lines to group big, small, rich, and poor countries. Some sensible definitions would be that “big” countries are those with 100 million people and above while “rich” countries are those with GDP per capita of $30,000 and above.\r\n\r\n\r\nShow code\r\n\r\nggplot(df, aes(x = log10(pop), y = log2(gpc))) +\r\n  geom_point(shape = 16, size = 3, color = \"#076fe4\") + \r\n  labs(title = \"Big and small, rich and poor\") +\r\n  geom_vline(xintercept = log10(10^8), size = .5, linetype = \"dashed\", color = \"gray50\") +\r\n  geom_hline(yintercept = log2(30000), size = .5, linetype = \"dashed\", color = \"gray50\") + \r\n  scale_x_continuous(name = \"Population\",\r\n                     breaks = c(log10(10^4), log10(10^5), log10(10^6), log10(10^7), log10(10^8), log10(10^9)),\r\n                     label = c(\"10,000\", \"100,000\", \"1 million\", \"10 million\", \"100 million\", \"1 billion\")) +\r\n  scale_y_continuous(name = \"GDP per capita constant 2015 US$\",\r\n                     breaks = c(log2(500), log2(1500), log2(10000), log2(30000)),\r\n                     label = function(x) prettyNum(2^x, big.mark = \",\", scientific = FALSE)) + \r\n  theme(axis.title = element_text(size = 11),\r\n        axis.title.x = element_text(margin = margin(10, 0, 0, 0)),\r\n        axis.title.y = element_text(margin = margin(0, 10, 0, 0)),\r\n        axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\r\n        axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\r\n        axis.ticks = element_blank(),\r\n        plot.title = element_text(size = 12, hjust = .5, face = \"bold\", margin = margin(0, 0, 10, 0)),\r\n        panel.background = element_rect(fill = \"gray97\"),\r\n        panel.grid = element_blank())\r\n\r\n\r\n\r\nAnd here’s the interesting result. Under this set of definitions, there are really only two big and rich countries: the United States and Japan. The biggest small and rich country is Germany, with a population of 82 million, while the richest small and poor country is Mexico, with a GDP per capita of $9,600. In short, no country in the near future is expected to join the big-and-rich club.1\r\nNow let’s make some finishing touches to the chart. First, let’s add the labels “big”, “small”, “rich”, and “poor” on either side of the dashed lines to make it clear what they’re indicating. Second, let’s bold the axis labels “30,000” and “100 million” to highlight the chosen thresholds for bigness and richness. Third, let’s label the points for the U.S., Japan, Germany, and Mexico to facilitate the discussion accompanying the chart. We also highlight these four points by making all other points transparent.\r\n\r\n\r\nShow code\r\n\r\nggplot(df, aes(x = log10(pop), y = log2(gpc))) +\r\n  geom_point(shape = 16, size = 3, color = \"#076fe4\", alpha = ifelse(df$country %in% c(\"United States\", \"Japan\", \"Germany\", \"Mexico\"), 1, .25)) +\r\n  labs(title = \"Big and small, rich and poor\") +\r\n  \r\n  # Dashed lines\r\n  geom_vline(xintercept = log10(10^8), size = .5, linetype = \"dashed\", color = \"gray50\") +\r\n  geom_hline(yintercept = log2(30000), size = .5, linetype = \"dashed\", color = \"gray50\") + \r\n  annotate(\"text\", x = log10(10^8) + .05, y = log2(200000), hjust = 0, label = \"big\", size = 3.5, color = \"gray50\") +\r\n  annotate(\"text\", x = log10(10^8) - .05, y = log2(200000), hjust = 1, label = \"small\", size = 3.5, color = \"gray50\") +\r\n  annotate(\"text\", x = log10(10.5^9), y = log2(30000) + .2, vjust = 0, label = \"rich\", size = 3.5, color = \"gray50\") +\r\n  annotate(\"text\", x = log10(10.5^9), y = log2(30000) - .15, vjust = 1, label = \"poor\", size = 3.5, color = \"gray50\") +\r\n  \r\n  # Highlighted points\r\n  annotate(\"text\", x = log10(df$pop[df$country == \"United States\"]), y = log2(df$gpc[df$country == \"United States\"]) + .4, hjust = 0, vjust = 0, label = \"United States\", size = 3.5, fontface = \"bold\") + \r\n  annotate(\"text\", x = log10(df$pop[df$country == \"Japan\"]) + .1, y = log2(df$gpc[df$country == \"Japan\"]), hjust = 0, vjust = 0, label = \"Japan\", size = 3.5, fontface = \"bold\") + \r\n  annotate(\"text\", x = log10(df$pop[df$country == \"Germany\"]), y = log2(df$gpc[df$country == \"Germany\"]) + .4, hjust = .5, vjust = 0, label = \"Germany\", size = 3.5, fontface = \"bold\") + \r\n  annotate(\"text\", x = log10(df$pop[df$country == \"Mexico\"]), y = log2(df$gpc[df$country == \"Mexico\"]) + .4, hjust = .5, vjust = 0, label = \"Mexico\", size = 3.5, fontface = \"bold\") + \r\n  \r\n  scale_x_continuous(name = \"Population\",\r\n                     breaks = c(log10(10^4), log10(10^5), log10(10^6), log10(10^7), log10(10^8), log10(10^9)),\r\n                     label = c(\"10,000\", \"100,000\", \"1 million\", \"10 million\", \"100 million\", \"1 billion\")) +\r\n  scale_y_continuous(name = \"GDP per capita constant 2015 US$\",\r\n                     breaks = c(log2(500), log2(1500), log2(10000), log2(30000)),\r\n                     label = function(x) prettyNum(2^x, big.mark = \",\", scientific = FALSE)) + \r\n  theme(axis.title = element_text(size = 11),\r\n        axis.title.x = element_text(margin = margin(10, 0, 0, 0)),\r\n        axis.title.y = element_text(margin = margin(0, 10, 0, 0)),\r\n        axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0), face = c(\"plain\", \"plain\", \"plain\", \"plain\", \"bold\", \"plain\")),\r\n        axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0), face = c(\"plain\", \"plain\", \"plain\", \"bold\")),\r\n        axis.ticks = element_blank(),\r\n        plot.title = element_text(size = 12, hjust = .5, face = \"bold\", margin = margin(0, 0, 10, 0)),\r\n        panel.background = element_rect(fill = \"gray97\"),\r\n        panel.grid = element_blank())\r\n\r\n\r\n\r\nAnd here’s the final chart!\r\n\r\nNot that this should be taken too seriously! The thresholds I used are completely arbitrary.↩︎\r\n",
    "preview": "posts/2022-11-05-wdi/wdi_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2022-11-29T09:52:40+08:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
