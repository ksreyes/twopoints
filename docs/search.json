[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About\n\n\n\nHello! My name is Ken.\n\n\n    \n\n\nI work a lot with data, which means I often engage in the fun, frustrating, highly consequential—yet frequently dismissed!—art of data visualization.\n\n\nTwo Points Make a Line documents my journey in mastering this art. I take an interesting dataset and tell a story about it using charts. Along the way, I share my thoughts on what makes a chart work and what doesn’t, the tools I use, and other tidbits. Enjoy!\n\n\n\nSyndicated onR-Bloggers\n\n\n\n\nThis website was built using Quarto in RStudio and published via GitHub Pages. View the source code here. “The Plotting Cats” artwork that peppers the site is by Issa Cruz."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Two Points Make a Line",
    "section": "",
    "text": "Babies and boomers\n\n\nHumanity is rapidly aging everywhere except Africa\n\n\n\n\npython\n\n\nD3/OJS\n\n\n \n\n\n\n\nApr 30, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe tales we tell\n\n\nOur body of folklore can say a lot about our modern-day attitudes and beliefs — for better or worse\n\n\n\n\npython\n\n\nD3/OJS\n\n\n \n\n\n\n\nApr 22, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLearning curves\n\n\nCharts have been aiding — and confusing — students of economics for generations. Give them a fresh twist by adding interactivity.\n\n\n\n\nD3/OJS\n\n\n \n\n\n\n\nApr 14, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThat’ll be ₱1 billion please\n\n\nA bike lane building blitz from the pandemic era offers a glimpse into the Philippine government’s procurement process\n\n\n\n\nR\n\n\nD3/OJS\n\n\n \n\n\n\n\nApr 6, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPeople as particles\n\n\nPopulation density in cities, portrayed more vividly\n\n\n\n\nD3/OJS\n\n\n \n\n\n\n\nMar 29, 2023\n\n\n\n\n\n\n  \n\n\n\n\nI just read 456 books*\n\n\n*Actually my computer did, but let’s not split hairs. An exploration into NLP, dimensionality reduction, and reactive visualizations.\n\n\n\n\npython\n\n\nD3/OJS\n\n\n \n\n\n\n\nMar 22, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTelling the future is hard\n\n\nA forecasting tournament put the predictive powers of social scientists to the test. They, ah, didn’t do so well.\n\n\n\n\nR\n\n\nggplot\n\n\nD3/OJS\n\n\n \n\n\n\n\nMar 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe demographics of Nobel laureates\n\n\nI’m starting to think there might be privileges to being old, white, and male\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nMar 3, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPutin’s leverage, Putin’s folly\n\n\nA newly released dataset lets us visualize the patterns of global trade on the eve of Russia’s invasion of Ukraine\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nFeb 22, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThe standard age\n\n\nAt what age are we our “standard” selves, when we are neither too young nor too old?\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nFeb 14, 2023\n\n\n\n\n\n\n  \n\n\n\n\nFrancis is an old pope\n\n\nAt 86, the current supreme pontiff is making his mark as one of history’s oldest. How long can he go on?\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nFeb 6, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWill people care about this Oscars?\n\n\nOn the surprising popularity of the 2023 nominations for Best Picture\n\n\n\n\nR\n\n\nggplot\n\n\nhighcharts\n\n\n \n\n\n\n\nJan 26, 2023\n\n\n\n\n\n\n  \n\n\n\n\nSomehow, Avatar has returned\n\n\nThe highest grossing movie of all time got to the top gradually rather than all at once\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nDec 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLuzon’s hiking trails\n\n\nCreating a stylized map of mountains using ridgelines\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n  \n\n\n\n\nI’m gonna carry that weight\n\n\nUsing a massive dataset of powerlifting competitors to set my gym goals for next year\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n  \n\n\n\n\nWar is over (if you want it?)\n\n\nA tally of active armed conflicts as of Christmas Day, since 1946\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nDec 3, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMore on the great post-1500 migrations\n\n\nWhich countries have the most diverse ancestors? Which countries have the most descendants around the world today?\n\n\n\n\nR\n\n\nhighcharts\n\n\n \n\n\n\n\nNov 26, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThe roots of economic development\n\n\nVisualizing some key results in Spolaore and Wacziarg’s 2013 survey\n\n\n\n\nR\n\n\nhighcharts\n\n\n \n\n\n\n\nNov 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThe emotional shape of novels\n\n\nUsing sentiment analysis, I chart the emotional highs and lows of three classic novels\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nNov 19, 2022\n\n\n\n\n\n\n  \n\n\n\n\nThat FTX balance sheet\n\n\nSBF shops around for investors with a balance sheet that is emphatically not GAAP\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nNov 15, 2022\n\n\n\n\n\n\n  \n\n\n\n\nVisualizing Elon Musk’s Twitter addiction\n\n\nThe world’s busiest billionaire finds the time to tweet at all hours of the day\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nNov 13, 2022\n\n\n\n\n\n\n  \n\n\n\n\nShould you dual wield y axes?\n\n\nPoints to keep in mind when resorting to a secondary axis\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMapping the Metro Manila subway\n\n\nIn a fit of wishful thinking, I use Leaflet to map the Metro Manila subway as if it existed\n\n\n\n\nR\n\n\nleaflet\n\n\n \n\n\n\n\nNov 8, 2022\n\n\n\n\n\n\n  \n\n\n\n\nExercises in plotting WDI data\n\n\nPull the data with R instead of downloading spreadsheet after spreadsheet\n\n\n\n\nR\n\n\nggplot\n\n\n \n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-11-05-wdi/index.html",
    "href": "posts/2022-11-05-wdi/index.html",
    "title": "Exercises in plotting WDI data",
    "section": "",
    "text": "In the old days I used to download WDI datasets in Excel format and point-and-click my way to a neat little chart. Now I want to try using the WDI package and some ggplot wizardry.\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(WDI)\nTo start, let’s try plotting the GDP per capita of the Philippines and Vietnam in constant 2015 US$.\ndf &lt;- WDI(\n  country = c(\"PH\", \"VN\"),\n  indicator = \"NY.GDP.PCAP.KD\",\n  start = 1990\n) %&gt;%\n  as_tibble()\n\nggplot(df, aes(x = year, y = NY.GDP.PCAP.KD, color = country)) +\n  geom_line()\nGreat. Now let’s try to get a cleaner chart by removing everything we don’t need: the axis labels, the legend title, the vertical grid lines, the tick marks. Let’s also add a chart title.\nggplot(df, aes(x = year, y = NY.GDP.PCAP.KD, color = country)) +\n  geom_line() +\n  labs(title = \"GDP per capita in constant 2015 US$\") +\n  theme(\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    legend.position = \"right\",\n    legend.title = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nIt’s a serviceable chart, but not a particularly attractive chart. Let’s spend some more time glamming it up. The numbers on the y-axis could use a thousands separator. The plot lines could be a little thicker. We can also make tweaks to the text sizes, the colors, the margins, and so forth.\nCode\nggplot(df, aes(x = year, y = NY.GDP.PCAP.KD, color = country)) +\n  geom_line(size = 1) +\n  labs(title = \"GDP per capita in constant 2015 US$\") +\n  scale_color_manual(values = c(\"#076fe4\", \"#f2500d\")) +\n  scale_y_continuous(label = function(x) prettyNum(x, big.mark = \",\", scientific = FALSE)) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(size = 11, margin = margin(5, 0, 0, 0)),\n    axis.text.y = element_text(size = 11, margin = margin(0, 5, 0, 0)),\n    plot.title = element_text(size = 14, hjust = .5, face = \"bold\", margin = margin(0, 0, 10, 0)),\n    legend.position = \"right\",\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nNow this to me is pleasing to the eye. A document populated with charts like this — as opposed to charts like the first two above — would be much more motivating to read.\nHere’s a second exercise. I think one useful way to categorize countries is according to whether they are big and rich, big and poor, small and rich, or small and poor. We can visualize this in a scatterplot with population on one axis and GDP per capita on the other. Let’s load up the data and plot the scatter.\ndf &lt;- WDI(\n  country = \"all\",\n  indicator = c(\n    \"gpc\" = \"NY.GDP.PCAP.KD\",\n    \"pop\" = \"SP.POP.TOTL\"\n  ),\n  start = 2015,\n  end = 2015,\n  extra = TRUE\n) %&gt;%\n  as_tibble() %&gt;%\n  filter(region != \"Aggregates\") %&gt;%\n  select(country, gpc, pop) %&gt;%\n  drop_na()\n\nggplot(df, aes(x = pop, y = gpc)) +\n  geom_point()\nWhat an atrocious chart! To make it comprehensible, we’ll need to re-express the axes in log scale first.\nggplot(df, aes(x = log10(pop), y = log2(gpc))) +\n  geom_point() +\n  scale_x_continuous(\n    name = \"Population\",\n    breaks = c(log10(10^4), log10(10^5), log10(10^6), log10(10^7), log10(10^8), log10(10^9)),\n    label = c(\"10,000\", \"100,000\", \"1 million\", \"10 million\", \"100 million\", \"1 billion\")\n  ) +\n  scale_y_continuous(\n    name = \"GDP per capita constant 2015 US$\",\n    breaks = c(log2(500), log2(1500), log2(10000), log2(30000)),\n    label = function(x) prettyNum(2^x, big.mark = \",\", scientific = FALSE)\n  )\nBetter! Let’s make further tweaks to the colors and so on to make it more attractive. In addition, let’s include some dividing lines to group big, small, rich, and poor countries. Some sensible definitions would be that “big” countries are those with 100 million people and above while “rich” countries are those with GDP per capita of $30,000 and above.\nCode\nggplot(df, aes(x = log10(pop), y = log2(gpc))) +\n  geom_point(shape = 16, size = 3, color = \"#076fe4\") +\n  labs(title = \"Big and small, rich and poor\") +\n  geom_vline(xintercept = log10(10^8), size = .5, linetype = \"dashed\", color = \"gray50\") +\n  geom_hline(yintercept = log2(30000), size = .5, linetype = \"dashed\", color = \"gray50\") +\n  scale_x_continuous(\n    name = \"Population\",\n    breaks = c(log10(10^4), log10(10^5), log10(10^6), log10(10^7), log10(10^8), log10(10^9)),\n    label = c(\"10,000\", \"100,000\", \"1 million\", \"10 million\", \"100 million\", \"1 billion\")\n  ) +\n  scale_y_continuous(\n    name = \"GDP per capita constant 2015 US$\",\n    breaks = c(log2(500), log2(1500), log2(10000), log2(30000)),\n    label = function(x) prettyNum(2^x, big.mark = \",\", scientific = FALSE)\n  ) +\n  theme(\n    axis.title = element_text(size = 11),\n    axis.title.x = element_text(margin = margin(10, 0, 0, 0)),\n    axis.title.y = element_text(margin = margin(0, 10, 0, 0)),\n    axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\n    axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\n    axis.ticks = element_blank(),\n    plot.title = element_text(size = 12, hjust = .5, face = \"bold\", margin = margin(0, 0, 10, 0)),\n    panel.background = element_rect(fill = \"gray97\"),\n    panel.grid = element_blank()\n  )\nAnd here’s the interesting result. Under this set of definitions, there are really only two big and rich countries: the United States and Japan. The biggest small and rich country is Germany, with a population of 82 million, while the richest small and poor country is Mexico, with a GDP per capita of $9,600. In short, no country in the near future is expected to join the big-and-rich club.1\nNow let’s make some finishing touches to the chart. First, let’s add the labels “big”, “small”, “rich”, and “poor” on either side of the dashed lines to make it clear what they’re indicating. Second, let’s bold the axis labels “30,000” and “100 million” to highlight the chosen thresholds for bigness and richness. Third, let’s label the points for the U.S., Japan, Germany, and Mexico to facilitate the discussion accompanying the chart. We also highlight these four points by making all other points transparent.\nCode\nggplot(df, aes(x = log10(pop), y = log2(gpc))) +\n  geom_point(shape = 16, size = 3, color = \"#076fe4\", alpha = ifelse(df$country %in% c(\"United States\", \"Japan\", \"Germany\", \"Mexico\"), 1, .25)) +\n  labs(title = \"Big and small, rich and poor\") +\n\n  # Dashed lines\n  geom_vline(xintercept = log10(10^8), size = .5, linetype = \"dashed\", color = \"gray50\") +\n  geom_hline(yintercept = log2(30000), size = .5, linetype = \"dashed\", color = \"gray50\") +\n  annotate(\"text\", family = \"karla\", x = log10(10^8) + .1, y = log2(200000), hjust = 0, label = \"big\", size = 3.5, color = \"gray50\") +\n  annotate(\"text\", family = \"karla\", x = log10(10^8) - .1, y = log2(200000), hjust = 1, label = \"small\", size = 3.5, color = \"gray50\") +\n  annotate(\"text\", family = \"karla\", x = log10(10.5^9), y = log2(30000) + .2, vjust = 0, label = \"rich\", size = 3.5, color = \"gray50\") +\n  annotate(\"text\", family = \"karla\", x = log10(10.5^9), y = log2(30000) - .15, vjust = 1, label = \"poor\", size = 3.5, color = \"gray50\") +\n\n  # Highlighted points\n  annotate(\"text\", family = \"karla\", x = log10(df$pop[df$country == \"United States\"]), y = log2(df$gpc[df$country == \"United States\"]) + .4, hjust = 0, vjust = 0, label = \"United States\", size = 3.5, fontface = \"bold\") +\n  annotate(\"text\", family = \"karla\", x = log10(df$pop[df$country == \"Japan\"]) + .1, y = log2(df$gpc[df$country == \"Japan\"]), hjust = 0, vjust = 0, label = \"Japan\", size = 3.5, fontface = \"bold\") +\n  annotate(\"text\", family = \"karla\", x = log10(df$pop[df$country == \"Germany\"]), y = log2(df$gpc[df$country == \"Germany\"]) + .4, hjust = .5, vjust = 0, label = \"Germany\", size = 3.5, fontface = \"bold\") +\n  annotate(\"text\", family = \"karla\", x = log10(df$pop[df$country == \"Mexico\"]), y = log2(df$gpc[df$country == \"Mexico\"]) + .4, hjust = .5, vjust = 0, label = \"Mexico\", size = 3.5, fontface = \"bold\") +\n  scale_x_continuous(\n    name = \"Population\",\n    breaks = c(log10(10^4), log10(10^5), log10(10^6), log10(10^7), log10(10^8), log10(10^9)),\n    label = c(\"10,000\", \"100,000\", \"1 million\", \"10 million\", \"100 million\", \"1 billion\")\n  ) +\n  scale_y_continuous(\n    name = \"GDP per capita constant 2015 US$\",\n    breaks = c(log2(500), log2(1500), log2(10000), log2(30000)),\n    label = function(x) prettyNum(2^x, big.mark = \",\", scientific = FALSE)\n  ) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    axis.title.x = element_text(size = 12, margin = margin(10, 0, 0, 0)),\n    axis.title.y = element_text(size = 12, margin = margin(0, 10, 0, 0)),\n    axis.text.x = element_text(size = 11, margin = margin(5, 0, 0, 0), face = c(\"plain\", \"plain\", \"plain\", \"plain\", \"bold\", \"plain\")),\n    axis.text.y = element_text(size = 11, margin = margin(0, 5, 0, 0), face = c(\"plain\", \"plain\", \"plain\", \"bold\")),\n    axis.ticks = element_blank(),\n    plot.title = element_text(size = 14, hjust = .5, face = \"bold\", margin = margin(0, 0, 10, 0)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid = element_blank()\n  )\nAnd here’s the final chart!"
  },
  {
    "objectID": "posts/2022-11-05-wdi/index.html#footnotes",
    "href": "posts/2022-11-05-wdi/index.html#footnotes",
    "title": "Exercises in plotting WDI data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot that this should be taken too seriously! The thresholds I used are completely arbitrary.↩︎"
  },
  {
    "objectID": "posts/2022-11-08-metro-manila-subway/index.html",
    "href": "posts/2022-11-08-metro-manila-subway/index.html",
    "title": "Mapping the Metro Manila subway",
    "section": "",
    "text": "Today I’ll experiment with making maps via leaflet, which I’m using for the first time. I’m relying mainly on this tutorial.\n\nlibrary(tidyverse)\nlibrary(leaflet)\n\nBelow is a map pointing out some of the planned stations of the future Metro Manila Subway, which will be built… sometime… maybe? Back in June the first tunnel boring machine was “ceremonially lowered” but no digging has actually taken place.\nAnyway, I map the stations from Quirino Highway to 11th Avenue in BGC. I got the locations from trawling through news articles and project documents, then I used Google Maps to get their coordinates.\n\nleaflet(options = leafletOptions(minZoom = 10, maxZoom = 15)) %&gt;%\n  addTiles() %&gt;%\n  addMarkers(lng=121.028460, lat=14.689541, label=\"Quirino Highway Station\") %&gt;%\n  addMarkers(lng=121.032355, lat=14.676936, label=\"Tandang Sora Station\") %&gt;%\n  addMarkers(lng=121.035685, lat=14.654850, label=\"North Avenue Station\") %&gt;%\n  addMarkers(lng=121.037591, lat=14.644747, label=\"Quezon Avenue Station\") %&gt;%\n  addMarkers(lng=121.051628, lat=14.640692, label=\"East Avenue Station\") %&gt;%\n  addMarkers(lng=121.065282, lat=14.627151, label=\"Anonas Station\") %&gt;%\n  addMarkers(lng=121.069868, lat=14.613690, label=\"Camp Aguinaldo Station\") %&gt;%\n  addMarkers(lng=121.063565, lat=14.588103, label=\"Ortigas Station\") %&gt;%\n  addMarkers(lng=121.061238, lat=14.575162, label=\"Shaw Station\") %&gt;%\n  addMarkers(lng=121.055859, lat=14.558327, label=\"11th Avenue Station\")\n\n\n\n\n\nAnd here’s the map! It’s fine? It’s a little busy, so let’s change the map tile from the default OpenStreetMap to a nice minimalist one from this list.\n\nleaflet(options = leafletOptions(minZoom = 10, maxZoom = 15)) %&gt;%\n  addProviderTiles(providers$CartoDB.Voyager) %&gt;%\n  addMarkers(lng=121.028460, lat=14.689541, label=\"Quirino Highway Station\") %&gt;%\n  addMarkers(lng=121.032355, lat=14.676936, label=\"Tandang Sora Station\") %&gt;%\n  addMarkers(lng=121.035685, lat=14.654850, label=\"North Avenue Station\") %&gt;%\n  addMarkers(lng=121.037591, lat=14.644747, label=\"Quezon Avenue Station\") %&gt;%\n  addMarkers(lng=121.051628, lat=14.640692, label=\"East Avenue Station\") %&gt;%\n  addMarkers(lng=121.065282, lat=14.627151, label=\"Anonas Station\") %&gt;%\n  addMarkers(lng=121.069868, lat=14.613690, label=\"Camp Aguinaldo Station\") %&gt;%\n  addMarkers(lng=121.063565, lat=14.588103, label=\"Ortigas Station\") %&gt;%\n  addMarkers(lng=121.061238, lat=14.575162, label=\"Shaw Station\") %&gt;%\n  addMarkers(lng=121.055859, lat=14.558327, label=\"11th Avenue Station\")\n\n\n\n\n\nNeat. I’ll revisit this later on to see what else I can add. \nUpdate 17 Nov 2022: Transportation Undersecretary Cesar Chavez has said that “the actual excavation is on December 12”. He added: “Actually, this is for real. The excavation is real.” Well, there you have it. The excavation is “real”.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2022-11-10-dual-wield/index.html",
    "href": "posts/2022-11-10-dual-wield/index.html",
    "title": "Should you dual wield y axes?",
    "section": "",
    "text": "Consider this: all charts are essentially squiggles on a Cartesian plane. There’s a horizontal, or x, axis and there’s a vertical, or y, axis. This implies that the underlying datasets ever only need two columns, corresponding to the two axes. Many chart enthusiasts seem to be guided by this principle, which is why they detest charts that violate this setup, like pie charts.\nAnother chart that maybe violates this setup are those with two different y axes, or dual axis charts. These are very popular. Today, Planning Secretary Arsenio Balisacan accompanied his tweet on the Philippine third quarter GDP numbers with this chart:\nWhat’s wrong with it?\nThe first problem is that there isn’t really a reason why it has to be a dual axis chart at all. The level of real GDP is not meaningful to most people and visualizing it doesn’t provide much insight.\nThe second problem is that it’s sloppily made. In the legend, “Real GDP” (the bars) is on the left and “GDP growth” (the line) is on the right, so the natural inclination is to use the left axis for the bars and the right axis for the line. But woe to you if you do — the positions are reversed. This is because for “combo charts” in Excel (i.e. where you combine two chart types), bar layers always go first before lines, hence they are listed first in the legend.1 But you can choose which axis the bar series is assigned to, so it should have been assigned to the left one.\nMore importantly: the two axes clash. Look at 5.0 on the left axis. If you follow the grid line all the way to the right axis, you get… 4.something. You quickly realize that the grid lines really just mark the axis labels on the left, not the right. The right axis exists in its own parallel grid in the nether regions of the chart. That’s confusing! This is again a trait of Excel. If you tick the check box that puts a series on the secondary axis, it automatically scales its axis independent of the primary axis. So you basically end up with two charts sharing the same x axis superimposed on top of each other.\nBelow is my own quick fix of the chart (data source here).\nCode\nlibrary(tidyverse)\nlibrary(tsibble)\nlibrary(ggplot2)\n\nhere::here(\"datasets\", \"phgdp.csv\") %&gt;% \n  read_csv() %&gt;%\n  mutate(\n    date = as.Date(date, format = \"%d/%m/%Y\"),\n    quarter = yearquarter(date),\n    qtr = as.character(quarter),\n    growth = 100 * (gdp / lag(gdp, 4) - 1)\n  ) %&gt;% \n  filter(date &gt;= \"2019-03-01\") %&gt;% \n  \n  ggplot() +\n  geom_bar(aes(x = qtr, y = gdp / 1000000, fill = \"LHS - Real GDP (in constant 2018 trillion pesos)\"), stat = \"identity\", width = .5) +\n  geom_line(aes(x = qtr, y = growth / 5 + 4, color = \"RHS - GDP growth (in %)\"), group = 1, linewidth = 1.5) +\n  geom_point(aes(x = qtr, y = growth / 5 + 4, color = \"RHS - GDP growth (in %)\", line = \"RHS - GDP growth (in %)\"), size = 3.5) +\n  geom_hline(yintercept = 0, size = .25, color = \"gray25\") +\n  scale_fill_manual(values = \"#fcc954\") +\n  scale_color_manual(values = \"#0b3f90\") +\n  guides(fill = guide_legend(order = 1)) +\n  scale_y_continuous(\n    limits = c(0, 7), breaks = 0:7,\n    sec.axis = sec_axis(~ (. - 4) * 5, breaks = seq(-20, 15, 5))\n  ) +\n  theme(\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 12, angle = 90, margin = margin(-3, 0, 0, 0)),\n    axis.text.y = element_text(size = 12, margin = margin(0, 5, 0, 0)),\n    axis.ticks = element_blank(),\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    legend.key = element_blank(),\n    legend.key.height = unit(.75, \"lines\"),\n    legend.key.width = unit(1.5, \"lines\"),\n    legend.text = element_text(size = 12),\n    panel.background = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(size = .25, color = \"gray85\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nThere’s still one last problem with this chart, which is that the right y axis really ought to cross the x axis at zero. Positive growth rates fundamentally differ from negative growth rates, but a quick glance at the chart gives the impression that Philippine growth just took a dip in 2020. But! If you cross the right y axis at zero, the left y axis will have to extend to the negative numbers. This would make no sense for GDP. So there’s the dilemma: one y axis ends up compromising the other. I don’t know if there’s a way to fix this.\nI personally don’t have anything against dual axis charts, and I have used them a lot in my work. What I am against are sloppily made charts, and perhaps, by being inherently more complex, sloppiness in dual axis charts tends to be extra noticeable.\nOne essential to keep in mind is that both y axes must coexist in the same Cartesian plane, meaning one is just a transformation of the other. In the chart I made, \\(y_{\\text{right}} = ( y_{\\text{left}} - 4 ) \\times 5\\). This is something you manually have to specify in ggplot, making it harder to make dual axis charts there. But that’s by design. Excel makes it too easy, and so you get people hitting that secondary axis check box and calling it a day."
  },
  {
    "objectID": "posts/2022-11-10-dual-wield/index.html#footnotes",
    "href": "posts/2022-11-10-dual-wield/index.html#footnotes",
    "title": "Should you dual wield y axes?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor some reason, Excel is adamant that you should never be able to change the order of chart layers, or the order of legend items.↩︎"
  },
  {
    "objectID": "posts/2022-11-13-elon/index.html",
    "href": "posts/2022-11-13-elon/index.html",
    "title": "Visualizing Elon Musk’s Twitter addiction",
    "section": "",
    "text": "Elon Musk tweets a lot. Like, a lot. We can quantify it using this Kaggle dataset that contains all of Musk’s tweets between 27 January and 27 October 2022.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\n\ndf &lt;- here::here(\"datasets\", \"elon.csv\") %&gt;% \n  read_csv() %&gt;%\n  arrange(Date) %&gt;%\n  mutate(hour(Date) &lt;- hour(Date) + 1)\n\n# Switch from UTC to UTC-6 (Texas)\nhour(df$Date) &lt;- hour(df$Date) - 6\n\ndf &lt;- df %&gt;%\n  mutate(\n    date = date(Date),\n    hour = hour(Date),\n    gap = difftime(Date, lag(Date), units = \"mins\")\n  )\n\n# Tweets per day: nrow(df) / as.numeric(as.Date(\"2022-10-27\") - as.Date(\"2022-01-27\"))\n# Average time between tweets: mean(df$gap[-1])\n\nThe timestamps were in UTC, but since Musk seems to reside mostly in Texas, I switched the time zone to UTC-6.\nDuring this 10-month period, Musk sent out about 11 tweets per day. Put another way, he tweeted every 2 hours and 8 minutes for 10 months. Some of the tweets dabble in great power diplomacy, some are poop emojis.\nLooking at the sheer volume of tweets Musk produces, I got to wondering: when does this guy work? Elon Musk is famously a workaholic who claims to work 80-90 hours a week. But… is he just tweeting the whole time? Let’s investigate.\nFirst let’s chart his tweets per day to see what we’re dealing with.\n\n\nCode\nggplot(df %&gt;% count(date), aes(x = date, y = n)) +\n  geom_bar(stat = \"identity\", width = 1, fill = \"#1046b1\") +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\") +\n  scale_y_continuous(breaks = c(0, 20, 40)) +\n  theme(\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\n    axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\n    panel.background = element_rect(fill = \"gray97\"),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nInterestingly, Musk does take breaks from time to time, like a 10-day stretch in late June. Maybe work picked up?\nNow let’s plot an hourly histogram of his tweets.\n\n\nCode\nggplot(df, aes(x = hour)) +\n  geom_histogram(aes(y = after_stat(density)),\n    binwidth = 1, fill = \"#1046b1\", color = \"gray97\", linewidth = 2\n  ) +\n  scale_x_continuous(breaks = 0:23) +\n  scale_y_continuous(labels = function(x) paste0(100 * x, \"%\")) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(size = 10, margin = margin(5, 0, 0, 0)),\n    axis.text.y = element_text(size = 10, margin = margin(0, 5, 0, 0)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(color = \"white\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nWow. It looks like he tweets at pretty much all waking hours of the day. He also seems to not be getting much sleep, with the lull in tweets spanning just 3am to 6am.\nLooking through the dataset, what’s more remarkable is that most of his tweets are replies to other tweets. Anyone can tweet 11 tweets per day, but what Musk is doing involves actually browsing Twitter, reading other people’s tweets, and reacting to them. Constantly. All day. Everyday. I suppose an argument can be made that one so thoroughly immersed in the platform (to the point of crippling addiction) is actually well-placed to run said platform. But an argument can also be made that no, what, are you crazy, that’d be a horrible idea.\nHere’s a fun data viz exercise to end. Let’s color the bars according to the time of day, with nighttime in blue and daytime in yellow.\n\n\nCode\ndaycolors &lt;- c(\n  rep(\"#1046b1\", 5),     # 12am to 4am\n  rep(\"#9696d2\", 3),     # 5am to 7am\n  rep(\"#ffa600\", 12),    # 8am to 7pm\n  rep(\"#9696d2\", 3),     # 8pm to 10pm\n  rep(\"#1046b1\", 1)      # 11pm\n)\n\nggplot(df, aes(x = hour)) +\n  geom_histogram(aes(y = after_stat(density)),\n    binwidth = 1, fill = daycolors, color = \"gray97\", linewidth = 2.5\n  ) +\n  labs(\n    title = \"Hourly distribution of Elon Musk's tweets\",\n    subtitle = \"January to October 2022\"\n  ) +\n  scale_x_continuous(\n    breaks = 0:23,\n    label = paste0(c(12, 1:12, 1:11), \":00\")\n  ) +\n  scale_y_continuous(labels = function(x) paste0(100 * x, \"%\")) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(0, 0, 15, 0)),\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(size = 12, angle = 90, hjust = 1, vjust = .5, margin = margin(5, 0, 0, 0)),\n    axis.text.y = element_text(size = 12, margin = margin(0, 5, 0, 0)),\n    legend.position = \"none\",\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(color = \"white\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2022-11-15-ftx/index.html",
    "href": "posts/2022-11-15-ftx/index.html",
    "title": "That FTX balance sheet",
    "section": "",
    "text": "I was reading Matt Levine’s entertaining walkthrough of the FTX balance sheet and I thought it’d be fun to visualize this, um, unique financial document. FTX is a crypto exchange that collapsed spectacularly last week. There are already plans for a movie adaptation and I hope Sorkin and Fincher reunite for it.\nThe balance sheet in question is dated 10 November and appears to have been constructed by SBF himself. It sent prospective investors running the other way. Per Levine: “It’s an Excel file full of the howling of ghosts and the shrieking of tortured souls. If you look too long at that spreadsheet, you will go insane.”\nFor this visualization, I want to show the assets and liabilities in two bars, with the assets bar broken down into the various weird things that FTX counted as assets. I will be employing a lot of visual trickery in this chart and I’d like to walk you through my process.\nFirst, here is how I gathered the numbers into a dataset. Doing it in this “long” format makes it easier to chart.\n\nlibrary(tidyverse)\n\ndf &lt;- here::here(\"datasets\", \"ftx.csv\") %&gt;%\n  read_csv()\ndf\n\n# A tibble: 12 × 3\n   group1      group2            billions\n   &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;\n 1 liabilities total                8.86 \n 2 assets      total                9.58 \n 3 assets      liquid               0.900\n 4 assets      liquid-robinhood     0.472\n 5 assets      liquid-others        0.428\n 6 assets      lessliquid           5.45 \n 7 assets      lessliquid-ftt       0.554\n 8 assets      lessliquid-serum     2.19 \n 9 assets      lessliquid-sol       0.982\n10 assets      lessliquid-maps      0.616\n11 assets      lessliquid-others    1.11 \n12 assets      illiquid             3.23 \n\n\nHere’s a first stab:\n\nlibrary(ggplot2)\n\ndf1 &lt;- df %&gt;%\n  filter(group2 %in% c(\"total\", \"liquid\", \"lessliquid\", \"illiquid\"), !(group1 == \"assets\" & group2 == \"total\"))\n\nggplot(df1, aes(x = group1, y = billions, fill = group2)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  theme(\n    axis.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    panel.background = element_blank(),\n    panel.grid = element_blank()\n  )\n\n\n\n\nAtrocious but you get the idea.\nI’m going to annotate these bars with subcategories of interest, so I’ll need some space on the sides. To get this, I’ll add phantom categories to the “group1” column.\n\ndf1 &lt;- df1 %&gt;%\n  bind_rows(tibble(\n    group1 = c(\"space_l\", \"space_r\"),\n    group2 = \"total\", value = 0\n  )) %&gt;%\n  mutate(group1 = factor(group1, levels = c(\"space_l\", \"assets\", \"liabilities\", \"space_r\")))\n\nplot &lt;- ggplot(df1, aes(x = group1, y = billions, fill = group2)) +\n  geom_bar(stat = \"identity\", position = \"stack\", width = .7) +\n  theme(\n    axis.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    panel.background = element_blank(),\n    panel.grid = element_blank()\n  )\nplot\n\n\n\n\nFor the annotations, we will be using geom_rect(), geom_segment(), annotate(), and a significant amount of trial and error. Let me demonstrate by annotating the portion of the “less liquid” assets that comprise the stuff FTX “made up” (FTT, SRM, SOL, and MAPS tokens). We’ll first need to identify some coordinates in the plot space:\n\nh1 &lt;- df$billions[df$group2 == \"liquid\"]\nh2 &lt;- h1 + df$billions[df$group2 == \"lessliquid\"]\nh3 &lt;- h1 + df$billions[df$group2 == \"lessliquid-others\"]\nh4 &lt;- df$billions[df$group1 == \"assets\" & df$group2 == \"total\"]\n\nNow we add to the plot:\n\nbw &lt;- .35\n\nplot +\n  geom_rect(\n    xmin = 2 - bw, xmax = 2 + bw, ymin = h3, ymax = h2,\n    data = df1[1, ], fill = NA, color = \"black\"\n  ) +\n  geom_segment(\n    x = 2 - bw, xend = 2 - 1.5 * bw, y = h2 - 1, yend = h2 - .8,\n    color = \"black\"\n  ) +\n  annotate(\"text\",\n    x = 2 - 1.8 * bw, y = h2 - .65, hjust = 1,\n    label = \"Stuff we made up\"\n  )\n\n\n\n\nNote that all the positioning values were discovered through trial and error. So if you’re doing something like this, try and organize your values around fundamental constants of the chart. For example, bw here is half the width of the bars.\nNow let’s add all the other annotations, and while we’re at it let’s tweak the aesthetics of the chart. There’s also the question of where to place the 8-billion-dollar “hidden, poorly internally labeled ‘fiat@’ account”. No one’s really sure what to do with this. Writes Matt Levine:\n\nIf you try to calculate the equity of a balance sheet with an entry for HIDDEN POORLY INTERNALLY LABELED ACCOUNT, Microsoft Clippy will appear before you in the flesh, bloodshot and staggering, with a knife in his little paper-clip hand, saying “just what do you think you’re doing Dave?” You cannot apply ordinary arithmetic to numbers in a cell labeled “HIDDEN POORLY INTERNALLY LABELED ACCOUNT.” The result of adding or subtracting those numbers with ordinary numbers is not a number; it is prison.\n\nGiven this expert advice, I’ve decided to give it its own accurately sized bar that kind of just hovers over the liabilities bar, like a ghoul.\nHere’s the final chart:\n\n\nCode\nggplot(df1, aes(x = group1, y = billions, fill = group2)) +\n  geom_bar(stat = \"identity\", position = \"stack\", width = .7) +\n\n  # Hidden poorly internally labeled account\n  geom_rect(\n    xmin = 3 - .8 * bw, xmax = 3 + 1.2 * bw, ymin = 1.2, ymax = 1.2 + 8,\n    data = df1[1, ], fill = \"gray80\", alpha = .5\n  ) +\n  annotate(\"text\",\n    x = 3 - 1.1 * bw, y = 8 + 1.45, family = \"karla\", size = 10 / .pt, vjust = 0, hjust = 0, color = \"gray50\",\n    label = \"Hidden, poorly internally labeled account: -$8 billion\"\n  ) +\n\n  # Robinhood shares\n  geom_rect(\n    xmin = 2 - bw, xmax = 2 + bw, ymin = h1 - .472, ymax = h1,\n    data = df1[1, ], fill = NA, color = \"black\", linewidth = 1\n  ) +\n  geom_segment(\n    x = 2 - bw, xend = 2 - 1.4 * bw, y = h1 - .472 / 2, yend = h1 - .4,\n    linewidth = .5, color = \"black\"\n  ) +\n  annotate(\"text\",\n    x = 2 - 1.6 * bw, y = h1 - .4, family = \"karla\", size = 12 / .pt, hjust = 1,\n    label = \"Robinhood shares\"\n  ) +\n\n  # Stuff we made up\n  geom_rect(\n    xmin = 2 - bw, xmax = 2 + bw, ymin = h3, ymax = h2,\n    data = df1[1, ], fill = NA, color = \"black\", linewidth = 1\n  ) +\n  geom_segment(\n    x = 2 - bw, xend = 2 - 1.4 * bw, y = h2 - .9, yend = h2 - .76,\n    linewidth = .5, color = \"black\"\n  ) +\n  annotate(\"text\",\n    x = 2 - 1.6 * bw, y = h2 - .6, family = \"karla\", size = 12 / .pt, hjust = 1,\n    label = \"Stuff we made up\"\n  ) +\n\n  # TRUMPLOSE\n  geom_rect(\n    xmin = 2 - .8 * bw, xmax = 2 - .7 * bw, ymin = h4 - 1.15, ymax = h4 - 1,\n    data = df1[1, ], fill = NA, color = \"black\", linewidth = 1\n  ) +\n  geom_segment(\n    x = 2 - .8 * bw, xend = 2 - 1.5 * bw, y = h4 - 1.075, yend = h4 - 1.2,\n    linewidth = .5, color = \"black\"\n  ) +\n  annotate(\"text\",\n    x = 2 - 1.7 * bw, y = h4 - 1.15, family = \"karla\", size = 12 / .pt, hjust = 1,\n    label = \"TRUMPLOSE\"\n  ) +\n\n  # Labels and legend\n  labs(\n    title = \"There were many things I wish I could do differently than I did\",\n    caption = \"Note: all of these are rough values and could be slightly off; there is also obviously a chance of typos etc.\"\n  ) +\n  scale_fill_manual(\n    labels = c(\"Illiquid: $3.2bn\", \"Less liquid: $5.4bn\", \"Liquid: $900mn\", \"\"),\n    values = c(\"#a4b1ff\", \"#6679d8\", \"#1046b1\", \"#d1241a\")\n  ) +\n  scale_x_discrete(labels = c(\"\", \"Assets\\n\\\"$9.6bn\\\"\", \"Liabilities\\n-$8.9bn\", \"\")) +\n  guides(fill = guide_legend(\n    keywidth = unit(.8, \"lines\"),\n    keyheight = unit(.8, \"lines\"),\n    byrow = TRUE,\n    override.aes = list(alpha = c(1, 1, 1, 0))\n  )) +\n\n  # Theme\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5, margin = margin(b = 10)),\n    plot.caption = element_text(size = 10, hjust = .5, margin = margin(t = 15)),\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 14, color = \"black\", margin = margin(t = 8)),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    legend.position = c(.02, .45),\n    legend.background = element_blank(),\n    legend.justification = c(0, 1),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    legend.spacing.y = unit(.4, \"lines\"),\n    legend.key = element_blank(),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\nI think this exercise really brings out the “grid” nature of ggplot. It may be painstaking but as long as you can place your rectangle or line or textbox in the x-y coordinate system, you can modify your chart in all sorts of fun ways. \n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2022-11-19-the-emotional-shape-of-novels/index.html",
    "href": "posts/2022-11-19-the-emotional-shape-of-novels/index.html",
    "title": "The emotional shape of novels",
    "section": "",
    "text": "Novels can take you for such a ride.\nToday I’m experimenting with sentiment analysis on some novels I’ve recently read. I’ll be using tidytext with data from gutenbergr (i.e. Project Gutenberg), which means I’m restricted to the classics. I read three this year: Swann’s Way by Marcel Proust, Tess of the d’Urbervilles by Thomas Hardy, and The Age of Innocence by Edith Wharton.\nQuick review of each. (1) It takes a certain mood to be reading Proust. I got through Within a Budding Grove but found halfway through that oops I’m not in the mood anymore, so I stopped searching for that lost time. (2) While I enjoyed Hardy’s Far from the Madding Crowd, Tess was such an unrelenting depression parade that I was feeling numb by the end of it. (3) Ah, Age of Innocence is one of my all-time favorites. I have been, at various points in my life, Newland, Ellen, and May. My God, I might have even been a Julius Beaufort.\nLet’s load up these works.\n\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(gutenbergr)\n\n# Get the IDs\ngutenberg_works(title %in% c(\n  \"Swann's Way\",\n  \"Tess of the d'Urbervilles: A Pure Woman\",\n  \"The Age of Innocence\"\n))\n\n# A tibble: 3 × 8\n  gutenberg_id title               author guten…¹ langu…² guten…³ rights has_t…⁴\n         &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;lgl&gt;  \n1          110 Tess of the d'Urbe… Hardy…      23 en      Banned… Publi… TRUE   \n2          541 The Age of Innocen… Whart…     104 en      Movie … Publi… TRUE   \n3         7178 Swann's Way         Prous…     987 en      &lt;NA&gt;    Publi… TRUE   \n# … with abbreviated variable names ¹​gutenberg_author_id, ²​language,\n#   ³​gutenberg_bookshelf, ⁴​has_text\n\nbooks &lt;- gutenberg_download(c(110, 541, 7178)) %&gt;%\n  filter(text != \"\") %&gt;%\n  group_by(gutenberg_id) %&gt;%\n  mutate(line = row_number()) %&gt;%\n  ungroup() %&gt;%\n  left_join(tibble(\n    gutenberg_id = c(110, 541, 7178),\n    title = c(\n      \"Tess of the d'Urbervilles\",\n      \"The Age of Innocence\",\n      \"Swann's Way\"\n    )\n  )) %&gt;%\n  select(title, line, text)\n\nLines refer to lines on the printed page. What I want to do is split each work into 100 equal sized groups of lines, quantify the sentiment of each, and map the emotional shape of the novel. I’m using the AFINN lexicon, which assigns a score between -5 and 5 to about 2500 English words. More negative scores imply more negative sentiments, and vice nersa.\nThe following code breaks up the works so that each row corresponds to one word. Uninteresting words like “the” are removed with anti_join(stop_words). The remaining words are then assigned a sentiment score according to AFINN.\n\nbooks_df &lt;- books %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  anti_join(stop_words) %&gt;%\n  inner_join(get_sentiments(\"afinn\"))\n\nLet’s try it out first with Tess. It has 13,776 lines, so I split it into 100 chunks of 138 lines.\n\n\nCode\nlibrary(ggplot2)\n\ntess &lt;- books_df %&gt;%\n  filter(title == \"Tess of the d'Urbervilles\") %&gt;%\n  group_by(chunk = line %/% 138) %&gt;%\n  summarise(sentiment = sum(value))\n\nggplot(tess, aes(x = chunk, y = sentiment)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\nIt worked! But the chart is ugly! The problem is that net sentiment swings so wildly up and down from chunk to chunk that the result looks more like a seismograph than the “shape” of the novel.\nLet’s try a different approach. When you read a chapter and it’s a happy one, you enter the next chapter starting from a position of positive sentiment. Then maybe the next chapter is a sad one, so it brings down your overall sentiment back to something like neutral. The point is, the emotional weight of a novel builds, it doesn’t reset every chapter. Working off this idea, let’s try and map cumulative sentiment across the novel instead of the isolated sentiment of each chunk.\nThe chart that works best for this is a waterfall chart, for which the waterfalls package will be helpful.\n\nlibrary(waterfalls)\n\ntess &lt;- tess %&gt;%\n  mutate(\n    chunk = factor(chunk),\n    fill = ifelse(sentiment &gt;= 0, \"#1046b1\", \"#d1241a\")\n  )\n\nwf &lt;- waterfall(tess,\n  rect_width = 1,\n  rect_border = NA,\n  rect_text_labels = rep(NA, nrow(tess)),\n  draw_axis.x = \"none\",\n  fill_by_sign = FALSE,\n  fill_colours = tess$fill\n) +\n  geom_hline(yintercept = 0, color = \"gray50\", size = .5, linetype = \"dashed\") +\n  scale_y_continuous(name = \"Sentiment (AFINN lexicon)\") +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    axis.title = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(size = 12, margin = margin(r = 10)),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(size = 12),\n    axis.ticks = element_blank(),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\nwf\n\n\n\n\nNow the shape is more discernible. You can see the ups and downs of Tess’ life (it’s mostly downs). By the end of the book, you are at about a -600 sentiment score.\nFor a bit of extra fanciness let’s annotate the chart with the book’s title, author, and cover, the last one taken from Goodreads.\n\nlibrary(cowplot)\nlibrary(magick)\n\nggdraw(wf) +\n  draw_image(\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1543250144l/42959097._SY475_.jpg\",\n    x = .15, y = .1, halign = 0, valign = 0, scale = .4\n  ) +\n  draw_label(\"Tess of the d'Urbervilles\",\n    x = .15 + .18, y = .1 + .16, hjust = 0, vjust = .5,\n    size = 14, fontfamily = \"karla\", fontface = \"bold\"\n  ) +\n  draw_label(\"by Thomas Hardy\",\n    x = .15 + .18, y = .1 + .10, hjust = 0, vjust = .5,\n    size = 12, fontfamily = \"karla\"\n  )\n\n\n\n\nLet’s do the same for The Age of Innocence.\n\n\nCode\nage &lt;- books_df %&gt;%\n  filter(title == \"The Age of Innocence\") %&gt;%\n  group_by(chunk = line %/% 94) %&gt;%\n  summarise(sentiment = sum(value)) %&gt;%\n  mutate(\n    chunk = factor(chunk),\n    fill = ifelse(sentiment &gt;= 0, \"#1046b1\", \"#d1241a\")\n  )\n\nwf &lt;- waterfall(age,\n  rect_width = 1,\n  rect_border = NA,\n  rect_text_labels = rep(NA, nrow(age)),\n  draw_axis.x = \"none\",\n  fill_by_sign = FALSE,\n  fill_colours = age$fill\n) +\n  geom_hline(yintercept = 0, color = \"gray50\", size = .5, linetype = \"dashed\") +\n  scale_y_continuous(name = \"Sentiment (AFINN lexicon)\") +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    axis.title = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(size = 12, margin = margin(0, 10, 0, 0)),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(size = 11),\n    axis.ticks = element_blank(),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\nggdraw(wf) +\n  draw_image(\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1320402548l/545294.jpg\",\n    x = .53, y = .18, halign = 0, valign = 0, scale = .4\n  ) +\n  draw_label(\"The Age of Innocence\",\n    x = .53 + .18, y = .18 + .16, hjust = 0, vjust = .5,\n    size = 14, fontfamily = \"karla\", fontface = \"bold\"\n  ) +\n  draw_label(\"by Edith Wharton\",\n    x = .53 + .18, y = .18 + .10, hjust = 0, vjust = .5,\n    size = 12, fontfamily = \"karla\"\n  )\n\n\n\n\n\nIt’s a reasonably happy ride for the first half of the novel as we follow Madame Olenska’s disruptions of the self-satisfied New York upper-class society of the 19th century. The turning point is right about where Newland Archer decides not to call her from up the hill. There’s a steady descent as passions clash with idealistic notions of the world before ending on a bittersweet note. You end the book on a net positive, and all in all I’d say that makes sense.\nFinally, here is Swann’s Way.\n\n\nCode\nswann &lt;- books_df %&gt;%\n  filter(title == \"Swann's Way\") %&gt;%\n  group_by(chunk = line %/% 159) %&gt;%\n  summarise(sentiment = sum(value)) %&gt;%\n  mutate(\n    chunk = factor(chunk),\n    fill = ifelse(sentiment &gt;= 0, \"#1046b1\", \"#d1241a\")\n  )\n\nwf &lt;- waterfall(swann,\n  rect_width = 1,\n  rect_border = NA,\n  rect_text_labels = rep(NA, nrow(swann)),\n  draw_axis.x = \"none\",\n  fill_by_sign = FALSE,\n  fill_colours = swann$fill\n) +\n  geom_hline(yintercept = 0, color = \"gray50\", size = .5, linetype = \"dashed\") +\n  scale_y_continuous(name = \"Sentiment (AFINN lexicon)\") +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    axis.title = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(size = 12, margin = margin(0, 10, 0, 0)),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(size = 11),\n    axis.ticks = element_blank(),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\nggdraw(wf) +\n  draw_image(\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1657565006l/133539._SY475_.jpg\",\n    x = .15, y = .3, halign = 0, valign = 0, scale = .4\n  ) +\n  draw_label(\"Swann's Way\",\n    x = .15 + .18, y = .3 + .16, hjust = 0, vjust = .5,\n    size = 14, fontfamily = \"karla\", fontface = \"bold\"\n  ) +\n  draw_label(\"by Marcel Proust\",\n    x = .15 + .18, y = .3 + .10, hjust = 0, vjust = .5,\n    size = 12, fontfamily = \"karla\"\n  )\n\n\n\n\n\nThis one surprised me. Odette’s unending torment of Swann didn’t strike me as particularly happy? I guess this demonstrates the limitations of literal-minded approaches to coding sentiments. If the work is heavy on irony, a word-based lexicon like AFINN wouldn’t really be able to catch that. \n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2022-11-25-roots/index.html",
    "href": "posts/2022-11-25-roots/index.html",
    "title": "The roots of economic development",
    "section": "",
    "text": "One of the most interesting economics papers I’ve ever read is the 2013 survey by Enrico Spolaore and Romain Wacziarg (SW) titled “How Deep Are the Roots of Economic Development?” There has long been an active, highly contentious discussion over why some countries today are rich while others are poor. As a citizen of a “poor” country, this was a big motivation for me to study economics.1\nThe proximate causes are relatively uncontroversial — Solow had it all laid out in 1956. Production turns inputs into output. More inputs mean more output. Some output are consumed, some are saved (“invested”) and turned into capital, which are then used as inputs to produce more output. You can keep accumulating capital to grow your output, but over time, for a given state of technology, capital accumulation will hit diminishing returns. You will then need to move up the technological ladder to continue increasing output. Repeat until rich.\nThe Solow model is elegant, but it has the flavor of saying that a business is successful because it makes a lot of money. The deeper question is why some countries have managed to perform these pro-growth activities while others have not. Is it something in their culture? Maybe their geography? Maybe they had a Great Leader who put all the pieces in place?\nThis has been the research agenda of a number of empirical economic historians. Their work supplements that of traditional economic historians by quantifying the evidence for various hypothesized root causes of development. SW survey their findings as of 2013 using a unified dataset available here. What I want to do is chart some of the more interesting results.\nlibrary(tidyverse)\nlibrary(foreign)\n\ndf &lt;- here::here(\"datasets\", \"roots\", \"2013_longterm.dta\") %&gt;%\n  read.dta() %&gt;%\n  as_tibble()\nGeography is a natural candidate for explaining the relative wealth of nations. Ever notice that cold countries tend to be richer than hot ones? In fact, it’s empirically well-founded:\nCode\nlibrary(highcharter)\nlibrary(broom)\n\npretty &lt;- function(n, d = 0) {\n  n &lt;- format(round(n, digits = d), nsmall = d)\n  prettyNum(n, big.mark = \",\", scientific = FALSE)\n}\n\ndf1 &lt;- df %&gt;%\n  select(country, rgdpch_2005, avelat) %&gt;%\n  drop_na() %&gt;%\n  mutate(rgdpch_2005_pretty = pretty(rgdpch_2005, 0))\n\nfit &lt;- lm(log10(rgdpch_2005) ~ avelat, data = df1) %&gt;%\n  augment() %&gt;%\n  arrange(avelat) %&gt;%\n  slice(c(1, nrow(df1)))\n\nx &lt;- c(\"Country\", \"GDP per capita\", \"Absolute latitude\")\ny &lt;- c(\"{point.country:s}\", \"${point.rgdpch_2005_pretty:s}\", \"{point.avelat:.1f}\")\ntltip &lt;- tooltip_table(x, y)\n\nhchart(df1, \"scatter\",\n  hcaes(x = avelat, y = rgdpch_2005),\n  color = hex_to_rgba(\"#1046b1\", 0.5),\n  size = 20,\n  stickyTracking = FALSE\n) %&gt;%\n  hc_xAxis(\n    title = list(text = \"Absolute latitude\"),\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"GDP per capita 2005\"),\n    type = \"logarithmic\",\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = tltip,\n    headerFormat = \"\"\n  ) %&gt;%\n  hc_add_series(\n    data = fit,\n    type = \"spline\",\n    hcaes(x = avelat, y = 10^.fitted),\n    color = \"black\",\n    lineWidth = 1,\n    marker = FALSE,\n    enableMouseTracking = FALSE\n  )\nWhat explains this intriguing correlation? SW divide proposed mechanisms into direct and indirect channels. Geography may have a direct influence on economic development through the effects of climate and diseases on agricultural and labor productivity. Or in cruder form, this is the argument that hotter weather makes for lazier people, which Rizal refuted in “The Indolence of the Filipino”.\nArguments for an indirect channel are, for me, more convincing. Geography influenced x, and x in turn influenced economic development. There may even be additional layers (x influenced y, y influenced z, etc.). A famous hypothesis comes from Jared Diamond’s 1997 book Guns, Germs, and Steel, which argues that climate and the ecosystems it supported influenced the onset of agriculture and domestication in a society, what is known as the Neolithic Revolution. In turn, societies that transitioned earlier would have had a head start in technological progress and centralized governments. This explains why Europeans had the advantage of “guns, germs, and steel” as they were conquering the civilizations of New World America in the 16th century.\nTo illustrate the Diamond hypothesis, the following plots population density in the year 1500 against the years since a country had undergone its Neolithic Revolution — population density being the best proxy available for relative economic development in a pre-industrial world. Again, a positive correlation is established.\nCode\ndf1 &lt;- df %&gt;%\n  select(country, pd1500, agyears) %&gt;%\n  drop_na() %&gt;%\n  mutate(\n    pd1500_pretty = pretty(pd1500, 2),\n    agyears_pretty = pretty(agyears, 0)\n  )\n\nfit &lt;- lm(log10(pd1500) ~ agyears, data = df1) %&gt;%\n  augment() %&gt;%\n  arrange(agyears) %&gt;%\n  slice(c(1, nrow(df1)))\n\nx &lt;- c(\"Country\", \"Population density in 1500\", \"Years since Neolithic Revolution\")\ny &lt;- c(\"{point.country:s}\", \"{point.pd1500_pretty:s}\", \"{point.agyears_pretty:s}\")\ntltip &lt;- tooltip_table(x, y)\n\nhchart(df1, \"scatter\",\n  hcaes(x = agyears, y = pd1500),\n  color = hex_to_rgba(\"#1046b1\", 0.5),\n  size = 20,\n  stickyTracking = FALSE\n) %&gt;%\n  hc_xAxis(\n    title = list(text = \"Years since Neolithic Revolution\"),\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"Population density 1500\"),\n    type = \"logarithmic\",\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = tltip,\n    headerFormat = \"\"\n  ) %&gt;%\n  hc_add_series(\n    data = fit,\n    type = \"spline\",\n    hcaes(x = agyears, y = 10^.fitted),\n    color = \"black\",\n    lineWidth = 1,\n    marker = FALSE,\n    enableMouseTracking = FALSE\n  )\nThere is another reason why it makes more sense to use economic development as of 1500 rather than as of today. If geography shapes economic destinies, then how do we account for countries whose peoples are, in the grand scale of things, relative newcomers to the environments they now inhabit? These include European migrants to the New World as well as African slaves forcibly transported to New World colonies. If it takes thousands of years for geography to shape human cultures and institutions, then an English colonist who settled in what is now the United States would have been influenced by English rather than American geography.\nIn short, one must take into account the historical composition of a given country’s population when correlating geographic factors to contemporary development. This motivates the World Migration Matrix constructed by Louis Putterman and David N. Weil, which, for 165 countries, gives “an estimate of the proportion of the ancestors in 1500 of that country’s population today that were living within what are now the borders of that and each of the other countries”. To take one example, among the present-day inhabitants of Cuba, Putterman and Weil estimate that 63% of their ancestors originate from Spain, 5.6% from Nigeria, 5.1% from Ghana, 4.9% from Angola, and so on. Cuba today would exhibit the effects of the weighted average of all these different geographies.\nThe following map shows the countries with the highest proportion of “immigrants” relative to their present-day populations. In countries like Australia, Singapore, Taiwan, and Jamaica, very few of their current citizens have ancestors that were living in that country in 1500. On the opposite extreme are countries like China, Japan, Algeria, and Greece.\nCode\nlibrary(readxl)\nlibrary(countrycode)\n\nmm &lt;- here::here(\"datasets\", \"matrix version 1.1.xls\") %&gt;% \n  read_excel() %&gt;%\n  pivot_longer(\n    cols = !c(wbcode, wbname),\n    names_to = \"ancestry\",\n    values_to = \"share\"\n  ) %&gt;%\n  mutate(ancestry = toupper(ancestry)) %&gt;%\n  filter(wbcode == ancestry) %&gt;%\n  mutate(\n    immigrant = 1 - share,\n    iso_3 = countrycode(wbcode, \"wb\", \"iso3c\")\n  ) %&gt;%\n  select(iso_3, wbname, immigrant)\n\nmm$iso_3[mm$wbname == \"Congo, Dem. Rep.\"] &lt;- \"COD\"\nmm$iso_3[mm$wbname == \"East Timor\"] &lt;- \"TLS\"\nmm$iso_3[mm$wbname == \"Romania\"] &lt;- \"ROU\"\nmm$iso_3[mm$wbname == \"Taiwan, China\"] &lt;- \"TWN\"\n\nformattp &lt;- JS(\"function() {\n  if (this.point.value &lt; 0.01) {\n    return '&lt;b&gt;' + this.point.name + '&lt;/b&gt;: &lt;0.01';\n  }\n  else {\n    if (this.point.value &gt; 0.99) {\n      return '&lt;b&gt;' + this.point.name + '&lt;/b&gt;: &gt;0.99';\n    }\n    else {\n      return '&lt;b&gt;' + this.point.name + '&lt;/b&gt;: ' + Highcharts.numberFormat(this.point.value, 2);\n    }\n  }\n}\")\n\nhcmap(\n  map = \"custom/world-highres3\",\n  data = mm,\n  name = \"Share of population that arrived after 1500\",\n  value = \"immigrant\",\n  borderWidth = .5,\n  joinBy = c(\"iso-a3\", \"iso_3\")\n) %&gt;%\n  hc_legend(\n    align = \"left\",\n    title = list(text = \"Share of population that arrived after 1500\")\n  ) %&gt;%\n  hc_mapNavigation(enabled = TRUE) %&gt;%\n  hc_tooltip(\n    headerFormat = \"\",\n    formatter = formattp\n  )\nApplying an “ancestry adjustment” to the Diamond hypothesis makes a significant difference. The first chart below plots GDP per capita today and the years since the Neolithic Revolution. There is a positive correlation, albeit a weak one. The second chart plots GDP per capita against the ancestry-adjusted years since the Neolithic Revolution. Doing this strengthens the correlation. This suggests that (1) people were shaped by their environment, and (2) they brought their cultures and institutions with them during the great post-1500 migrations.\nThe correlations above provide pretty fascinating insights. But they are all flawed, of course. Countries are not random realizations of a well-defined stochastic process. Nor are they equal: when generalizing about long-run economic development, it’s not clear that the experiences of a Singapore or a Cape Verde should hold equal weight to the experiences of an India or a China. Which are the exceptions and which are the rules? Do rules even exist?\nThe field of empirical economic history has done much to extend, refine, and qualify the basic results shown here. Hopefully I’ll write about them in future posts."
  },
  {
    "objectID": "posts/2022-11-25-roots/index.html#unadjusted",
    "href": "posts/2022-11-25-roots/index.html#unadjusted",
    "title": "The roots of economic development",
    "section": "Unadjusted",
    "text": "Unadjusted\n\n\nCode\ndf1 &lt;- df %&gt;%\n  select(country, rgdpch_2005, agyears) %&gt;%\n  drop_na() %&gt;%\n  mutate(\n    rgdpch_2005_pretty = pretty(rgdpch_2005, 0),\n    agyears_pretty = pretty(agyears, 0)\n  )\n\nfit &lt;- lm(log10(rgdpch_2005) ~ agyears, data = df1) %&gt;%\n  augment() %&gt;%\n  arrange(agyears) %&gt;%\n  slice(c(1, nrow(df1)))\n\nx &lt;- c(\"Country\", \"GDP per capita\", \"Years since Neolithic Revolution\")\ny &lt;- c(\"{point.country:s}\", \"${point.rgdpch_2005_pretty:s}\", \"{point.agyears_pretty:s}\")\ntltip &lt;- tooltip_table(x, y)\n\nhchart(df1, \"scatter\",\n  hcaes(x = agyears, y = rgdpch_2005),\n  color = hex_to_rgba(\"#1046b1\", 0.5),\n  size = 20,\n  stickyTracking = FALSE\n) %&gt;%\n  hc_xAxis(\n    title = list(text = \"Years since Neolithic Revolution\"),\n    gridLineWidth = 1,\n    min = 0, max = 11000\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"GDP per capita 2005\"),\n    type = \"logarithmic\",\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = tltip,\n    headerFormat = \"\"\n  ) %&gt;%\n  hc_add_series(\n    data = fit,\n    type = \"spline\",\n    hcaes(x = agyears, y = 10^.fitted),\n    color = \"black\",\n    lineWidth = 1,\n    marker = FALSE,\n    enableMouseTracking = FALSE\n  )"
  },
  {
    "objectID": "posts/2022-11-25-roots/index.html#ancestry-adjusted",
    "href": "posts/2022-11-25-roots/index.html#ancestry-adjusted",
    "title": "The roots of economic development",
    "section": "Ancestry-adjusted",
    "text": "Ancestry-adjusted\n\n\nCode\ndf1 &lt;- df %&gt;%\n  select(country, rgdpch_2005, adjagyears) %&gt;%\n  drop_na() %&gt;%\n  mutate(\n    rgdpch_2005_pretty = pretty(rgdpch_2005, 0),\n    adjagyears_pretty = pretty(adjagyears, 0)\n  )\n\nfit &lt;- lm(log10(rgdpch_2005) ~ adjagyears, data = df1) %&gt;%\n  augment() %&gt;%\n  arrange(adjagyears) %&gt;%\n  slice(c(1, nrow(df1)))\n\nx &lt;- c(\"Country\", \"GDP per capita\", \"Years since Neolithic Revolution\")\ny &lt;- c(\"{point.country:s}\", \"${point.rgdpch_2005_pretty:s}\", \"{point.adjagyears_pretty:s}\")\ntltip &lt;- tooltip_table(x, y)\n\nhchart(df1, \"scatter\",\n  hcaes(x = adjagyears, y = rgdpch_2005),\n  color = hex_to_rgba(\"#1046b1\", 0.5),\n  size = 20,\n  stickyTracking = FALSE\n) %&gt;%\n  hc_xAxis(\n    title = list(text = \"Years since Neolithic Revolution (ancestry-adjusted)\"),\n    gridLineWidth = 1,\n    min = 0, max = 11000\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"GDP per capita 2005\"),\n    type = \"logarithmic\",\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = tltip,\n    headerFormat = \"\"\n  ) %&gt;%\n  hc_add_series(\n    data = fit,\n    type = \"spline\",\n    hcaes(x = adjagyears, y = 10^.fitted),\n    color = \"black\",\n    lineWidth = 1,\n    marker = FALSE,\n    enableMouseTracking = FALSE\n  )"
  },
  {
    "objectID": "posts/2022-11-25-roots/index.html#data",
    "href": "posts/2022-11-25-roots/index.html#data",
    "title": "The roots of economic development",
    "section": "Data",
    "text": "Data\n\n\n2013_longterm.dta"
  },
  {
    "objectID": "posts/2022-11-25-roots/index.html#footnotes",
    "href": "posts/2022-11-25-roots/index.html#footnotes",
    "title": "The roots of economic development",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTen years later and I still don’t have clear answers.↩︎"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html",
    "href": "posts/2022-11-26-migration/index.html",
    "title": "More on the great post-1500 migrations",
    "section": "",
    "text": "In my last post I brought up the World Migration Matrix, an ambitious dataset constructed in 2009 by Louis Putterman and David N. Weil that attempts to trace the ancestral origins of the present-day populations of nearly every country on Earth. It’s a complete matrix, so that you can pick any pair of countries and obtain the share of one country’s ancestors that originated from the other, and vice versa. It’s a deeply fascinating dataset and I thought I’d play around with it some more. (It’s also a chance to familiarize myself further with Highcharts.)\nPreviously, I plotted the immigrant share of each country, i.e. the share of its current population whose ancestors were not living in that country in the year 1500 (using modern borders). A related question to ask is, what is the ancestral diversity of each country? We encountered cases like Taiwan where nearly all inhabitants have “foreign” ancestors, but since a huge portion come from China, its resulting ancestral diversity is quite low. Contrast that with, say, the United States, where both the immigrant share is high and the ancestral country sources are very diverse.\nTo quantify this more formally, I use 1 minus the HH index as a measure of ancestral diversity. It takes a bit of data processing so I’m hiding the code below.\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(countrycode)\n\nmm_raw &lt;- here::here(\"datasets\", \"matrix version 1.1.xls\") %&gt;% \n  read_excel() %&gt;%\n  select(-update) %&gt;%\n  pivot_longer(\n    cols = !c(wbcode, wbname),\n    names_to = \"origin\",\n    values_to = \"share\"\n  )\n\n# Convert to ISO names and codes\n\nmm &lt;- mm_raw %&gt;%\n  mutate(\n    origin = toupper(origin),\n    country_iso3 = countrycode(wbcode, \"wb\", \"iso3c\"),\n    origin_iso3 = countrycode(origin, \"wb\", \"iso3c\")\n  )\n\nmm$country_iso3[mm$wbcode == \"ZAR\"] &lt;- mm$origin_iso3[mm$origin == \"ZAR\"] &lt;- \"COD\"\nmm$country_iso3[mm$wbcode == \"TMP\"] &lt;- mm$origin_iso3[mm$origin == \"TMP\"] &lt;- \"TLS\"\nmm$country_iso3[mm$wbcode == \"ROM\"] &lt;- mm$origin_iso3[mm$origin == \"ROM\"] &lt;- \"ROU\"\nmm$country_iso3[mm$wbcode == \"OAN\"] &lt;- mm$origin_iso3[mm$origin == \"OAN\"] &lt;- \"TWN\"\n\nmm &lt;- mm %&gt;%\n  mutate(\n    country_name = countrycode(country_iso3, \"iso3c\", \"country.name\"),\n    origin_name = countrycode(origin_iso3, \"iso3c\", \"country.name\"),\n    country_region = countrycode(country_iso3, \"iso3c\", \"continent\"),\n    origin_region = countrycode(origin_iso3, \"iso3c\", \"continent\")\n  ) %&gt;%\n  select(country_iso3, country_name, country_region, origin_iso3, origin_name, origin_region, share) %&gt;%\n  drop_na()\n\n# Compute immigrant share\n\nmm_immig &lt;- mm %&gt;%\n  filter(country_iso3 == origin_iso3) %&gt;%\n  mutate(immig = 1 - share) %&gt;%\n  select(country_iso3, country_name, country_region, immig)\n\n# Compute ancestral diversity\n\nmm_hhi &lt;- mm %&gt;%\n  mutate(share2 = share^2) %&gt;%\n  group_by(country_iso3, country_name, country_region) %&gt;%\n  summarize(hhi = 1 - sum(share2)) %&gt;%\n  ungroup()\n\nmm_immig_hhi &lt;- mm_immig %&gt;%\n  left_join(mm_hhi)\nThe following scatter plots ancestral diversity against the immigrant share of ancestors. They go hand-in-hand up to a point, and then we encounter enormous variety. I was surprised to find that the country with the most diverse set of ancestors is Jamaica, followed very closely by the United States. The other panels below showcase the ancestral origins of Jamaica and the U.S.\nNow let’s flip things around: which countries contributed the most to the immigrant share of populations worldwide? Here are the top 10 in terms of absolute amounts:\nCode\nlibrary(WDI)\n\npop &lt;- WDI(\n  country = \"all\",\n  indicator = c(\"pop\" = \"SP.POP.TOTL\"),\n  start = 2009,\n  end = 2009,\n) %&gt;%\n  as_tibble() %&gt;%\n  select(iso3c, pop) %&gt;%\n  bind_rows(tibble(\n    iso3c = \"TWN\",\n    pop = 23119772\n  ))\n\nmm_origin &lt;- mm %&gt;%\n  left_join(pop, by = c(\"country_iso3\" = \"iso3c\")) %&gt;%\n  mutate(\n    absolute = share * pop,\n    absolute_out = ifelse(country_iso3 == origin_iso3, 0, share * pop)\n  )\n\nmm_origin_sum &lt;- mm_origin %&gt;%\n  group_by(origin_iso3, origin_name, origin_region) %&gt;%\n  summarize(\n    share = mean(share),\n    absolute = sum(absolute),\n    absolute_out = sum(absolute_out)\n  ) %&gt;%\n  ungroup() %&gt;%\n  filter(absolute_out &gt; 0) %&gt;%\n  arrange(-absolute_out) %&gt;%\n  slice(1:10)\n\nmm_origin_sum &lt;- mm_origin_sum %&gt;%\n  mutate(origin_name = factor(origin_name, levels = mm_origin_sum$origin_name))\n\nhchart(mm_origin_sum, \"bar\",\n  hcaes(y = absolute_out, x = origin_name),\n  color = \"#1046b1\",\n  stickyTracking = FALSE\n) %&gt;%\n  hc_yAxis(\n    title = list(text = \"Global descendants outside of own country\"),\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_xAxis(title = list(text = \"\")) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = \"{point.absolute_out:,.0f}\",\n    headerFormat = \"\"\n  )\nAround the world, some 167 million people1 not living in Spain have ancestors who lived in Spain in the year 1500. It speaks to the legacy of European colonization and migration that the top 5 largest sources of immigrant ancestry are European countries.\nWhere did the descendants of these prolific exporters of people settle? Here are some more maps to give you an idea."
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#immigrant-share-vs-diversity",
    "href": "posts/2022-11-26-migration/index.html#immigrant-share-vs-diversity",
    "title": "More on the great post-1500 migrations",
    "section": "Immigrant share vs diversity",
    "text": "Immigrant share vs diversity\n\n\nCode\nlibrary(highcharter)\n\nx &lt;- c(\"Country\", \"Continent\", \"Immigrant share of ancestors\", \"Ancestral diversity\")\ny &lt;- c(\"{point.country_name:s}\", \"{point.country_region:s}\", \"{point.immig:.2f}\", \"{point.hhi:.2f}\")\ntltip &lt;- tooltip_table(x, y)\n\nhchart(mm_immig_hhi, \"scatter\",\n  hcaes(x = immig, y = hhi, group = country_region),\n  color = c(\"#1046b1\", \"#a835a6\", \"#f0307d\", \"#ff6549\", \"#ffa600\"),\n  stickyTracking = FALSE,\n  jitter = list(x = .005, y = .005)\n) %&gt;%\n  hc_xAxis(\n    title = list(text = \"Immigrant share of ancestors\"),\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"Ancestral diversity\"),\n    gridLineWidth = 1\n  ) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = tltip,\n    headerFormat = \"\"\n  )"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#jamaicas-ancestors",
    "href": "posts/2022-11-26-migration/index.html#jamaicas-ancestors",
    "title": "More on the great post-1500 migrations",
    "section": "Jamaica’s ancestors",
    "text": "Jamaica’s ancestors\n\n\nCode\njamaica &lt;- mm %&gt;%\n  filter(country_name == \"Jamaica\")\n\nformattp &lt;- JS(\"function() {\n  if (this.point.value &lt; 0.01) {\n    return '&lt;b&gt;' + this.point.name + '&lt;/b&gt;: &lt;0.01';\n  }\n  else {\n    return '&lt;b&gt;' + this.point.name + '&lt;/b&gt;: ' + Highcharts.numberFormat(this.point.value, 2);\n  }\n}\")\n\nhcmap(\n  map = \"custom/world-highres3\",\n  data = jamaica,\n  name = \"origin_name\",\n  value = \"share\",\n  borderWidth = .5,\n  joinBy = c(\"iso-a3\", \"origin_iso3\")\n) %&gt;%\n  hc_mapNavigation(enabled = TRUE) %&gt;%\n  hc_legend(\n    align = \"left\",\n    title = list(text = \"Ancestral contribution to Jamaica's population\")\n  ) %&gt;%\n  hc_tooltip(\n    headerFormat = \"\",\n    formatter = formattp\n  )"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#americas-ancestors",
    "href": "posts/2022-11-26-migration/index.html#americas-ancestors",
    "title": "More on the great post-1500 migrations",
    "section": "America’s ancestors",
    "text": "America’s ancestors\n\n\nCode\nusa &lt;- mm %&gt;%\n  filter(country_name == \"United States\")\n\nhcmap(\n  map = \"custom/world-highres3\",\n  data = usa,\n  name = \"origin_name\",\n  value = \"share\",\n  borderWidth = .5,\n  joinBy = c(\"iso-a3\", \"origin_iso3\")\n) %&gt;%\n  hc_mapNavigation(enabled = TRUE) %&gt;%\n  hc_legend(\n    align = \"left\",\n    title = list(text = \"Ancestral contribution to U.S. population\")\n  ) %&gt;%\n  hc_tooltip(\n    headerFormat = \"\",\n    formatter = formattp\n  )"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#spain",
    "href": "posts/2022-11-26-migration/index.html#spain",
    "title": "More on the great post-1500 migrations",
    "section": "Spain",
    "text": "Spain\n\n\nCode\nlibrary(CoordinateCleaner)\n\ncentroids &lt;- as_tibble(countryref) %&gt;%\n  filter(type == \"country\") %&gt;%\n  select(iso3, centroid.lon, centroid.lat) %&gt;%\n  group_by(iso3) %&gt;%\n  summarize(\n    lon = mean(centroid.lon),\n    lat = mean(centroid.lat)\n  ) %&gt;%\n  ungroup()\n\nspain &lt;- mm_origin %&gt;%\n  filter(origin_name == \"Spain\") %&gt;%\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %&gt;%\n  mutate(z = absolute_out)\n\nhcmap(\n  map = \"custom/world\",\n  borderWidth = .5,\n  showInLegend = FALSE\n) %&gt;%\n  hc_add_series(\n    data = spain,\n    type = \"mapbubble\",\n    maxSize = \"40\",\n    minSize = \"0\",\n    showInLegend = FALSE,\n    color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\n    tooltip = list(\n      headerFormat = \"\",\n      pointFormat = \"&lt;b&gt;{point.country_name}&lt;/b&gt;: {point.absolute_out:,.0f}\"\n    )\n  ) %&gt;%\n  hc_title(text = \"Distribution of Spanish descendants\")"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#portugal",
    "href": "posts/2022-11-26-migration/index.html#portugal",
    "title": "More on the great post-1500 migrations",
    "section": "Portugal",
    "text": "Portugal\n\n\nCode\nportugal &lt;- mm_origin %&gt;%\n  filter(origin_name == \"Portugal\") %&gt;%\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %&gt;%\n  mutate(z = absolute_out)\n\nhcmap(\n  map = \"custom/world\",\n  borderWidth = .5,\n  showInLegend = FALSE\n) %&gt;%\n  hc_add_series(\n    data = portugal,\n    type = \"mapbubble\",\n    maxSize = \"40\",\n    minSize = \"0\",\n    showInLegend = FALSE,\n    color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\n    tooltip = list(\n      headerFormat = \"\",\n      pointFormat = \"&lt;b&gt;{point.country_name}&lt;/b&gt;: {point.absolute_out:,.0f}\"\n    )\n  ) %&gt;%\n  hc_title(text = \"Distribution of Portuguese descendants\")"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#united-kingdom",
    "href": "posts/2022-11-26-migration/index.html#united-kingdom",
    "title": "More on the great post-1500 migrations",
    "section": "United Kingdom",
    "text": "United Kingdom\n\n\nCode\nuk &lt;- mm_origin %&gt;%\n  filter(origin_name == \"United Kingdom\") %&gt;%\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %&gt;%\n  mutate(z = absolute_out)\n\nhcmap(\n  map = \"custom/world\",\n  borderWidth = .5,\n  showInLegend = FALSE\n) %&gt;%\n  hc_add_series(\n    data = uk,\n    type = \"mapbubble\",\n    maxSize = \"40\",\n    minSize = \"0\",\n    showInLegend = FALSE,\n    color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\n    tooltip = list(\n      headerFormat = \"\",\n      pointFormat = \"&lt;b&gt;{point.country_name}&lt;/b&gt;: {point.absolute_out:,.0f}\"\n    )\n  ) %&gt;%\n  hc_title(text = \"Distribution of British descendants\")"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#china",
    "href": "posts/2022-11-26-migration/index.html#china",
    "title": "More on the great post-1500 migrations",
    "section": "China",
    "text": "China\n\n\nCode\nchina &lt;- mm_origin %&gt;%\n  filter(origin_name == \"China\") %&gt;%\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %&gt;%\n  mutate(z = absolute_out)\n\nhcmap(\n  map = \"custom/world\",\n  borderWidth = .5,\n  showInLegend = FALSE\n) %&gt;%\n  hc_add_series(\n    data = china,\n    type = \"mapbubble\",\n    maxSize = \"40\",\n    minSize = \"0\",\n    showInLegend = FALSE,\n    color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\n    tooltip = list(\n      headerFormat = \"\",\n      pointFormat = \"&lt;b&gt;{point.country_name}&lt;/b&gt;: {point.absolute_out:,.0f}\"\n    )\n  ) %&gt;%\n  hc_title(text = \"Distribution of Chinese descendants\")"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#india",
    "href": "posts/2022-11-26-migration/index.html#india",
    "title": "More on the great post-1500 migrations",
    "section": "India",
    "text": "India\n\n\nCode\nindia &lt;- mm_origin %&gt;%\n  filter(origin_name == \"India\") %&gt;%\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %&gt;%\n  mutate(z = absolute_out)\n\nhcmap(\n  map = \"custom/world\",\n  borderWidth = .5,\n  showInLegend = FALSE\n) %&gt;%\n  hc_add_series(\n    data = india,\n    type = \"mapbubble\",\n    maxSize = \"40\",\n    minSize = \"0\",\n    showInLegend = FALSE,\n    color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\n    tooltip = list(\n      headerFormat = \"\",\n      pointFormat = \"&lt;b&gt;{point.country_name}&lt;/b&gt;: {point.absolute_out:,.0f}\"\n    )\n  ) %&gt;%\n  hc_title(text = \"Distribution of Indian descendants\")"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#angola",
    "href": "posts/2022-11-26-migration/index.html#angola",
    "title": "More on the great post-1500 migrations",
    "section": "Angola",
    "text": "Angola\n\n\nCode\nangola &lt;- mm_origin %&gt;%\n  filter(origin_name == \"Angola\") %&gt;%\n  left_join(centroids, by = c(\"country_iso3\" = \"iso3\")) %&gt;%\n  mutate(z = absolute_out)\n\nhcmap(\n  map = \"custom/world\",\n  borderWidth = .5,\n  showInLegend = FALSE\n) %&gt;%\n  hc_add_series(\n    data = angola,\n    type = \"mapbubble\",\n    maxSize = \"40\",\n    minSize = \"0\",\n    showInLegend = FALSE,\n    color = hex_to_rgba(\"#1046b1\", alpha = 0.3),\n    tooltip = list(\n      headerFormat = \"\",\n      pointFormat = \"&lt;b&gt;{point.country_name}&lt;/b&gt;: {point.absolute_out:,.0f}\"\n    )\n  ) %&gt;%\n  hc_title(text = \"Distribution of Angolan descendants\")"
  },
  {
    "objectID": "posts/2022-11-26-migration/index.html#footnotes",
    "href": "posts/2022-11-26-migration/index.html#footnotes",
    "title": "More on the great post-1500 migrations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot meant to be literal since a person can be of mixed ancestry. Perhaps it is more proper to say there are 167 million “people-equivalent” whose ancestors came from Spain. But hey, we’re just having fun here!↩︎"
  },
  {
    "objectID": "posts/2022-12-03-war-is-over/index.html",
    "href": "posts/2022-12-03-war-is-over/index.html",
    "title": "War is over (if you want it?)",
    "section": "",
    "text": "People’s feelings about the Christmas season span a wide range, from very positive to very negative. As for where I fall, well:\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(lubridate)\n\ndf &lt;- here::here(\"datasets\", \"ucdp-prio-acd-221.csv\") %&gt;%\n  read_csv() %&gt;%\n  select(conflict_id, location, year, type_of_conflict, region, ep_end_date, region) %&gt;%\n  mutate(\n    type_of_conflict = factor(type_of_conflict),\n    xmas = as.Date(paste0(year, \"-12-25\")),\n    count = ifelse(!(ep_end_date &gt; xmas), 0, 1)\n  ) %&gt;%\n  replace_na(list(count = 1))\n\nconflicts &lt;- df %&gt;%\n  group_by(year, type_of_conflict) %&gt;%\n  summarize(count = sum(count)) %&gt;%\n  ungroup()\n\nggplot(conflicts, aes(x = year, y = count, fill = type_of_conflict)) +\n  geom_bar(stat = \"identity\", position = \"stack\", width = .7) +\n  geom_hline(yintercept = 0, linewidth = .25, color = \"black\") +\n  labs(\n    title = \"Another year over\",\n    subtitle = \"Active armed conflicts as of Christmas Day, 1946-2021\",\n    caption = \"Source: UCDP/PRIO Armed Conflict Dataset v.22.1\"\n  ) +\n  scale_fill_manual(\n    name = \"Type of conflict\",\n    labels = c(\"Extrasystemtic\", \"Interstate\", \"Intrastate\", \"Internationalized intrastate\"),\n    values = rev(c(\"#1046b1\", \"#c52e9b\", \"#ff505b\", \"#ffa600\"))\n  ) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 15)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.text.y = element_text(size = 12, margin = margin(r = 5)),\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 11, face = \"bold\", margin = margin(r = 10)),\n    legend.text = element_text(size = 11),\n    legend.key.size = unit(.4, \"lines\"),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(color = \"white\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nThe data is from the UCDP/PRIO Armed Conflict Dataset. I’ll go through how I constructed the above chart.\nFirst, some words about the dataset. Each observation is a conflict-year. A conflict is dated from its first battle-related death, but only active “episodes” — defined as 25 battle-related deaths — are recorded in the database. For example, the Basque conflict has the following entries:\n\nhere::here(\"datasets\", \"ucdp-prio-acd-221.csv\") %&gt;%\n  read_csv() %&gt;%\n  select(conflict_id, side_a, side_b, year, start_date, start_date2, ep_end_date) %&gt;%\n  filter(conflict_id == \"342\") %&gt;%\n  knitr::kable(align = \"c\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nconflict_id\nside_a\nside_b\nyear\nstart_date\nstart_date2\nep_end_date\n\n\n\n\n342\nGovernment of Spain\nETA\n1978\n1968-06-07\n1978-10-22\nNA\n\n\n342\nGovernment of Spain\nETA\n1979\n1968-06-07\n1978-10-22\nNA\n\n\n342\nGovernment of Spain\nETA\n1980\n1968-06-07\n1978-10-22\nNA\n\n\n342\nGovernment of Spain\nETA\n1981\n1968-06-07\n1978-10-22\nNA\n\n\n342\nGovernment of Spain\nETA\n1982\n1968-06-07\n1978-10-22\n1982-12-29\n\n\n342\nGovernment of Spain\nETA\n1985\n1968-06-07\n1985-12-23\nNA\n\n\n342\nGovernment of Spain\nETA\n1986\n1968-06-07\n1985-12-23\nNA\n\n\n342\nGovernment of Spain\nETA\n1987\n1968-06-07\n1985-12-23\n1987-12-31\n\n\n342\nGovernment of Spain\nETA\n1991\n1968-06-07\n1991-06-28\n1991-12-13\n\n\n\n\n\nWhile it is recorded as starting on 7 June 1968, its first active episode started on 22 October 1978 and lasted until 29 December 1982. A second episode occurred from 23 December 1985 to 31 December 1987, then a third from 28 June to 13 December 1991. For my purposes, this would count as an active conflict for the Christmas Days of 1978-1982 and 1985-1987. Not 1991 however, since that episode ended right before Christmas.\nFor each conflict-year, I therefore need to construct a dummy to indicate whether it is a Christmas conflict or not. I do it in three steps. First, I construct the variable xmas to set the Christmas Day for each year. Second, I set the variable count to 0 if the conflict-year’s ep_end_date occurs before Christmas. Finally, for all cases where ep_end_date is NA, I set count to 1.\n\ndf &lt;- here::here(\"datasets\", \"ucdp-prio-acd-221.csv\") %&gt;%\n  read_csv() %&gt;%\n  mutate(\n    xmas = as.Date(paste0(year, \"-12-25\")),\n    count = ifelse(!(ep_end_date &gt; xmas), 0, 1)\n  ) %&gt;%\n  replace_na(list(count = 1))\n\nThen it’s a simple matter of counting the active conflicts per year and constructing a bar chart. to illustrate the depressing fact that Christmas 2021 saw an all-time high in active conflicts worldwide.\nTo end, here’s the song that inspired this post. Have a bad Christmas season everybody. \n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2022-12-07-im-gonna-carry-that-weight/index.html",
    "href": "posts/2022-12-07-im-gonna-carry-that-weight/index.html",
    "title": "I’m gonna carry that weight",
    "section": "",
    "text": "The pandemic (and turning 30) made me really start paying more attention to my health, and one of my resolutions was to go to the gym more consistently. It’s now been a little over a year. At the moment, my one-rep max for squats is about 1.5x my body weight, while for bench, it’s about 1.15x. As a motivator, I thought I’d look for benchmarks to work towards this coming year.\nMy basis will be this Kaggle dataset that contains the lifting records of over 400,000 powerlifting competitors, as listed in OpenPowerlifting.org. I might be setting the bar(bell) a bit high for myself here since I am by no means a competitive powerlifter, but consider that most people who join powerlifting comps aren’t particularly good. In fact, most of them lose! In the aggregate, the dataset will probably be a good sample of the population I’m looking to compare myself against — men who lift regularly.\nHere are its columns:\n\nlibrary(tidyverse)\n\nhere::here(\"datasets\", \"openpowerlifting.csv\") %&gt;%\n  read_csv() %&gt;%\n  names()\n\n [1] \"Name\"            \"Sex\"             \"Event\"           \"Equipment\"      \n [5] \"Age\"             \"AgeClass\"        \"Division\"        \"BodyweightKg\"   \n [9] \"WeightClassKg\"   \"Squat1Kg\"        \"Squat2Kg\"        \"Squat3Kg\"       \n[13] \"Squat4Kg\"        \"Best3SquatKg\"    \"Bench1Kg\"        \"Bench2Kg\"       \n[17] \"Bench3Kg\"        \"Bench4Kg\"        \"Best3BenchKg\"    \"Deadlift1Kg\"    \n[21] \"Deadlift2Kg\"     \"Deadlift3Kg\"     \"Deadlift4Kg\"     \"Best3DeadliftKg\"\n[25] \"TotalKg\"         \"Place\"           \"Wilks\"           \"McCulloch\"      \n[29] \"Glossbrenner\"    \"IPFPoints\"       \"Tested\"          \"Country\"        \n[33] \"Federation\"      \"Date\"            \"MeetCountry\"     \"MeetState\"      \n[37] \"MeetName\"       \n\n\nI’ll subset this to keep it as relevant as possible to myself: I’ll retain males lifters only (Sex == \"M\"); I’ll remove records from competitions that do not require drug testing (Test == \"Yes\"); and I’ll remove all failed attempts, which are recorded as negative of the weight attempted (Best3SquatKg &gt; 0 & Best3BenchKg &gt; 0). I will then compute the ratios of the maximum weight lifted in the squat and bench press to the lifter’s body weight.\n\ndf &lt;- here::here(\"datasets\", \"openpowerlifting.csv\") %&gt;%\n  read_csv() %&gt;%\n  filter(Sex == \"M\" & Tested == \"Yes\" & Best3SquatKg &gt; 0 & Best3BenchKg &gt; 0) %&gt;%\n  select(Name, Age, Date, BodyweightKg, Best3SquatKg, Best3BenchKg) %&gt;%\n  mutate(\n    Ratio_Squat = Best3SquatKg / BodyweightKg,\n    Ratio_Bench = Best3BenchKg / BodyweightKg\n  ) %&gt;%\n  arrange(Name, Date) %&gt;%\n  drop_na()\n\nI am left with 234,174 observations on 76,233 lifters. To get an idea of what the data looks like, here are the records of some arbitrary guy I picked out named Linh Vu:\n\ndf %&gt;%\n  filter(Name == \"Linh Vu\") %&gt;%\n  knitr::kable(align = \"lccrrrrr\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nAge\nDate\nBodyweightKg\nBest3SquatKg\nBest3BenchKg\nRatio_Squat\nRatio_Bench\n\n\n\n\nLinh Vu\n26.5\n2010-09-19\n82.40\n155.0\n90.0\n1.881068\n1.092233\n\n\nLinh Vu\n26.5\n2010-11-28\n82.65\n160.0\n90.0\n1.935874\n1.088929\n\n\nLinh Vu\n27.5\n2011-03-26\n82.68\n157.5\n92.5\n1.904935\n1.118771\n\n\nLinh Vu\n27.5\n2011-06-26\n87.85\n170.0\n105.0\n1.935117\n1.195219\n\n\nLinh Vu\n28.5\n2012-11-25\n82.20\n170.0\n90.0\n2.068126\n1.094890\n\n\nLinh Vu\n29.5\n2013-05-26\n82.10\n175.0\n95.0\n2.131547\n1.157126\n\n\nLinh Vu\n29.5\n2013-08-18\n81.05\n177.5\n105.0\n2.190006\n1.295497\n\n\nLinh Vu\n29.5\n2013-12-01\n73.85\n162.5\n105.0\n2.200406\n1.421801\n\n\nLinh Vu\n30.5\n2014-04-27\n73.80\n160.0\n105.0\n2.168022\n1.422764\n\n\nLinh Vu\n30.5\n2014-11-23\n73.80\n175.0\n102.5\n2.371274\n1.388889\n\n\nLinh Vu\n31.5\n2015-04-26\n73.40\n182.5\n107.5\n2.486376\n1.464578\n\n\nLinh Vu\n31.5\n2015-08-14\n72.25\n190.0\n107.5\n2.629758\n1.487889\n\n\n\n\n\nI want to get a sense of how ratios are distributed across the population, so I’ll have to keep just one record from lifters with multiple records. I thought about taking the average, but instead I opted to just choose one at random.\n\ndf1 &lt;- df %&gt;%\n  group_by(Name) %&gt;%\n  slice_sample(n = 1) %&gt;%\n  ungroup()\n\nSince we’re looking at the distribution of two variables, a good plot use is a 2D histogram, implemented using geom_bin_2d from ggplot.\n\n\nCode\nlibrary(ggplot2)\n\n# Number of observations in comma-separated format\nn &lt;- df$Name %&gt;%\n  unique() %&gt;%\n  length() %&gt;%\n  prettyNum(big.mark = \",\", scientific = FALSE)\n\nggplot(df1, aes(x = Ratio_Squat, y = Ratio_Bench)) +\n  geom_bin_2d(binwidth = .1) +\n\n  # Label: Me\n  geom_rect(\n    xmin = 1.5, xmax = 1.6, ymin = 1.1, ymax = 1.2,\n    fill = \"#cc0700\", color = \"#8c0803\", linewidth = .75\n  ) +\n  annotate(\"text\",\n    x = 1.6 + .2, y = 1.1 - .4, hjust = 0, vjust = 1,\n    label = \"Me!\", size = 14 / .pt, family = \"karla\", fontface = \"bold\", color = \"#cc0700\"\n  ) +\n  geom_segment(\n    x = 1.6 - .01, xend = 1.6 + .15, y = 1.1 - .07, yend = 1.1 - .37,\n    color = \"#cc0700\", linewidth = .5\n  ) +\n\n  # Label: Mode\n  geom_rect(\n    xmin = 2.1, xmax = 2.2, ymin = 1.4, ymax = 1.5,\n    fill = NA, color = \"black\", linewidth = .75\n  ) +\n  annotate(\"text\",\n    x = 2.2 + .5, y = 1.4, hjust = 0, vjust = 1,\n    label = \"Mode\", size = 14 / .pt, family = \"karla\", fontface = \"bold\", color = \"black\"\n  ) +\n  geom_segment(\n    x = 2.2 + .07, xend = 2.2 + .45, y = 1.4 + .04, yend = 1.4 - .05,\n    color = \"black\", linewidth = .5\n  ) +\n\n  # Labels\n  labs(\n    title = \"Ratio of max weight lifted to body weight\",\n    subtitle = paste0(\"Data on \", n, \" natural male lifters\")\n  ) +\n  scale_x_continuous(name = \"Squat\", limits = c(.2, 5.5), breaks = 1:6) +\n  scale_y_continuous(name = \"Bench\", limits = c(.2, 3.5), breaks = 1:4) +\n\n  # Legend\n  scale_fill_gradient(\n    low = \"gray94\", high = \"#1046b1\", guide = \"colorbar\",\n    breaks = c(250, 500, 750, 1000)\n  ) +\n  guides(fill = guide_colorbar(\n    title = \"Count\",\n    title.position = \"top\", title.vjust = 1, title.hjust = .5,\n    barwidth = unit(.75, \"lines\"),\n    barheight = unit(8, \"lines\"),\n    ticks = FALSE\n  )) +\n\n  # Theme\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 15)),\n    axis.ticks = element_blank(),\n    axis.title.x = element_text(size = 12, margin = margin(t = 10)),\n    axis.title.y = element_text(size = 12, margin = margin(r = 10)),\n    axis.text.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.text.y = element_text(size = 12, margin = margin(r = 5)),\n    legend.position = \"right\",\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.text = element_text(size = 10),\n    panel.background = element_rect(fill = \"gray98\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nThe mode is 2.1-2.2x for squat and 1.4-1.5x for bench. I’m some ways off from the histogram’s central tendency, but not as far as I thought! Getting to that dark blue region is totally doable. I’ll revisit this chart a year from now and see where I am.\nAs a bonus, it might also be interesting to divide the lifters into age brackets and see how the distribution changes. My guess is that lifters in their mid-20s would be stronger than lifters in their late 30s. However, here is what I get:\n\n\nCode\nlibrary(cowplot)\n\n# Common plot elements\n\nbin &lt;- geom_bin_2d(binwidth = .1)\nme_box &lt;- geom_rect(\n  xmin = 1.5, xmax = 1.6, ymin = 1.1, ymax = 1.2,\n  fill = \"#cc0700\", color = \"#8c0803\", linewidth = .25\n)\nfill &lt;- scale_fill_gradient(low = \"gray94\", high = \"#1046b1\")\nx_axis &lt;- scale_x_continuous(name = \"Squat\", limits = c(.5, 4), breaks = 1:4)\ny_axis &lt;- scale_y_continuous(name = \"Bench\", limits = c(.5, 4), breaks = 1:4)\ntheme &lt;- theme_minimal(base_family = \"karla\") +\n  theme(\n    panel.background = element_rect(fill = \"gray98\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.x = element_text(size = 11, margin = margin(t = 5)),\n    axis.title.y = element_text(size = 11, margin = margin(r = 5)),\n    axis.text = element_text(size = 10),\n    legend.position = \"none\"\n  )\n\n# Plots\n\np1 &lt;- ggplot(\n  df1 %&gt;% filter(Age %in% 26:30),\n  aes(x = Ratio_Squat, y = Ratio_Bench)\n) +\n  bin +\n  me_box +\n  fill +\n  x_axis +\n  y_axis +\n  theme +\n  annotate(\"text\",\n    x = 1.2, y = 2.2, size = 9 / .pt, hjust = .5, vjust = .5,\n    label = \"Me!\", family = \"karla\", fontface = \"bold\", color = \"#cc0700\"\n  ) +\n  geom_segment(\n    x = 1.5, xend = 1.3, y = 1.2 + .1, yend = 2.2 - .25,\n    color = \"#cc0700\", linewidth = .25\n  )\n\np2 &lt;- ggplot(\n  df1 %&gt;% filter(Age %in% 31:35),\n  aes(x = Ratio_Squat, y = Ratio_Bench)\n) +\n  bin + me_box + fill + x_axis + y_axis + theme\n\np3 &lt;- ggplot(\n  df1 %&gt;% filter(Age %in% 36:40),\n  aes(x = Ratio_Squat, y = Ratio_Bench)\n) +\n  bin + me_box + fill + x_axis + y_axis + theme\n\n# Consolidate\n\ntitle &lt;- ggdraw() +\n  draw_label(\"Ratio of max weight lifted to body weight, by age group\",\n    fontfamily = \"karla\", fontface = \"bold\", x = .5, hjust = .5, size = 13\n  ) +\n  theme(plot.margin = margin(t = -15, b = 10))\n\nplots &lt;- plot_grid(p1, p2, p3,\n  nrow = 1,\n  labels = c(\"Aged 26-30\", \"Aged 31-35\", \"Aged 36-40\"),\n  label_size = 11, label_fontfamily = \"karla\", label_fontface = \"plain\",\n  hjust = -1.4, vjust = -.9\n)\n\nplot_grid(title, plots, ncol = 1, rel_heights = c(.2, 1))\n\n\n\n\n\nThe histograms don’t actually differ all that much. It’s possible that the bodily disadvantages of age are offset by the skills advantages of more training and experience. Just look at Linh Vu! \n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2022-12-15-mountains/index.html",
    "href": "posts/2022-12-15-mountains/index.html",
    "title": "Luzon’s hiking trails",
    "section": "",
    "text": "I have lately been experimenting with R’s map-making capabilities, and as a project I wanted to try visualizing the great mountain ranges of Luzon. The Philippines has some remarkable mountain ranges, and hiking through them is a unique sort of pleasure that I only discovered recently.\nAn obvious approach would be to make a relief map, with colors corresponding to elevation, but to make it more interesting I decided to create a more stylized ridgeline-style map. A ridge plot is… hard to describe. Look up the album cover of Joy Division’s Unknown Pleasures and you’ll understand. I am indebted to dieghernan’s tutorial on mapping with ridgelines.1\nLet’s start by loading up the basic packages.\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(terra)\nThe coastline of the Philippines can be obtained from the rnaturalearth package.\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(rnaturalearthhires)\n\nph &lt;- ne_countries(scale = 10, country = \"Philippines\", returnclass = \"sf\")\n\nluzon &lt;- ph %&gt;%\n  st_crop(\n    xmin = st_bbox(ph)$xmin %&gt;% as.numeric(),\n    xmax = st_bbox(ph)$xmax %&gt;% as.numeric(),\n    ymin = 13.5,\n    ymax = 18.5\n  ) %&gt;%\n  st_transform(25391)\nThis returns a simple features or sf object, which has a geometry column that draws the coastline of the Philippines. The st_crop() function subsets the polygon to our area of interest while the st_transform() function sets the coordinate reference system to “Luzon 1911 / Philippines zone I” (EPSG code 25391).\nBecause this only draws the coastline, the major Luzon lakes of Laguna de Bay and Taal are not defined. We can load their polygons from rnaturalearth as well:\nlakes &lt;- ne_download(scale = 10, type = \"lakes\", category = \"physical\", returnclass = \"sf\") %&gt;%\n  mutate(in_luzon = str_detect(name, \"Laguna de Bay|Taal\")) %&gt;%\n  filter(in_luzon == TRUE) %&gt;%\n  st_transform(25391) %&gt;%\n  summarize()\nWe can then use lakes to “punch holes” into the luzon polygon:\nluzon &lt;- st_difference(st_geometry(luzon), st_geometry(lakes))\n\nplot(luzon)\nTo draw the ridges that symbolize Luzon’s mountain ranges, we need elevation raster data. This is taken from the elevatr package using the get_elev_raster() function.\nlibrary(elevatr)\n\ndem &lt;- get_elev_raster(luzon, z = 7, clip = \"bbox\", expand = NULL) %&gt;%\n  rast() %&gt;%\n  mask(vect(luzon))\n\nnames(dem) &lt;- \"elev\"\nThe rast() function converts it into a SpatRaster object, which is native to the terra package. The mask() function removes all cells outside the luzon polygon.\nThis raster actually provides more granularity than we want, so we aggregate the cells up to get a lower resolution. Then we convert it to a data.frame for plotting with ggplot2.\ndem_agg &lt;- aggregate(dem, round(nrow(dem) / 200))\ndem_df &lt;- as.data.frame(dem_agg, xy = TRUE, na.rm = FALSE)\nThe luzon polygon is plotted using geom_sf() while the ridgelines obtained from elevated data are plotted using geom_ridgeline() from the ggridges packages.\nlibrary(ggplot2)\nlibrary(ggridges)\n\n# Set expanded boundaries\ncoords &lt;- st_bbox(c(xmin = 118.75, xmax = 125.75, ymin = 13.75, ymax = 18.25),\n  crs = 4326\n) %&gt;%\n  st_as_sfc() %&gt;%\n  st_transform(25391) %&gt;%\n  st_coordinates()\n\nmap &lt;- ggplot() +\n  geom_sf(data = luzon, color = NA, fill = \"#069801\") +\n  geom_ridgeline(\n    data = dem_df,\n    aes(x = x, y = y, group = y, height = elev),\n    scale = 25, fill = \"#84502e\", color = \"#4f3321\"\n  ) +\n  coord_sf(\n    xlim = coords[c(1, 2), 1],\n    ylim = coords[c(2, 3), 2],\n    expand = FALSE\n  ) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme_ridges() +\n  theme(\n    plot.margin = margin(0, 0, 0, 0),\n    panel.background = element_rect(fill = \"#b8dfff\"),\n    panel.grid.major = element_line(color = \"#a5d0f3\"),\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks.length = unit(0, \"cm\"),\n  )\nmap\nYou can see how vividly the ridgelines capture Luzon’s mountains. It’s practically 3D!\nI now want to add markers for some of the more famous hiking trails in Luzon. I can easily get their coordinates using Google Maps, but a complication to deal with is that the coordinate reference system (CRS) of Google Maps is different from the one I’m using here. I must therefore use st_transform() to reproject them first.\nspots &lt;- here::here(\"datasets\", \"hikingspots.csv\") %&gt;% \n  read_csv() %&gt;%\n  mutate(label = toupper(label))\n\ncoords &lt;- spots %&gt;%\n  st_as_sf(agr = \"constant\", coords = c(\"x\", \"y\"), crs = 4326) %&gt;%\n  st_transform(25391) %&gt;%\n  st_coordinates()\n\nspots &lt;- cbind(spots, coords)\nFinally, I downloaded some Google fonts for some added fanciness. Here is the final chart:\nCode\nlibrary(ggrepel)\n\nmap +\n  geom_point(\n    data = spots,\n    aes(x = X, y = Y),\n    size = 2.5, shape = 24, linewidth = .75, color = \"white\", fill = \"black\"\n  ) +\n  geom_label_repel(\n    data = spots,\n    aes(x = X, y = Y, label = label),\n    family = \"karla\", fontface = \"bold\", size = 8 / .pt,\n    hjust = .5, vjust = .5, nudge_x = 10000, min.segment.length = 1, label.r = unit(0, \"lines\"), label.size = NA, label.padding = unit(.2, \"lines\"), alpha = .6\n  ) +\n\n  # Fancy plot title\n  annotate(\"text\",\n    x = 1.27 * 10^6, y = 1.855 * 10^6, hjust = .5,\n    label = \"HIKING DESTINATIONS\", family = \"lora\", size = 12 / .pt\n  ) +\n  annotate(\"text\",\n    x = 1.27 * 10^6, y = 1.835 * 10^6, hjust = .5,\n    label = \"in\", family = \"lora\", fontface = \"italic\", size = 12 / .pt\n  ) +\n  annotate(\"text\",\n    x = 1.27 * 10^6, y = 1.803 * 10^6, hjust = .5,\n    label = \"L U Z O N\", family = \"lora\", size = 30 / .pt\n  )\nMy one hiking experience so far was at Nagpatong Rock, near Masungi. It was arduous and muddy and I slept for 12 hours afterwards. But for that brief moment at the peak, as I sipped cold coffee and braced myself against the wind, I looked out at the view and found it absolutely grand.\nStay elevated!"
  },
  {
    "objectID": "posts/2022-12-15-mountains/index.html#footnotes",
    "href": "posts/2022-12-15-mountains/index.html#footnotes",
    "title": "Luzon’s hiking trails",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd let me just say that learning to make maps in R has been bewilderingly difficult. I have found Geocomputation with R useful, but much of it remains mysterious to me.↩︎"
  },
  {
    "objectID": "posts/2022-12-21-avatar/index.html",
    "href": "posts/2022-12-21-avatar/index.html",
    "title": "Somehow, Avatar has returned",
    "section": "",
    "text": "In 2009, I watched James Cameron’s Avatar and thought, wait a minute, this is just Atlantis: The Lost Empire but with blue people. Then I didn’t think about Avatar again for the next 13 years.\nLast week, Avatar: The Way of Water was released, the second in what will now be a five-film, billion-dollar epic. What! In a way, this makes perfect sense: Avatar is somehow still the highest grossing movie of all time. Someone must’ve wanted this, and if you were that someone, then good for you! Your 13-year wait is over, good God.\nBut I still find it baffling that Avatar has made more money than, say, Avengers: Endgame, despite a far more subdued cultural presence. How did it do this? And can James Cameron pull it off again with Way of Water?\nIn this post, I visualize the box office trajectories of Avatar, Endgame, and two other blockbusters, Star Wars: The Force Awakens and Spider-Man: No Way Home, to see if anything sets Avatar apart. I add the receipts so far of Way of Water to check if it is on track to repeat its predecessor’s success. And for additional context, I’m also including the would-be blockbuster Batman v Superman, which started strong but quickly fizzled out.\nThe data was scraped from BoxOfficeMojo.com using the rvest package. There was unfortunately no daily data for worldwide box office receipts so I confined myself to daily U.S. receipts.\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(magrittr)\n\nfilms &lt;- c(\n  \"2691925505\",    # Star Wars: The Force Awakens\n  \"3059975681\",    # Avengers: Endgame\n  \"2869659137\",    # Spider-Man: No Way Home\n  \"2238875137\",    # Batman v Superman\n  \"876971521\",     # Avatar\n  \"3372254721\"     # Avatar: The Way of Water\n)\n\nurls &lt;- paste0(\"https://www.boxofficemojo.com/release/rl\", films)\n\nnames(urls) &lt;- c(\n  \"Star Wars: The Force Awakens\",\n  \"Avengers: Endgame\",\n  \"Spider-Man: No Way Home\",\n  \"Batman v Superman\",\n  \"Avatar\",\n  \"Avatar: The Way of Water\"\n)\n\ndf &lt;- tibble(title = NULL, day = NULL, todate = NULL)\n\nfor (i in 1:length(urls)) {\n  df_i &lt;- read_html(urls[i]) %&gt;%\n    html_nodes(\"table\") %&gt;%\n    extract2(1) %&gt;%\n    html_table() %&gt;%\n    mutate(\n      title = names(urls)[i],\n      todate = gsub(\"[\\\\$,]\", \"\", `To Date`) %&gt;% as.numeric()\n    ) %&gt;%\n    select(title, day = Day, todate)\n\n  df &lt;- bind_rows(df, df_i)\n}\n\ndf &lt;- df %&gt;% mutate(title = factor(title, levels = names(urls)))\nThe following shows cumulative receipts for the first 90 days of each film’s original theatrical run:\nCode\nlibrary(ggplot2)\n\nggplot(\n  df %&gt;% filter(day &lt; 91),\n  aes(x = day, y = todate / 1000000, group = title, color = title)\n) +\n  geom_line(linewidth = 1.1) +\n\n  # Labels\n  labs(\n    title = \"The way of Avatar I\",\n    subtitle = \"Cumulative U.S. box office receipts\",\n    caption = \"Note: Chart updated 30 Jan 2023\\nSource: boxofficemojo.com\"\n  ) +\n  scale_x_continuous(\n    name = \"Days since release\",\n    breaks = c(0, 30, 60, 90)\n  ) +\n  scale_y_continuous(\n    breaks = seq(0, 900, 300),\n    labels = c(\"\", 300, 600, \"$900 mn\")\n  ) +\n\n  # Legend\n  scale_color_manual(values = hcl.colors(n = 6, palette = \"Spectral\")) +\n  guides(color = guide_legend(\n    nrow = 3, ncol = 2,\n    keyheight = unit(1, \"lines\")\n  )) +\n\n  # Themes\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(family = \"karla\", size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 10)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    axis.ticks = element_blank(),\n    axis.title.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.title.y = element_blank(),\n    axis.text.x = element_text(size = 11, margin = margin(t = 5)),\n    axis.text.y = element_text(size = 11, margin = margin(r = 5)),\n    legend.position = c(.6, .15),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12, margin = margin(r = 10)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(linewidth = .5, color = \"white\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nThe Disney marketing machinery is evident in the trajectories of its three movies here. When these came out, they were all anybody could talk about, all anybody wanted to see, and as people flocked to cinemas these movies made a boatload of money very quickly. But the hype started to die down at around the 30-day mark, and receipts plateaued thereafter.\nWarner Bros.’ Batman v Superman had a similar start. The pre-release hype was intense, saturating the pop culture landscape in a major way (and in the year 2016 no less!). People rushed to see it and it broke box office records. The only problem was that it was bad, bad, bad. The chart shows how its receipts plateaued immediately, and after just 84 days, it was unceremoniously pulled from theaters.\nAvatar did not have a splashy start, but what it had was staying power. Long after the other blockbusters entered their plateaus, Avatar’s cumulative receipts were still growing.\nHere is another chart that makes this more apparent. I have segmented each film’s theatrical run into fortnightly (two-week) periods and plotted their cumulative receipts for each fortnight.\nCode\ndf1 &lt;- df %&gt;%\n  group_by(title) %&gt;%\n  mutate(\n    todate_lag = lag(todate),\n    fortnight = (day - 1) %/% 14\n  ) %&gt;%\n  replace_na(list(todate_lag = 0)) %&gt;%\n  group_by(title, fortnight) %&gt;%\n  mutate(\n    day2 = 1:n(),\n    todate2 = todate - min(todate_lag)\n  ) %&gt;%\n  ungroup()\n\nggplot(\n  df1 %&gt;% filter(title != \"Avatar: The Way of Water\"),\n  aes(x = day2, y = todate2 / 1000000, group = fortnight, color = fortnight)\n) +\n  geom_line(linewidth = .8) +\n  facet_wrap(~title, nrow = 2, scales = \"free_y\") +\n\n  # Labels\n  scale_y_continuous(name = \"$ million\") +\n  labs(\n    title = \"The way of Avatar II\",\n    subtitle = \"Cumulative U.S. box office receipts, by fortnight\",\n    caption = \"Source: boxofficemojo.com\"\n  ) +\n\n  # Legend\n  scale_color_gradient2(\n    low = \"#d11f00\", mid = \"#f2e38c\", high = \"white\",\n    midpoint = 8,\n    guide = \"colorbar\"\n  ) +\n  guides(color = guide_colorbar(\n    title = \"Fortnights since release\",\n    title.position = \"top\",\n    title.vjust = 0,\n    title.hjust = .5,\n    direction = \"horizontal\",\n    barwidth = unit(8, \"lines\"),\n    barheight = unit(.75, \"lines\"),\n    ticks = FALSE\n  )) +\n\n  # Themes\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 15)),\n    axis.ticks = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_text(size = 12),\n    axis.text.x = element_blank(),\n    axis.text.y = element_text(size = 10, margin = margin(r = 2)),\n    legend.position = c(.84, .24),\n    legend.title = element_text(size = 12, face = \"bold\"),\n    legend.text = element_text(size = 10),\n    strip.background = element_rect(fill = \"#1046b1\", color = NA),\n    strip.text = element_text(size = 10, face = \"bold\", color = \"white\"),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(linewidth = .5, color = \"white\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nAvatar certainly stands out. In a way, it marked the end of the pre-MCU blockbuster era when the installments of a franchise didn’t come just months or even weeks apart. Such an onslaught of content inevitably detracts from the experience of viewing any single release. Avatar was neither buoyed nor hobbled by its belonging to a mega-franchise, which might go some ways in explaining why people kept seeing it in cinemas for so long.\nInterestingly however, James Cameron now appears to be adopting the mega-franchise model as he mass-produces four Avatar sequels slated for biannual releases until 2028. Good luck with that. The franchise game is a crowded space these days, and The Way of Water has apparently already underperformed. But will it go on to have the same staying power as the first Avatar? Or will it fizzle out like BvS?\nThe stakes are… hilariously high? From Variety:\nI am no business genius, but if you need your enterprise to be the third or fourth most successful in history just to avoid financial ruin then maybe rethink your strategy. Maybe hedge a little!\nUpdate 30 Jan 2022: Well, he did it. As of my checking this morning, Avatar: The Way of Water has surpassed The Force Awakens to become the fourth highest-grossing film in history. It also bagged a Best Picture nomination while it was at it."
  },
  {
    "objectID": "posts/2022-12-21-avatar/index.html#data",
    "href": "posts/2022-12-21-avatar/index.html#data",
    "title": "Somehow, Avatar has returned",
    "section": "Data",
    "text": "Data\n\n\navatar.csv"
  },
  {
    "objectID": "posts/2023-01-26-oscars/index.html",
    "href": "posts/2023-01-26-oscars/index.html",
    "title": "Will people care about this Oscars?",
    "section": "",
    "text": "With the release of this year’s Academy Award nominations, many have pointed out a surprising fact: several of the films gunning for Best Picture are actually hits! More than that, the highest-grossing movie of the year (which is, somehow, Avatar: The Way of Water) and the second-highest grossing (Top Gun: Maverick) were both nominated.\nThere have long been discussions over whether prestige awards like the Oscars still matter. It doesn’t help that popular blockbusters tend not to get nominated — few people care that an indie film they didn’t see won over other indie films they didn’t see. The Academy of Motion Picture Arts and Sciences has made some efforts to stay relevant, such as expanding the field of Best Picture nominees from the traditional 5 to a maximum of 10 starting 2010. The idea is (and it sounds weird to say it) to be more inclusive of mainstream films.\nIt hasn’t worked so well. I compiled global box office receipts on all Best Picture nominees from 2010 to 2023 and charted them below. Billion-dollar blockbusters are still seldom nominated. They also never win.\nCode\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(ggplot2)\n\ndf &lt;- here(\"datasets\", \"oscars\", \"oscars.csv\") %&gt;% \n  read_csv()\n\ndf %&gt;%\n  select(year, title, winner, gross_us, gross_int) %&gt;%\n  filter(year &gt;= 2009) %&gt;%\n  replace_na(list(gross_us = 0, gross_int = 0)) %&gt;%\n  pivot_longer(\n    cols = c(gross_us, gross_int),\n    names_to = \"market\",\n    values_to = \"gross\"\n  ) %&gt;%\n  group_by(title) %&gt;%\n  mutate(\n    label_pos = cumsum(gross),\n    label = ifelse(market == \"gross_int\", title, \"\"),\n    year = year + 1,\n    winner = ifelse(winner == \"yes\", \"bold\", \"plain\")\n  ) %&gt;%\n  ungroup() %&gt;%\n  group_by(year) %&gt;%\n  mutate(title = fct_reorder(title, gross)) %&gt;%\n  ungroup() %&gt;%\n  \n  # Plot\n  ggplot(aes(y = title, x = gross, fill = market)) +\n  geom_bar(stat = \"identity\") +\n  facet_grid(rows = vars(year), scales = \"free_y\", space = \"free_y\", switch = \"y\") +\n\n  # Labels\n  labs(\n    title = \"Mm never heard of it\",\n    subtitle = \"Worldwide box office receipts for Best Picture nominees\",\n    caption = \"Note: winners are highlighted\\nSource: boxofficemojo.com\"\n  ) +\n  geom_text(aes(x = label_pos, label = label, fontface = winner, color = winner),\n    size = 7 / .pt, family = \"karla\", hjust = 0, nudge_x = 15 * 10^6\n  ) +\n  scale_x_continuous(\n    name = \"Worldwide box office receipts\",\n    limits = c(0, 3 * 10^9),\n    breaks = c(100, 500, 1000, 2000) * 10^6,\n    labels = c(\"$100mn\", \"$500mn\", \"$1bn\", \"$2bn\"),\n    sec.axis = sec_axis(~.,\n      breaks = c(100, 500, 1000, 2000) * 10^6,\n      labels = c(\"$100mn\", \"$500mn\", \"$1bn\", \"$2bn\")\n    )\n  ) +\n  \n  # Themes\n  scale_color_manual(values = c(\"#1046b1\", \"gray10\")) +\n  scale_fill_manual(\n    values = c(\"#ff505b\", \"#ffa600\"),\n    labels = c(\"International\", \"U.S.\")\n  ) +\n  guides(\n    fill = guide_legend(reverse = TRUE),\n    color = FALSE\n  ) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 20)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x.top = element_text(size = 10, margin = margin(b = 5)),\n    axis.text.x.bottom = element_text(size = 10, margin = margin(t = 5)),\n    axis.text.y = element_blank(),\n    legend.position = c(.83, .96),\n    legend.direction = \"horizontal\",\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    strip.background = element_rect(fill = \"#1046b1\", color = NA),\n    strip.text = element_text(size = 10, face = \"bold\", color = \"white\"),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_line(linewidth = .15, color = \"gray80\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nSome caveats. Certain films, like last year’s Best Picture winner CODA, were released primarily on streaming, so their box office takings would not necessarily reflect their popularity. And of course, the pandemic has artificially depressed receipts from the last two years. Nevertheless, it’s clear that for better or worse, the 7,000 or so voting members of the Academy have generally refused to cater to mainstream appeal.\nHence the surprise at 2023’s nominees. There are fans of Avatar, there are fans of Top Gun, and there are fans of indie favorite Everything Everywhere All at Once. Taken together, there may just be enough people out there who will care what an exclusive club of film industry professionals have to say about cinema this year.\nAnother way to contrast the Academy’s tastes with other film enthusiasts is to look at the ratings of professional movie critics and online audience reviews. I collected these from Metacritic for all Best Picture nominees from 2001 to 2023 and charted them in the scatter below. The dotted line is a 45-degree line, indicating a state of agreement between critics and ordinary moviegoers\nCode\nlibrary(highcharter)\nlibrary(broom)\n\nfit &lt;- lm(mc_users ~ mc_critics, data = df) %&gt;%\n  augment() %&gt;%\n  arrange(mc_critics) %&gt;%\n  slice(c(1, nrow(df)))\n\nx &lt;- c(\"Title\", \"Year released\", \"Metascore\", \"User score\", \"Box office\")\ny &lt;- c(\"{point.title:s}\", \"{point.year:.0f}\", \"{point.mc_critics:.0f}\", \"{point.mc_users:.1f}\", \"${point.gross:,.0f}\")\ntltip &lt;- tooltip_table(x, y)\n\ntheme &lt;- hc_theme(\n  chart = list(\n    backgroundColor = NULL\n  ),\n  title = list(style = list(\n    color = \"#333333\",\n    fontWeight = \"bold\",\n    fontSize = \"21px\"\n  )),\n  subtitle = list(style = list(\n    color = \"#333333\",\n    fontSize = \"18px\"\n  )),\n  caption = list(style = list(\n    color = \"gray75\",\n    fontSize = \"11px\"\n  ))\n)\n\nhchart(df, \"scatter\",\n  hcaes(x = mc_critics, y = mc_users, group = winner),\n  color = c(\"#1046b1\", \"#ffa600\"),\n  stickyTracking = FALSE\n) %&gt;%\n  hc_title(text = \"That's just, like, your opinion, man\") %&gt;%\n  hc_subtitle(text = \"Professional critics vs audience reviews for Best Picture nominees, 2001-2023\") %&gt;%\n  hc_caption(\n    text = \"Note: winners are highlighted&lt;br&gt;Source: metacritic.com, boxofficemojo.com\",\n    align = \"left\",\n    useHTML = TRUE\n  ) %&gt;%\n  hc_xAxis(\n    title = list(text = \"Metascore\"),\n    min = 40, gridLineWidth = 1,\n    labels = list(style = list(fontSize = \"14px\"))\n  ) %&gt;%\n  hc_yAxis(\n    title = list(text = \"User score\"),\n    startOnTick = FALSE, endOnTick = FALSE, min = 5.5, max = 9.5,\n    labels = list(style = list(fontSize = \"14px\"))\n  ) %&gt;%\n  hc_tooltip(\n    useHTML = TRUE,\n    pointFormat = tltip,\n    headerFormat = \"\"\n  ) %&gt;%\n  hc_add_series(\n    data = tibble(\n      mc_critics = c(0, 100),\n      mc_users = c(0, 10)\n    ),\n    type = \"line\", dashStyle = \"Dot\",\n    hcaes(x = mc_critics, y = mc_users),\n    color = \"black\", lineWidth = 1,\n    marker = FALSE, enableMouseTracking = FALSE\n  ) %&gt;%\n  hc_legend(enabled = FALSE)\nThe closest the Academy, movie critics, and audiences got to unanimity was with the Lord of the Rings films. More often however, the camps were split. The Academy and professional critics closed ranks on 2016’s Best Picture winner Moonlight; audiences were less impressed. On the flip side, both the Academy and moviegoers loved 2005’s Crash, but publications still routinely cite its Best Picture win as an atrocity to cinema. Occasionally, critics and audiences side against the Academy: Extremely Loud and Incredibly Close’s nomination baffled them both.\nIt’s unclear whether the Oscars and their ilk will ever reclaim the eminence they once held. Few legacy institutions are held in much reverence these days. Maybe the Oscars never deserved it to begin with. Still, it’s nice to have a cultural fixed point, to be able to look back and say, ah yes 2004, the year of Return of the King. Was 2022 the year of CODA? I’m afraid most would simply shrug."
  },
  {
    "objectID": "posts/2023-01-26-oscars/index.html#data",
    "href": "posts/2023-01-26-oscars/index.html#data",
    "title": "Will people care about this Oscars?",
    "section": "Data",
    "text": "Data\n\n\noscars.R / oscars.csv"
  },
  {
    "objectID": "posts/2023-02-06-francis-is-an-old-pope/index.html",
    "href": "posts/2023-02-06-francis-is-an-old-pope/index.html",
    "title": "Francis is an old pope",
    "section": "",
    "text": "Next month, Pope Francis will mark his 10th year in the papacy. Will he make it to his 15th year? His 20th? He is already 86: the last pope to reach this age was Leo XIII, who died in 1903 at the age of 93.1 In fact, by my count, only 15 of the 264 popes in history remained pope past their 86th birthday, and only four since the year 1500. Francis is in very small company.\nI thought I’d visualize this using data scraped from the Wikipedia article “List of popes”. The resulting dataset popes.csv runs from Peter to Francis and excludes all the antipopes (who I call the nopes) for a total of 267 rows and 264 unique popes. Check this repository for more info.\nHere’s a look at a few entries in the dataset:\nlibrary(tidyverse)\nlibrary(knitr)\n\npopes &lt;- here(\"datasets\", \"popes\", \"popes.csv\") %&gt;%\n  read_csv()\n\npopes %&gt;%\n  arrange(-number) %&gt;%\n  head() %&gt;%\n  knitr::kable(digits = 2, align = \"c\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnumber\nname_full\nname\nsuffix\ncanonization\nbirth\nstart\nend\nage_start\nage_end\ntenure\n\n\n\n\n266\nFrancis\nFrancis\n1\nNA\n1936-12-17\n2013-03-13\nNA\n76\nNA\nNA\n\n\n265\nBenedict XVI\nBenedict\n16\nNA\n1927-04-16\n2005-04-19\n2013-02-28\n78\n85\n7.86\n\n\n264\nJohn Paul II\nJohn Paul\n2\nSaint\n1920-05-18\n1978-10-16\n2005-04-02\n58\n84\n26.46\n\n\n263\nJohn Paul I\nJohn Paul\n1\nBlessed\n1912-10-17\n1978-08-26\n1978-09-28\n65\n65\n0.09\n\n\n262\nPaul VI\nPaul\n6\nSaint\n1897-09-26\n1963-06-21\n1978-08-06\n65\n80\n15.13\n\n\n261\nJohn XXIII\nJohn\n23\nSaint\n1881-11-25\n1958-10-28\n1963-06-03\n76\n81\n4.60\nWe can use a histogram to get an idea of how rare it is for a pope to continue on past the age of 86.\nCode\nlibrary(ggplot2)\n\npopes %&gt;%\n  ggplot(aes(x = age_end)) +\n  geom_histogram(binwidth = 2, fill = \"#1046b1\", color = \"gray97\") +\n  geom_vline(xintercept = 86, linetype = \"dashed\", linewidth = .25) +\n\n  # Labels\n  labs(\n    title = \"Pope longevity I\",\n    subtitle = \"Distribution of ages at which papacy ended\",\n    caption = \"Source: \\\"List of popes\\\" Wikipedia article\"\n  ) +\n  scale_x_continuous(breaks = c(40, 60, 80, 86, 100)) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(\n      size = c(12, 12, 12, 14, 12), face = c(\"plain\", \"plain\", \"plain\", \"bold\", \"plain\"),\n      margin = margin(t = 5), vjust = .5\n    ),\n    axis.text.y = element_text(size = 12, margin = margin(r = 5)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nThough Francis is an old pope, his tenure so far of 10 years is less remarkable. Almost a third of all popes lasted for 10 years or more. And getting another decade in will be tough for Francis as he entered the papacy late in life — 76 years old. Of the popes with tenures of 20 years or more, most started before the age of 60, as the chart below shows.\nCode\npopes %&gt;%\n  filter(tenure &gt;= 20) %&gt;%\n  bind_rows(tibble(name_full = \"Francis\", tenure = 0)) %&gt;%\n  arrange(tenure) %&gt;%\n  mutate(name_full = factor(name_full, name_full)) %&gt;%\n  ggplot() +\n  geom_segment(aes(x = age_start, xend = age_end, y = name_full, yend = name_full),\n    linewidth = 1, color = \"#1046b1\"\n  ) +\n  geom_text(aes(x = age_start, y = name_full, label = age_start),\n    family = \"karla\",\n    size = 8 / .pt, fontface = \"bold\", color = \"#1046b1\", nudge_x = -1.25\n  ) +\n  geom_text(aes(x = age_end, y = name_full, label = age_end),\n    family = \"karla\",\n    size = 8 / .pt, fontface = \"bold\", color = \"#1046b1\", nudge_x = 1.25\n  ) +\n  geom_segment(\n    x = 76, xend = 86, y = \"Francis\", yend = \"Francis\",\n    linewidth = 1, linejoin = \"mitre\", color = \"#ff505b\",\n    arrow = arrow(angle = 30, length = unit(0.15, \"cm\"), type = \"closed\")\n  ) +\n  geom_text(\n    x = 74.5, y = \"Francis\", label = \"76\",\n    family = \"karla\",\n    size = 9 / .pt, fontface = \"bold\", color = \"#ff505b\"\n  ) +\n\n  # Labels\n  labs(\n    title = \"Pope longevity II\",\n    subtitle = \"Age spans of popes with the longest tenures\",\n    caption = \"Source: \\\"List of popes\\\" Wikipedia article\"\n  ) +\n  scale_x_continuous(breaks = seq(30, 90, 10)) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.text.y = element_text(\n      size = c(rep(11, 14), 12) %&gt;% rev(),\n      face = c(rep(\"plain\", 13), \"bold\") %&gt;% rev(),\n      color = c(rep(\"gray10\", 13), \"#ff505b\") %&gt;% rev(),\n      margin = margin(r = 5)\n    ),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_line(linewidth = .15, color = \"gray80\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nWe can use a bit of survival analysis to estimate the probability of a pope making it to their 20th year, controlled for whether they started relatively young (below 60 years old) or relatively old (60 and above). The Kaplan-Meier estimates are computed using the survival package and plotted using the ggsurvfit package.\nCode\nlibrary(survival)\nlibrary(ggsurvfit)\n\npopes1 &lt;- popes %&gt;%\n  mutate(old = case_when(\n    age_start &lt; 60 ~ 0,\n    age_start &gt;= 60 ~ 1\n  ))\n\nsurvfit2(with(popes1, Surv(tenure)) ~ old, data = popes1) %&gt;%\n  ggsurvfit(linewidth = .75) +\n  add_confidence_interval() +\n  geom_vline(xintercept = 10, linetype = \"dashed\", linewidth = .25) +\n\n  # Labels\n  labs(\n    title = \"Pope longevity III\",\n    subtitle = \"Survival probability of popes by starting age\",\n    caption = \"Source: \\\"List of popes\\\" Wikipedia article\"\n  ) +\n  scale_x_continuous(name = \"Years of tenure\") +\n  scale_y_continuous(\n    name = \"Probability of still being pope\",\n    labels = scales::percent\n  ) +\n  scale_color_manual(\n    labels = c(\"Under 60\", \"60 and above\"),\n    values = c(\"#ffa600\", \"#1046b1\")\n  ) +\n  scale_fill_manual(values = c(\"#FFD079\", \"#9BB8F6\")) +\n  guides(fill = FALSE) +\n\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    axis.ticks = element_blank(),\n    axis.title.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.title.y = element_text(size = 12, margin = margin(r = 5)),\n    axis.text.x = element_text(size = 11, margin = margin(t = 5)),\n    axis.text.y = element_text(size = 11, margin = margin(r = 5)),\n    legend.position = c(.75, .9),\n    legend.direction = \"horizontal\",\n    legend.text = element_text(size = 12),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nBased on these estimates, the young group has a 33.1% probability of reaching their 10th year while the old group has only a 23.9% probability. On the other hand, the young group has a 6.3% probability of reaching their 20th year while the old group has a 2.3% chance. It should be noted though that the estimates for the old group have a high amount of uncertainty, mainly because few old popes make it to their 20th year.\nIf Francis completes his second decade as pope, he would be 96. The odds are against him, but it wouldn’t be unheard of. Pope Agatho, elected pope in 678 AD at the age of 100, reigned until his death at age 103."
  },
  {
    "objectID": "posts/2023-02-06-francis-is-an-old-pope/index.html#data",
    "href": "posts/2023-02-06-francis-is-an-old-pope/index.html#data",
    "title": "Francis is an old pope",
    "section": "Data",
    "text": "Data\n\n\npopes.R / popes.csv"
  },
  {
    "objectID": "posts/2023-02-06-francis-is-an-old-pope/index.html#footnotes",
    "href": "posts/2023-02-06-francis-is-an-old-pope/index.html#footnotes",
    "title": "Francis is an old pope",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlthough Benedict XVI lived to 95, he resigned the papacy when he was 85.↩︎"
  },
  {
    "objectID": "posts/2023-02-14-standard-age/index.html",
    "href": "posts/2023-02-14-standard-age/index.html",
    "title": "The standard age",
    "section": "",
    "text": "A super spy races to stop terrorists from bombing a national landmark. A dour careerist falls in love with a reckless bohemian. A genius overcomes a disability to make revolutionary discoveries. A dorky scientist gains superpowers after a lab accident. When you picture these movie plots in your head, how old do you make the protagonist out to be?\nWe all have a sense of what the age of a “standard” adult is — the age when someone is neither too young nor too old, neither juvenile nor decaying, neither coming nor going. The age that a generic protagonist ought to be for a generic popcorn flick.\nWhat is this age? We can get an idea by looking at the actual ages of actors cast in mainstream movies. For this, I use the Hollywood Age Gap dataset featured in this week’s TidyTuesday. We load it up as follows:\nlibrary(tidytuesday)\nage_gaps &lt;- tidytuesdayR::tt_load(2023, week = 7)$age_gaps\nIt contains actors’ ages for movies where they are part of a romantic couple. The dataset highlights the often egregious age gaps between men and their female love interests. For example, here is Humphrey Bogart:\nlibrary(tidyverse)\n\nage_gaps %&gt;%\n  filter(actor_1_name == \"Humphrey Bogart\") %&gt;%\n  select(movie_name, release_year, actor_1_name, actor_1_age, actor_2_name, actor_2_age, age_difference) %&gt;%\n  knitr::kable(align = \"lclclcc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovie_name\nrelease_year\nactor_1_name\nactor_1_age\nactor_2_name\nactor_2_age\nage_difference\n\n\n\n\nSabrina\n1954\nHumphrey Bogart\n55\nAudrey Hepburn\n25\n30\n\n\nBeat the Devil\n1953\nHumphrey Bogart\n54\nGina Lollobrigida\n26\n28\n\n\nDark Passage\n1947\nHumphrey Bogart\n48\nLauren Bacall\n23\n25\n\n\nKey Largo\n1948\nHumphrey Bogart\n49\nLauren Bacall\n24\n25\n\n\nThe Big Sleep\n1946\nHumphrey Bogart\n47\nLauren Bacall\n22\n25\n\n\nTo Have and Have Not\n1944\nHumphrey Bogart\n45\nLauren Bacall\n20\n25\n\n\nIn a Lonely Place\n1950\nHumphrey Bogart\n51\nGloria Grahame\n27\n24\n\n\nCasablanca\n1942\nHumphrey Bogart\n43\nIngrid Bergman\n27\n16\n\n\nThe African Queen\n1951\nHumphrey Bogart\n52\nKatharine Hepburn\n44\n8\n“Here’s looking at you kid” indeed.\nBut my focus right now is solely on the actors’ ages, so I reconfigure the dataset as follows:\ndf1 &lt;- age_gaps %&gt;%\n  select(movie_name:director,\n    actor = actor_1_name,\n    character_gender = character_1_gender,\n    actor_birthdate = actor_1_birthdate,\n    actor_age = actor_1_age\n  )\n\ndf2 &lt;- age_gaps %&gt;%\n  select(movie_name:director,\n    actor = actor_2_name,\n    character_gender = character_2_gender,\n    actor_birthdate = actor_2_birthdate,\n    actor_age = actor_2_age\n  )\n\ndf &lt;- df1 %&gt;%\n  bind_rows(df2) %&gt;%\n  distinct() %&gt;%\n  arrange(movie_name, actor_age)\n\ndf %&gt;%\n  head() %&gt;%\n  select(-director) %&gt;%\n  knitr::kable(align = \"lcllcc\")\n\n\n\n\n\n\n\n\n\n\n\n\nmovie_name\nrelease_year\nactor\ncharacter_gender\nactor_birthdate\nactor_age\n\n\n\n\n10 Things I Hate About You\n1999\nJoseph Gordon-Levitt\nman\n1981-02-17\n18\n\n\n10 Things I Hate About You\n1999\nJulia Stiles\nwoman\n1981-03-28\n18\n\n\n10 Things I Hate About You\n1999\nLarisa Oleynik\nwoman\n1981-06-07\n18\n\n\n10 Things I Hate About You\n1999\nHeath Ledger\nman\n1979-04-24\n20\n\n\n13 Going on 30\n2004\nJennifer Garner\nwoman\n1972-04-17\n32\n\n\n13 Going on 30\n2004\nMark Ruffalo\nman\n1967-11-22\n37\nThis gives 2,103 entries on 1,031 unique actors. Because this was originally a couples dataset, there is an even split between men and women. It’s worth pointing out that the dataset seems to have been collected rather haphazardly. It’s mostly American films, though there are occasional foreign inclusions like Blue Is the Warmest Colour. For some reason, only five films each are included for 2020, 2021, and 2022 — this may have a bearing on the decade medians I compute below. Major films of the last three years like Tenet, Spider-Man: No Way Home, Shang-Chi, F9, and The Batman are inexplicably omitted.\nWith those limitations in mind, let’s see what the data say. Here is a histogram of actors’ ages, grouped by sex:\nCode\nlibrary(ggplot2)\n\ndf %&gt;%\n  ggplot(aes(x = actor_age, fill = character_gender)) +\n  geom_histogram(binwidth = 1, position = \"identity\", color = \"gray97\", alpha = .6) +\n\n  # Labels\n  labs(\n    title = \"The wonder years\",\n    subtitle = \"Distribution of leading actors' ages in selected movies, 1935-2022\",\n    caption = \"Source: Hollywood Age Gap dataset\"\n  ) +\n  scale_x_continuous(breaks = seq(20, 90, 10)) +\n  scale_y_continuous(limits = c(0, 80)) +\n  geom_rect(xmin = 36.5, xmax = 37.5, ymin = 0, ymax = 59, fill = \"#1046b1\", color = \"gray97\") +\n  geom_rect(xmin = 27.5, xmax = 28.5, ymin = 0, ymax = 68, fill = \"#ffa600\", color = \"gray97\") +\n  annotate(\"text\", label = \"37\", size = 12 / .pt, fontface = \"bold\", x = 37, y = 61, vjust = 0) +\n  annotate(\"text\", label = \"28\", size = 12 / .pt, fontface = \"bold\", x = 28, y = 70, vjust = 0) +\n\n  # Themes\n  scale_fill_manual(\n    values = c(\"#1046b1\", \"#ffa600\"),\n    labels = c(\"Men\", \"Women\")\n  ) +\n  guides(fill = guide_legend(\n    title = NULL,\n    override.aes = list(alpha = 1)\n  )) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 15)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.text.y = element_blank(),\n    legend.position = c(.8, .8),\n    legend.text = element_text(size = 12),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nHollywood’s idea of the standard age clusters at around 37 for men and 28 for women (implying that the standard age gap for romantic couples is 9). Some examples are, for men: Russell Crowe in A Beautiful Mind, George Clooney in Out of Sight, Jack Nicholson in Chinatown, Robert De Niro in Raging Bull, Gregory Peck in Roman Holiday; and for women: Robin Wright in Forrest Gump, Marisa Tomei in My Cousin Vinny, Demi Moore in Ghost, Meg Ryan in When Harry Met Sally, Léa Seydoux in Blue Is the Warmest Color.\nTimes seem to be changing, however, as the median ages of actors have been rising over the decades. The median actress, in particular, is the oldest she’s ever been (though with the caveat mentioned above that unusually few 2020s films are in the dataset).\nCode\ndf %&gt;%\n  mutate(decade = plyr::round_any(release_year, 10, floor)) %&gt;%\n  group_by(decade, character_gender) %&gt;%\n  summarize(actor_age = median(actor_age)) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(x = decade, y = actor_age, group = character_gender, fill = character_gender, color = character_gender)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 7.5, shape = 21, stroke = 1.5, color = \"gray97\") +\n  geom_text(aes(label = round(actor_age)),\n    family = \"karla\", size = 9 / .pt, fontface = \"bold\", color = \"white\"\n  ) +\n\n  # Labels\n  labs(\n    title = \"Signs of aging\",\n    subtitle = \"Median age of leading actors by decade\",\n    caption = \"Source: Hollywood Age Gap dataset\"\n  ) +\n  scale_x_continuous(breaks = seq(1930, 2020, 10)) +\n  scale_y_continuous(limits = c(20, 53)) +\n  guides(color = guide_legend(title = NULL), fill = FALSE) +\n\n  # Themes\n  scale_fill_manual(\n    values = c(\"#1046b1\", \"#ffa600\"),\n    labels = c(\"Men\", \"Women\")\n  ) +\n  scale_color_manual(\n    values = c(\"#1046b1\", \"#ffa600\"),\n    labels = c(\"Men\", \"Women\")\n  ) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 15)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.text.y = element_text(size = 12, margin = margin(r = 5)),\n    legend.position = c(.75, .85),\n    legend.text = element_text(size = 12),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\nThis idea of a standard age has some grounding in developmental psychology. Clare Mehta and her colleagues coined the term “established adulthood” to refer to our 30s and early 40s, a period in our lives that most look back on — or look forward to — as their golden years. She writes:\nIf you who are reading this are an established adult, or even better, are close to the Hollywood standard age, then feel free to defeat some terrorists, fall in love with a bohemian, or gain some superpowers. This time in your life calls for it."
  },
  {
    "objectID": "posts/2023-02-14-standard-age/index.html#data",
    "href": "posts/2023-02-14-standard-age/index.html#data",
    "title": "The standard age",
    "section": "Data",
    "text": "Data\n\n\nagegaps.csv"
  },
  {
    "objectID": "posts/2023-02-22-putins-leverage-putins-folly/index.html",
    "href": "posts/2023-02-22-putins-leverage-putins-folly/index.html",
    "title": "Putin’s leverage, Putin’s folly",
    "section": "",
    "text": "Putin’s war in Ukraine is now approaching its second year. In the face of Russia’s armies, Ukraine has confounded pessimists to contrive one unexpected success after another, from the repulsion of the initial invasion of Kiev to the retaking of territories around Kharkiv and Kherson late last year. The West has rallied behind Zelensky. Many geopolitical givens have been upended. John Mearsheimer has changed his mind (just kidding).\nEqually bewildering has been the conflict’s economic consequences. Energy commodity prices — crude oil, natural gas — went haywire last year. This joined hands with the great post-COVID reopening to unleash the highest rates of inflation the West has seen since the 70s. In response, central banks have decisively and jarringly ended the low-interest rate era. Recessions loom. Big and small implosions have occurred in the tech–crypto–meme stock space.\nThis is a lot to make sense of, but in today’s post, I want to focus on Russia’s centrality in the global energy trade. Earlier this month, the French think tank CEPII released the BACII dataset for 2021. The BACII is an extremely rich (and free!) dataset containing bilateral trade flows among 200-plus countries across 5000-plus products. It is a cleaned up version of the UN’s COMTRADE, hence the one-year lag in its release. What we therefore have is the global structure of trade right before the Russian invasion of Ukraine, after which Western sanctions dramatically altered trade patterns. How big of a player was Russia in energy markets?\nLet’s load it up:\n\nlibrary(tidyverse)\n\ndf &lt;- here(\"datasets\", \"baci2011\", \"BACI_HS17_Y2021_V202301.csv\") %&gt;% \n  read_csv()\n\ndf %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\nt\ni\nj\nk\nv\nq\n\n\n\n\n2021\n4\n24\n382499\n52.548\n13.235\n\n\n2021\n4\n24\n392410\n0.266\n1.854\n\n\n2021\n4\n24\n481890\n0.041\n0.022\n\n\n2021\n4\n24\n570232\n0.202\n1.854\n\n\n2021\n4\n24\n690722\n3.431\n1.854\n\n\n2021\n4\n24\n732310\n0.020\n1.854\n\n\n\n\n\nAs you can see, the structure of the dataset is very simple. Column i is the exporting country, j is the importing country, k is the HS six-digit commodity code, v is the annual value of the trade in millions of US dollars, and q is the annual quantity of the trade in metric tons. The 2021 release has *counts fingers* 11.1 million rows.\nAccompanying dictionaries define the country and product codes. We’ll go ahead and revise some of the more unusually labeled countries. In particular, note that “Other Asia, not elsewhere specificied” is essentially a euphemism for Taiwan. The result is as follows:\n\ncountries &lt;- here(\"datasets\", \"baci2011\", \"country_codes_V202301.csv\") %&gt;%\n  read_csv() %&gt;%\n  select(code = country_code, country = country_name_full, iso3 = iso_3digit_alpha)\n\n# Revise names\ncountries$country[which(countries$country == \"France, Monaco\")] &lt;- \"France\"\ncountries$country[which(countries$country == \"Norway, Svalbard and Jan Mayen\")] &lt;- \"Norway\"\ncountries$country[which(countries$country == \"United Kingdom\")] &lt;- \"UK\"\ncountries$country[which(countries$country == \"USA, Puerto Rico and US Virgin Islands\")] &lt;- \"USA\"\ncountries$iso3[which(countries$country == \"Other Asia, not elsewhere specified\")] &lt;- \"TWN\"\ncountries$country[which(countries$country == \"Other Asia, not elsewhere specified\")] &lt;- \"Taiwan\"\n\ncountries %&gt;%\n  head() %&gt;%\n  kable(align = \"clc\")\n\n\n\n\ncode\ncountry\niso3\n\n\n\n\n4\nAfghanistan\nAFG\n\n\n8\nAlbania\nALB\n\n\n12\nAlgeria\nDZA\n\n\n16\nAmerican Samoa\nASM\n\n\n20\nAndorra\nAND\n\n\n24\nAngola\nAGO\n\n\n\n\n\nThe key energy commodities I want to highlight are crude oil, refined petroleum, and natural gas. These have HS codes 270900, 271000, and 271111, respectively. Below are their full labels according to the products dictionary:\n\nhere(\"datasets\", \"baci2011\", \"product_codes_HS17_V202301.csv\") %&gt;% \n  read_csv() %&gt;%\n  filter(code %in% c(270900, 271000, 271111)) %&gt;%\n  kable()\n\n\n\n\n\n\n\n\ncode\ndescription\n\n\n\n\n270900\nOils: petroleum oils and oils obtained from bituminous minerals, crude\n\n\n271000\nPetroleum oils and oils from bituminous minerals, not crude: preparations n.e.c. containing by weight 70% or more of petroleum oils or oils from bituminous minerals: these being the basic constituents of the preparations: waste oils\n\n\n271111\nPetroleum gases and other gaseous hydrocarbons: liquefied, natural gas\n\n\n\n\n\nLet’s aggregate the BACII dataset to reflect the total exports and imports of all countries for each of these three energy products.\n\nenergy &lt;- df %&gt;%\n  filter(k %in% c(270900, 271000, 271111))\n\nenergy_exp &lt;- energy %&gt;%\n  group_by(i, k) %&gt;%\n  summarize(exports = sum(v)) %&gt;%\n  ungroup() %&gt;%\n  left_join(countries, by = c(\"i\" = \"code\")) %&gt;%\n  select(country, iso3, k, exports)\n\nenergy_imp &lt;- energy %&gt;%\n  group_by(j, k) %&gt;%\n  summarize(imports = sum(v)) %&gt;%\n  ungroup() %&gt;%\n  left_join(countries, by = c(\"j\" = \"code\")) %&gt;%\n  select(country, iso3, k, imports)\n\nenergy_agg &lt;- energy_exp %&gt;%\n  left_join(energy_imp) %&gt;%\n  replace_na(list(exports = 0, imports = 0)) %&gt;%\n  mutate(net_exports = exports - imports)\n\nThe graph below shows the biggest net exporters and net importers.\n\n\nCode\nlibrary(ggplot2)\n\ntop_countries &lt;- energy_agg %&gt;%\n  group_by(country) %&gt;%\n  summarize(net_exports = sum(net_exports)) %&gt;%\n  ungroup() %&gt;%\n  arrange(-net_exports) %&gt;%\n  slice(c(1:10, (n() - 9):n())) %&gt;%\n  bind_rows(tibble(country = \"\", net_exports = 0)) %&gt;%\n  arrange(-net_exports) %&gt;%\n  magrittr::use_series(country)\n\nenergy_agg %&gt;%\n  bind_rows(tibble(country = \"\", k = \"270900\", net_exports = 0)) %&gt;%\n  filter(country %in% top_countries) %&gt;%\n  arrange(-net_exports) %&gt;%\n  mutate(country = factor(country, rev(top_countries))) %&gt;%\n  ggplot(aes(x = net_exports, y = country, fill = k)) +\n  geom_bar(position = \"stack\", stat = \"identity\", width = .7) +\n  geom_hline(yintercept = \"\", linetype = \"dashed\", color = \"gray40\", linewidth = .25) +\n\n  # Labels\n  labs(\n    title = \"High octane trading\",\n    subtitle = \"Biggest net exporters/importers of energy commodities, 2021\",\n    caption = \"Source: CEPII BACI dataset\"\n  ) +\n  scale_x_continuous(\n    labels = c(\"-$200bn\", \"-$100bn\", \"0\", \"$100bn\", \"$200bn\"),\n    breaks = c(-200, -100, 0, 100, 200) * 10^6\n  ) +\n  scale_fill_manual(\n    labels = c(\"Crude oil\", \"Refined petroleum\", \"Natural gas\"),\n    values = c(\"#1046b1\", \"#ff505b\", \"#ffa600\")\n  ) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10, l = -10)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(size = 12, margin = margin(t = 5)),\n    axis.text.y = element_text(\n      size = c(rep(10, 20), 11),\n      face = c(rep(\"plain\", 20), \"bold\"),\n      color = c(rep(\"gray10\", 20), \"#ff505b\"),\n      margin = margin(r = 5)\n    ),\n    legend.position = c(.2, .85),\n    legend.background = element_blank(),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 11),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_line(linewidth = .15, color = \"gray80\"),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nIn net value terms for the commodities in question, Russia was the biggest exporter in 2021. Receipts from these would finance its war the following year and have naturally become the primary targets of Western sanctions. Over on the other end, the pronounced reliance of Chinese industry on energy imports adds another strategic reason why the Xi–Putin friendship would continue to have “no limits”.\nA visually striking way to represent the structure of global energy flows and Russia’s place in it is through a network chart. Making these is a little trickier than your run-of-the-mill line or bar chart, so I’ll walk through the preparation our data needs to undergo.\nLet’s use crude oil (HS 270900). We will need to construct a table containing all the “nodes” (and their properties) and all the “edges” that connect the nodes. In our case, nodes refer to countries while edges refer to the dollar amounts of crude oil flowing from one country to another.\nStarting with the nodes:\n\nlibrary(countrycode)\n\nenergy_trunc &lt;- energy %&gt;%\n  filter(k == 270900)\n\nsources &lt;- energy_trunc %&gt;%\n  distinct(i) %&gt;%\n  rename(code = i)\n\ndestinations &lt;- energy_trunc %&gt;%\n  distinct(j) %&gt;%\n  rename(code = j)\n\ntot_exports &lt;- energy %&gt;%\n  filter(k == 270900) %&gt;%\n  group_by(i) %&gt;%\n  summarize(tot_exports = sum(v)) %&gt;%\n  ungroup()\n\nnodes &lt;- full_join(sources, destinations) %&gt;%\n  inner_join(countries, by = \"code\") %&gt;%\n  left_join(tot_exports, by = c(\"code\" = \"i\")) %&gt;%\n  replace_na(list(tot_exports = 0)) %&gt;%\n  mutate(\n    id = 1:n(),\n    label = ifelse(tot_exports &gt;= 10^6, country, \"\")  # Labels only for big nodes\n  ) %&gt;%\n  select(id, code, iso3, country, label, tot_exports)\n\n# Add region of each country\nnodes &lt;- nodes %&gt;%\n  mutate(region = countrycode(nodes$iso3, origin = \"iso3c\", destination = \"continent\"))\n\nnodes %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\nid\ncode\niso3\ncountry\nlabel\ntot_exports\nregion\n\n\n\n\n1\n4\nAFG\nAfghanistan\n\n50582.04\nAsia\n\n\n2\n8\nALB\nAlbania\n\n208037.64\nEurope\n\n\n3\n12\nDZA\nAlgeria\nAlgeria\n10950655.07\nAfrica\n\n\n4\n24\nAGO\nAngola\nAngola\n27575679.32\nAfrica\n\n\n5\n31\nAZE\nAzerbaijan\nAzerbaijan\n13330215.35\nAsia\n\n\n6\n32\nARG\nArgentina\nArgentina\n1187448.54\nAmericas\n\n\n\n\n\nEach node is indexed by the id variable and has two properties that we will later incorporate in our network chart: total exports, which will determine the size of the node, and geographic region, which will determine the color of the node. Regions are obtained from the package countrycode.\nNow for the edges:\n\nedges &lt;- energy_trunc %&gt;%\n  left_join(nodes, by = c(\"i\" = \"code\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(nodes, by = c(\"j\" = \"code\")) %&gt;%\n  rename(to = id) %&gt;%\n  select(from, to, v)\n\nedges %&gt;%\n  head() %&gt;%\n  kable(align = \"c\")\n\n\n\n\nfrom\nto\nv\n\n\n\n\n1\n62\n50581.430\n\n\n1\n132\n0.605\n\n\n2\n27\n1.059\n\n\n2\n62\n26900.309\n\n\n2\n123\n181136.270\n\n\n3\n7\n114354.978\n\n\n\n\n\nThe edges table uses the id index from the nodes table to record flows between nodes.\nUsing the tidygraph package, our nodes and edges tables are now fed into the tbl_graph() function\n\nlibrary(tidygraph)\n\nnetwork &lt;- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)\n\nWe are now ready to produce a network chart using the ggraph package. I use the dh layout in the chart below, which implements the Davidson–Harel algorithm to position the nodes of the network. Because some randomness is involved, it is helpful to set a seed so that the result stays fixed as we iterate through drafts of the graph.\n\n\nCode\nlibrary(ggraph)\nlibrary(scales)\n\nset.seed(4146)\n\nggraph(network, layout = \"dh\") +\n  geom_edge_link(aes(alpha = v, width = v), show.legend = FALSE) +\n  geom_node_point(aes(color = region),\n    size = rescale(nodes$tot_exports, c(.75, 25)),\n    shape = 16, alpha = 0.7\n  ) +\n\n  labs(\n    title = \"Crudely speaking\",\n    subtitle = \"Crude oil trade flows in US dollar terms, 2021\",\n    caption = \"Source: CEPII BACI dataset\"\n  ) +\n  geom_node_text(aes(label = label), size = 8 / .pt) +\n  lims(x = c(-50, 45), y = c(-65, 45)) +\n\n  scale_edge_width(range = c(0.2, 2)) +\n  scale_edge_alpha(range = c(0.05, .8)) +\n  scale_color_manual(values = c(\"#1046b1\", \"#a835a6\", \"#ffa600\", \"#ff6549\", \"#f0307d\")) +\n  guides(color = guide_legend(\n    keyheight = unit(1, \"lines\"),\n    direction = \"vertical\",\n    override.aes = list(size = 2.5, alpha = 1)\n  )) +\n\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10, l = -10)),\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    legend.position = c(.85, .2),\n    legend.background = element_blank(),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),\n    legend.key = element_blank(),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nThe centrality of Russia is evident, making efforts to rapidly disentangle it from supply networks a daunting task. If it can be done at all, it will have to be done gradually, with plenty of near-term pain.\nCountries have had to bear this pain unevenly. The chart below shows the share of Russia in countries’ imports of crude oil, refined petroleum, and natural gas. I have highlighted some of the key geopolitical players in the present Ukraine conflict.\n\n\nCode\nhighlight &lt;- c(\"USA\", \"Germany\", \"France\", \"UK\", \"Sweden\", \"Finland\", \"Turkey\", \"China\", \"India\")\n\nfrom_russia &lt;- energy %&gt;%\n  filter(i == 643) %&gt;%\n  group_by(j) %&gt;%\n  summarize(from_russia = sum(v)) %&gt;%\n  ungroup()\n\ntot_imports &lt;- energy %&gt;%\n  group_by(j) %&gt;%\n  summarize(tot_imports = sum(v)) %&gt;%\n  ungroup()\n\nrussia_dependence &lt;- from_russia %&gt;%\n  left_join(tot_imports) %&gt;%\n  left_join(countries, by = c(\"j\" = \"code\")) %&gt;%\n  mutate(russia_dependence = 100 * from_russia / tot_imports) %&gt;%\n  arrange(-tot_imports) %&gt;%\n  slice(1:50) %&gt;%\n  arrange(-russia_dependence) %&gt;%\n  mutate(\n    country = factor(country, country),\n    region = countrycode(iso3, origin = \"iso3c\", destination = \"continent\"),\n    labelsize = ifelse(country %in% highlight, 10, 0),\n    highlight = ifelse(country %in% highlight, 1, 0)\n  ) %&gt;%\n  select(code = j, iso3, country, region, from_russia, tot_imports, russia_dependence, labelsize, highlight)\n\nrussia_dependence %&gt;%\n  ggplot(aes(x = country, y = russia_dependence, fill = region, alpha = highlight)) +\n  geom_bar(stat = \"identity\") +\n  \n  labs(\n    title = \"Moscow's dependents\",\n    subtitle = \"Share of energy imports sourced from Russia, 2021\",\n    caption = \"Notes: Energy here refers to crude oil, refined petroleum, and natural gas. Only top 50 countries by value are included.\\nSource: CEPII BACI dataset\"\n  ) +\n  \n  scale_y_continuous(expand = expansion(mult = c(0, .1))) +\n  scale_fill_manual(values = c(\"#1046b1\", \"#a835a6\", \"#ffa600\", \"#ff6549\", \"#f0307d\")) +\n  scale_alpha(range = c(.25, 1)) +\n  guides(\n    fill = guide_legend(direction = \"horizontal\"),\n    alpha = FALSE\n  ) +\n  theme_minimal(base_family = \"karla\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10, l = -10)),\n    axis.ticks = element_blank(),\n    axis.title = element_blank(),\n    axis.text.x = element_text(\n      size = russia_dependence$labelsize,\n      angle = 90, hjust = 1, vjust = .5, margin = margin(t = 5)\n    ),\n    axis.text.y = element_text(size = 12, margin = margin(r = 5)),\n    legend.position = c(.2, .85),\n    legend.justification = c(0, 0),\n    legend.background = element_blank(),\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12, margin = margin(r = 10)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(linewidth = .15, color = \"gray80\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank()\n  )\n\n\n\n\n\nThe fruits of Germany’s enthusiastic rapproachment with Russia had, by 2021, translated into a dependence on Russian energy that exceeded France and the UK. It has unsurprisingly dragged its feet in providing military aid to Ukraine. But even higher was Finland’s, which in contrast has opted to irrevocably defy Moscow by moving to join NATO. This after decades of steadfast neutrality, demonstrating how past alignments can shift — and have shifted — dramatically.\nGermany’s Ostpolitik was rooted in the reasonable notion that deepening economic links can only make state relations more peaceful, more constructive. And in terms of global energy markets, Russia was as embedded as it gets. But Putin in his insanity chose to throw this all away and wage a war of annihilation. That this would have been hard to fathom from the vantage point of 2021 holds sobering implications for whether peace will endure among the great powers in the future. \n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "posts/2023-03-03-nobel/index.html",
    "href": "posts/2023-03-03-nobel/index.html",
    "title": "The demographics of Nobel laureates",
    "section": "",
    "text": "In a previous post, we talked about the Oscars and whether prestige awards still matter. Let’s turn now to what is perhaps the mother of all prestige awards — the Nobel Prize. The legacy of Swedish industrialist Alfred Nobel, it honors outstanding achievement in the fields of chemistry, literature, medicine, peace, physics, and, since 1969, economics. Winners — ahem, laureates — receive unparalleled stature not just in their fields but in the public sphere (deservedly or otherwise).\nIn its 120-year history, close to a thousand individuals (and some two dozen organizations) have been given a Nobel. What are they like? As an elite group, you can probably guess that they would tend towards oldness, whiteness, and maleness. But how old, how white, and how male? Fortunately, NobelPrize.org has an API for downloading data on all laureates, through which I was able to compile, for each laureate: the year and category they won in, their sex, their birth date, and their birth country (using modern borders). I won’t be including organizations in my analysis.\nLet’s take a look at the cleaned dataset using reactable, a wonderful table-making package by Greg Lin that I sure wish I discovered earlier. Below is a sortable, searchable, paginated table of the complete dataset:\nCode\nlibrary(tidyverse)\nlibrary(reactable)\n\nnobel &lt;- here::here(\"datasets\", \"nobel\", \"nobel.csv\") %&gt;% \n  read_csv()\n\nnobel %&gt;%\n  reactable(\n    defaultColDef = colDef(\n      align = \"center\",\n      headerStyle = list(fontFamily = \"Karla\", background = \"#f7f7f8\"),\n      sortNALast = TRUE\n    ),\n    columns = list(\n      year = colDef(minWidth = 75),\n      category = colDef(minWidth = 125, align = \"left\"),\n      type = colDef(minWidth = 125),\n      name = colDef(minWidth = 250, align = \"left\"),\n      birth = colDef(minWidth = 150),\n      age = colDef(minWidth = 75),\n      birth_country = colDef(minWidth = 175, align = \"left\"),\n      birth_continent = colDef(minWidth = 175, align = \"left\")\n    ),\n    minRows = 5,\n    searchable = TRUE,\n    bordered = TRUE,\n    highlight = TRUE,\n    theme = reactableTheme(\n      searchInputStyle = list(align = \"left\")\n    )\n  )\nOf the three attributes, being old is probably the most innocent. A Nobel Prize after all generally honors a body of work, and so is received late in one’s career. Below is a tabulation of laureate age ranges by prize category.\nCode\nnobel %&gt;%\n  group_by(category) %&gt;%\n  mutate(\n    coverage = paste0(min(year), \"-\", max(year)),\n    agemin = min(age, na.rm = TRUE),\n    agemax = max(age, na.rm = TRUE),\n    agemean = mean(age, na.rm = TRUE)\n  ) %&gt;%\n  group_by(category, coverage, agemin, agemax, agemean) %&gt;%\n  count() %&gt;%\n  select(category, coverage, laureates = n, agemin, agemax, agemean) %&gt;%\n  \n  # Construct reactable\n  reactable(\n    defaultColDef = colDef(\n      align = \"center\",\n      format = colFormat(digits = 0),\n      headerStyle = list(fontFamily = \"Karla\", background = \"#f7f7f8\"),\n      sortNALast = TRUE\n    ),\n    columns = list(category = colDef(align = \"left\")),\n    bordered = TRUE,\n    highlight = TRUE\n  )\nThe youngest laureate was for Peace — Malala Yousafzai from Pakistan. Peace is unusual among the Nobel prizes: while it is also awarded for a body of work, it can get quite topical, awarding very recent achievements. Barack Obama was just eight months into his presidency when he was awarded for “extraordinary efforts to strengthen international diplomacy and cooperation between peoples”. This willingness to jump the gun has led to some deeply awkward conferrals, most recently Ethiopian prime minister Abiy Ahmed, who started a war against his own people less than a year after bagging the prize.\nWhat might be more surprising in the table above is the youngest age among the Physics laureates. Someone under 40 winning a Nobel in the sciences fields (or even in Literature) is unheard of today, but it was more common during the heyday of theoretical physics in the early twentieth century, when discoveries in quantum mechanics were being made left and right.1 Indeed, the changing nature of scientific research can be seen in the chart below, which plots the average ages of laureates over time.\nCode\nlibrary(zoo)\nlibrary(ggplot2)\n\nnobel %&gt;%\n  group_by(category) %&gt;%\n  mutate(agemean_ra = rollmean(age, k = 10, fill = NA, align = \"right\", na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  \n  ggplot(aes(x = year, y = agemean_ra)) +\n  geom_line(linewidth = .8, color = \"#b13d70\") +\n  facet_wrap(~category, nrow = 2, scales = \"fixed\") +\n  labs(\n    title = \"Some people wait a lifetime\",\n    subtitle = \"Laureates' average age by category, 10-year rolling\",\n    caption = \"Source: Nobel Foundation\"\n  ) +\n  scale_x_continuous(limits = c(1910, 2022), breaks = c(1960, 2020)) +\n  scale_y_continuous(breaks = c(50, 70)) +\n  theme(\n    text = element_text(family = \"karla\"),\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_text(size = 10),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(linewidth = .15, linetype = \"dashed\", color = \"gray60\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    strip.background = element_rect(fill = \"gray92\", color = NA),\n    strip.text = element_text(size = 12, face = \"bold\", color = \"gray40\")\n  )\nLaureates in the sciences fields have been getting older. According to a curator at the Nobel Museum, this is partly a crowding effect: whereas 1,000 physicists were competing for the prize 100 years ago, today there are a million. With the Nobel only awarding up to three for a given category each year, would-be laureates need to wait longer for their turn.\nIt will likely get more crowded still. Achievements in science and literature are driven not just by personal genius but also by an enabling environment that nurtures that genius, itself a function of economic wealth. No wonder then that the richest countries — the United States, Europe, and European offshoots (Australia, Canada, New Zealand) — dominate the Nobel Prizes. This should change as developing countries catch up and begin investing more heavily in their scientists and artists.\nCode\nnobel %&gt;%\n  mutate(\n    group = case_when(\n      birth_continent == \"Europe\" ~ \"Europe & offshoots\",\n      birth_country == \"USA\" ~ \"United States\",\n      birth_continent == \"North America\" ~ \"Americas\",\n      birth_continent == \"South America\" ~ \"Americas\",\n      birth_country == \"Canada\" ~ \"Europe & offshoots\",\n      birth_country == \"Australia\" ~ \"Europe & offshoots\",\n      birth_country == \"New Zealand\" ~ \"Europe & offshoots\",\n      birth_country == \"East Timor\" ~ \"Asia\",\n      TRUE ~ birth_continent\n    ),\n    group = factor(\n      group, \n      levels = c(\n        \"United States\",\n        \"Europe & offshoots\",\n        \"Africa\",\n        \"Americas\",\n        \"Asia\"\n      )),\n    decade = plyr::round_any(year, 10, floor)\n  ) %&gt;% \n  group_by(decade, category) %&gt;%\n  count(group) %&gt;%\n  ungroup() %&gt;%\n  \n  ggplot(aes(x = decade, y = n, fill = group)) +\n  geom_bar(position = \"fill\", stat = \"identity\", color = NA) +\n  facet_wrap(~category, nrow = 2, scales = \"fixed\") +\n  labs(\n    title = \"Western win\",\n    subtitle = \"Laureates' country of birth under contemporary borders, by decade\",\n    caption = \"Source: Nobel Foundation\"\n  ) +\n  scale_x_continuous(breaks = c(1950, 2020)) +\n  scale_fill_manual(\n    name = \"\",\n    values = c(\"#4889ab\", \"#84b0c5\", \"#f697bb\", \"#c85b89\", \"#b13d70\")\n  ) +\n  guides(fill = guide_legend(nrow = 2)) +\n  theme(\n    text = element_text(family = \"karla\"),\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(size = 10, hjust = .5),\n    axis.text.y = element_blank(),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12, margin = margin(r = 10)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid = element_blank(),\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    strip.background = element_rect(fill = \"gray92\", color = NA),\n    strip.text = element_text(size = 12, face = \"bold\", color = \"gray40\")\n  )\nLikewise, the greater participation of women in STEM fields should hopefully go some ways in bridging the sex gap among laureates. My field of economics has a particularly atrocious record, with just two female laureates (Elinor Ostrom and Esther Duflo) in 54 years.2 Literature has made the most progress here, though women still only won one-third of the prizes since 2000.\nCode\nnobel %&gt;%\n  mutate(decade = plyr::round_any(year, 10, floor)) %&gt;%\n  drop_na(sex) %&gt;%\n  group_by(decade, category) %&gt;%\n  count(sex) %&gt;%\n  mutate(share = n / sum(n)) %&gt;% \n  ungroup() %&gt;%\n  complete(decade, category, sex, fill = list(n = 0, share = 0)) %&gt;% \n  filter(sex == \"female\" & !(category == \"Economics\" & decade &lt; 1960)) %&gt;% \n  \n  ggplot(aes(x = decade, y = share)) +\n  geom_step(direction = \"mid\", linewidth = 1, color = \"#b13d70\") +\n  facet_wrap(~category, nrow = 2, scales = \"fixed\") +\n  labs(\n    title = \"The second sex\",\n    subtitle = \"Share of female laureates, by decade\",\n    caption = \"Source: Nobel Foundation\"\n  ) +\n  scale_x_continuous(breaks = c(1950, 2020)) +\n  scale_y_continuous(limits = c(-.1, .8), breaks = c(0, .5), labels = scales::label_percent()) +\n  theme(\n    text = element_text(family = \"karla\"),\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_text(size = 10),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12, margin = margin(r = 10)),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid.major.x = element_blank(),\n    panel.grid.major.y = element_line(linewidth = .15, linetype = \"dashed\", color = \"gray60\"),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    strip.background = element_rect(fill = \"gray92\", color = NA),\n    strip.text = element_text(size = 12, face = \"bold\", color = \"gray40\")\n  )\nBeyond problems of representation in the arts and sciences, another major issue is the composition of the prize selection committees themselves. These comprise just a handful of elite Swedes and Norwegians, and though they ostensibly solicit nominations from thousands of outside experts and institutions, theirs is the final say, in deliberations that are kept secret for 50 years. And insularity may not even be their biggest problem: a sexual assault scandal in 2017 hinted at moral bankruptcy within the Swedish Academy, which decides the Literature Prize.\nNo doubt the Nobel Prizes are held in high reverence around the world, but I suspect it has more to do with the distinction of the men and women who have received them in the past than the esteem held for the judgment of a few elite Scandinavians. As a hilarious corrective to Nobel worship, let’s turn to Bob Dylan, winner of the 2016 Literature Prize, who seenzoned the Swedish Academy, didn’t bother to attend the ceremony, and cribbed off SparkNotes for his Nobel lecture. I know Dylan was a controversial choice, but look: anyone who accepts a Nobel in a hoodie deserves ten of them."
  },
  {
    "objectID": "posts/2023-03-03-nobel/index.html#data",
    "href": "posts/2023-03-03-nobel/index.html#data",
    "title": "The demographics of Nobel laureates",
    "section": "Data",
    "text": "Data\n\n\nnobel.R / nobel.csv"
  },
  {
    "objectID": "posts/2023-03-03-nobel/index.html#footnotes",
    "href": "posts/2023-03-03-nobel/index.html#footnotes",
    "title": "The demographics of Nobel laureates",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nKey winners under 40 include Werner Heisenberg (31), Paul Dirac (31), Enrico Fermi (37), and Niels Bohr (37). This period in physics is covered in one of my favorite books, The Making of the Atomic Bomb by Richard Rhodes.↩︎\nA 2019 symposium by the American Economic Association on “Women in Economics” has three interesting papers on the topic. But speaking to economics’ legendary tone-deafness, it was followed by a symposium on “The Problems of Men”.↩︎"
  },
  {
    "objectID": "posts/2023-03-12-prediction/index.html",
    "href": "posts/2023-03-12-prediction/index.html",
    "title": "Telling the future is hard",
    "section": "",
    "text": "Do you want to excel at telling the future? Nostradamus shows us one way: make your predictions as vague and ambiguous as possible and you will always be “right”. Try attaching a 40% probability to all your calls: if you’re wrong, hey, you never said it was a sure thing. Throw in some authoritative-sounding statements like “the next six months will be decisive”, as Thomas Friedman said, repeatedly, for two and a half years, about the Iraq War. And whatever you do, never corner yourself with a weirdly specific, absurdly bold prediction like “the Internet’s impact on the economy will be no greater than the fax machine’s”. You will never live it down.\nAlternatively, you can take the hard way and actually become an expert in the field. Then you can use superior domain knowledge to make superior predictions. Or can you?\nThe Forecasting Collaborative is a project spearheaded by Igor Grossmann and Amanda Rotella from the University of Waterloo. They invited almost 200 experts in the social sciences to forecast various measures of societal change in the United States over the course of 12 months — things like political polarization, attitudes to racial minorities, and so on. Crucially, the time frame was from May 2020 to April 2021, a tumultuous period covering the first year of the pandemic, the George Floyd protests, a presidential election, and the January 6 riots.1 To benchmark how the experts performed, forecasts were also obtained from 800 non-experts and naive approaches like historical averaging. If domain knowledge makes for superior forecasts, then experts should easily outperform.\nAlas. Results published last month in Nature Human Behavior2 found that experts’ forecasts were generally no more accurate than non-experts and naive methods. Let’s explore the data, made available by the researchers on GitHub and forked by me.\nlibrary(tidyverse)\n\nroot &lt;- \"https://raw.github.com/ksreyes/Forecasting-Tournament/main\"\nfiles &lt;- c(\"dat_for_analyses.csv\", \"wave1.scores.csv\", \"historical_data.csv\")\n\ndat_for_analyses &lt;- file.path(root, files[1]) %&gt;% \n  read_csv()\nwave1_scores &lt;- file.path(root, files[2]) %&gt;% \n  read_csv()\nhistorical_data &lt;- file.path(root, files[3]) %&gt;% \n  read_csv()\nThe table below lists all the forecasting teams who participated, along with their discipline, how many members they had, and, if available, some demographic information. Now I love a good team name, and I will be remiss not to mention some standouts. There’s a team of four called The Forecasting Four and a team of five called 5casters. Kudos to The Well-Adjusted R Squares for being well-adjusted and to ForeverJung90 for being forever Jung. It looks like 4 chimps with a dart and Abracadabra named themselves after their methods. And to whoever registered himself as Cynical Belief in the Inexorable Crush of the Wheel — I hope you made T-shirts.\nCode\nlibrary(reactable)\n\nteams &lt;- dat_for_analyses %&gt;% \n  filter(isExpert == 1) %&gt;% \n  mutate(team_education_inv = 100 - team_education) %&gt;% \n  select(team_name, discipline, team_size.coded, team_Age, team_gender, team_education_inv, non_US) %&gt;%\n  distinct() %&gt;% \n  arrange(team_name)\n\nteams %&gt;%   \n  reactable(\n    defaultColDef = colDef(\n      align = \"center\",\n      headerStyle = list(fontFamily = \"Karla\", background = \"#f7f7f8\"),\n      sortNALast = TRUE,\n      format = colFormat(digits = 0)\n    ),\n    columns = list(\n      team_name = colDef(name = \"Team name\", minWidth = 250, align = \"left\"),\n      discipline = colDef(name = \"Disicipline\", minWidth = 200, align = \"left\"),\n      team_size.coded = colDef(name = \"Members\", minWidth = 110),\n      team_Age = colDef(name = \"Average age\", minWidth = 110),\n      team_gender = colDef(name = \"Share not male\", minWidth = 110),\n      team_education_inv = colDef(name = \"Share with Ph.D\", minWidth = 110),\n      non_US = colDef(name = \"Share not US\", minWidth = 110)\n    ),\n    minRows = 5,\n    searchable = TRUE,\n    bordered = TRUE,\n    highlight = TRUE,\n    theme = reactableTheme(\n      searchInputStyle = list(align = \"left\")\n    )\n  )\nLet’s visualize how these teams did in their forecasting. The preferred measure of the paper is mean absolute scaled error, or MASE, a metric that can be compared across different variables despite different scales. The higher the MASE, the worse the forecast. Let’s first do some data wrangling on R.\nCode\ndomains_key &lt;- tibble(\n  domain = c(\n    \"egend\",\n    \"igend\",\n    \"eafric\",\n    \"iafric\",\n    \"easian\",\n    \"iasian\",\n    \"ideoldem\",\n    \"ideolrep\",\n    \"polar\",\n    \"lifesat\",\n    \"posaffect\",\n    \"negaffect\"\n  ),\n  domain_long = c(\n    \"Explicit gender–career bias\",\n    \"Implicit gender–career bias\",\n    \"Explicit African American bias\",\n    \"Implicit African American bias\",\n    \"Explicit Asian American bias\",\n    \"Implicit Asian American bias\",\n    \"Ideologically lean Democrat\",\n    \"Ideologically lean Republican\",\n    \"Political polarization\",\n    \"Life satisfaction\",\n    \"Positive affect in social media\",\n    \"Negative affect in social media\"\n  ),\n  order = as.integer(1:12)\n)\n\nsort &lt;- tibble(\n  method = c(\n    \"All experts\", \n    \"Intuition/theory\",\n    \"Data-driven\",\n    \"Hybrid\",\n    \"Non-experts\"),\n  order = 1:5\n)\n\nscores_all &lt;- wave1_scores %&gt;% \n  left_join(\n    dat_for_analyses %&gt;% \n      select(!starts_with(\"Month.\")), \n    by = c(\"team_name\", \"Method.code\", \"domain\", \"MASE1_w1\")\n  ) %&gt;% \n  left_join(domains_key, by = \"domain\") %&gt;% \n  mutate(method = case_when(\n    is.na(isExpert) ~ \"Non-experts\",\n    TRUE ~ str_to_sentence(Method.code)\n  )\n)\n\nscores &lt;- scores_all %&gt;% \n  filter(isExpert == 1) %&gt;% \n  select(team_name, method, domain_long, MASE1_w1) %&gt;% \n  left_join(sort) %&gt;% \n  arrange(order)\n\nmedians &lt;- scores_all %&gt;% \n  group_by(domain_long, method) %&gt;% \n  summarize(MASE1_w1 = median(MASE1_w1)) %&gt;% \n  ungroup() %&gt;% \n  bind_rows(\n    scores %&gt;% \n      group_by(domain_long) %&gt;% \n      summarize(MASE1_w1 = median(MASE1_w1)) %&gt;% \n      ungroup() %&gt;% \n      mutate(method = \"All experts\")\n  ) %&gt;% \n  left_join(sort) %&gt;% \n  arrange(order)\n\nojs_define(scores_ojs1 = scores)\nojs_define(medians_ojs1 = medians)\nThe function ojs_define() ports our data over to Observable JS, through which we construct an interactive chart:\nCode\nscores_ojs = transpose(scores_ojs1)\nmedians_ojs = transpose(medians_ojs1)\n\ndomains = [\n    \"Explicit gender–career bias\", \n    \"Implicit gender–career bias\", \n    \"Positive affect in social media\", \n    \"Implicit Asian American bias\", \n    \"Political polarization\", \n    \"Explicit Asian American bias\", \n    \"Ideologically lean Democrat\", \n    \"Life satisfaction\", \n    \"Negative affect in social media\", \n    \"Explicit African American bias\", \n    \"Implicit African American bias\",\n    \"Ideologically lean Republican\"\n]\n\nviewof median_radio = Inputs.radio(\n    d3.group(medians_ojs, d =&gt; d.method), \n    { key: \"All experts\", label: html`&lt;b&gt;Median&lt;/b&gt;` }\n)\n\nviewof mase_range = Inputs.range(\n    [3, d3.extent(scores_ojs, d =&gt; d.MASE1_w1)], \n    { step: .5, value: 25, label: html`&lt;b&gt;MASE max&lt;/b&gt;`, format: x =&gt; x.toFixed(0) }\n)\n\naddTooltips(\n    Plot.plot({\n        marks: [\n            Plot.frame({ fill: \"#f7f7f7\" }),\n            Plot.dot(scores_ojs, {\n                x: \"MASE1_w1\",\n                y: \"domain_long\",\n                title: \"team_name\",\n                r: 7,\n                fill: \"method\",\n                fillOpacity: 0.5,\n            }),\n            Plot.dot(median_radio, {\n                x: \"MASE1_w1\",\n                y: \"domain_long\",\n                r: 7,\n                stroke: \"black\",\n                strokeWidth: 2,\n            }),\n        ],\n        x: {\n            label: \"Mean absolute scaled error\",\n            labelAnchor: \"center\",\n            tickSize: 0,\n            grid: false,\n            domain: [0, mase_range],\n        },\n        y: {\n            label: null,\n            tickSize: 0,\n            grid: true,\n            padding: 0,\n            domain: domains,\n        },\n        color: {\n            legend: true,\n            domain: [\"Intuition/theory\", \"Data-driven\", \"Hybrid\"],\n            range: [\"#B13D70\", \"#7fc6a4\", \"#4889ab\"],\n        },\n        width: 800,\n        height: 450,\n        marginLeft: 215,\n        marginRight: 10,\n        marginBottom: 50,\n        insetLeft: 5,\n        insetTop: 20,\n        insetBottom: 20,\n    })\n);\nIt’s clear that some variables were harder to forecast than others. The evolution of explicit gender-career bias (i.e. the explicit association of certain genders with certain careers) was forecasted with relatively small errors, whereas support for the Republican Party was forecasted with large errors (few anticipated it to shoot up [!]). Implicit bias against African-Americans stands out as being the one nearly all experts (and non-experts) got wrong: the measure, happily, fell down more than anyone anticipated.\nThe median expert generally had a slight lead over the median non-expert, though not by much. The paper explores the underlying distributions and concludes that experts only had a statistically significant lead in forecasting life satisfaction, polarization, and explicit and implicit gender–career bias; in all other variables, they performed no better than non-experts.\nAmong experts, it was found that those employing data-driven strategies (either with or without consideration of subject matter theories) performed the best. This reflects well on data scientists but poorly on domain experts. It essentially means that one can get good results by throwing any old variable into a forecasting model without necessarily thinking too hard about the social phenomena behind that variable.\nWhich team, overall, performed the best? Let’s visualize the rankings of teams across all 12 domains. To keep the chart manageable, let’s only include teams who ranked in the top three of at least one domain. There were 24 such teams in total:\nCode\nlibrary(ggplot2)\n\nrank &lt;- scores_all %&gt;% \n  filter(isExpert == 1) %&gt;% \n  group_by(team_name) %&gt;% \n  filter(any(Rank &lt;= 3)) %&gt;% \n  ungroup() %&gt;% \n  select(team_name, order, domain_long, Rank) %&gt;% \n  group_by(team_name) %&gt;% \n  mutate(participated = n()) %&gt;% \n  ungroup() %&gt;% \n  arrange(participated) %&gt;% \n  mutate(\n    team_name = factor(team_name, levels = unique(team_name)),\n    domain_label = paste(order, domain_long) %&gt;% \n      factor(levels = paste(domains_key$order, domains_key$domain_long))\n  )\n\nrank %&gt;% \n  ggplot(aes(x = order, y = team_name, fill = Rank, alpha = domain_label)) +\n  geom_tile(color = \"gray97\", linewidth = 1) +\n  geom_text(aes(label = Rank), size = 11/.pt, color = \"white\") +\n  \n  scale_x_continuous(position = \"top\", breaks = 1:12, expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_fill_gradientn(colors = c(\"#32C778\", \"gray90\", \"gray90\", \"#f697bb\", \"#B13D70\")) +\n  scale_alpha_manual(values = rep(1, 12)) +\n  \n  labs(\n    title = \"Augur games\",\n    subtitle = \"Team rankings in domains they participated in\",\n    caption = \"Note: Only teams that reached the top three in at least one domain are included\\nSource: The Forecasting Collaborative\",\n  ) +\n  \n  guides(\n    fill = \"none\", \n    alpha = guide_legend(\n      title = \"Domains\",\n      title.position = \"top\",\n      keywidth = 0, \n      keyheight = unit(.6, \"cm\"), \n      nrow = 4, \n      override.aes = list(fill = NA)\n    )) +\n  \n  theme(\n    text = element_text(family = \"karla\"),\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.x = element_text(size = 11, margin = margin(b = 5)),\n    axis.text.y = element_text(size = 11, margin = margin(r = 5)),\n    legend.key = element_blank(),\n    legend.text = element_text(size = 11),\n    legend.title = element_text(size = 11, face = \"bold\"),\n    legend.title.align = .03,\n    legend.position = \"bottom\",\n    legend.box.margin = margin(l = -120),\n    panel.background = element_rect(fill = \"gray97\", color = NA),\n    panel.grid = element_blank(),\n    plot.title.position = \"plot\", \n    plot.title = element_text(size = 16, face = \"bold\", hjust = .5),\n    plot.subtitle = element_text(size = 14, hjust = .5, margin = margin(b = 12)),\n    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 10)),\n    plot.caption.position = \"plot\"\n  )\nIn terms of first place finishes, fearfulastra takes the cake with three. However, they performed rather poorly in forecasting life satisfaction. NotGreatWithNamesTeam has the best track record, participating in two domains and getting a first and a second. But the most well-rounded would probably be The Well-Adjusted R Squares, who had four finishes in the top three and whose worst performance was just 16th place.\nLet’s chart the forecasts of the best performing expert in each domain against how these variables actually evolved. As a benchmark, let’s also chart the forecasts of the median non-expert.\nCode\nactual &lt;- historical_data %&gt;% \n  pivot_longer(cols = negaffect:polar,\n               names_to = \"domain\",\n               values_to = \"value\") %&gt;% \n  left_join(domains_key) %&gt;% \n  mutate(series = \"Actual\") %&gt;% \n  select(series, domain_long, month = Month, value)\n\nseries &lt;- scores_all %&gt;% \n  mutate(series = case_when(\n    isExpert == 1 ~ \"Top expert\",\n    is.na(isExpert) ~ \"Median non-expert\"\n  )) %&gt;% \n  pivot_longer(cols = starts_with(\"Month.\"),\n               names_to = \"month\",\n               names_prefix = \"Month.\",\n               values_to = \"value\") %&gt;% \n  mutate(month = as.numeric(month)) %&gt;% \n  group_by(series, domain_long, month) %&gt;% \n  filter(Rank == 1 | is.na(Rank)) %&gt;% \n  ungroup() %&gt;% \n  select(series, team_name, domain_long, month, value) %&gt;% \n  bind_rows(actual)\n\nojs_define(series_ojs1 = series)\nCode\nseries_ojs = transpose(series_ojs1)\n\nviewof select = Inputs.select(\n    d3.group(series_ojs, d =&gt; d.domain_long), \n    { label: html`&lt;b&gt;Domain&lt;/b&gt;` }\n)\n\nviewof month_range = Inputs.range(\n    [d3.extent(series_ojs, d =&gt; d.month)[0], -3], \n    { label: html`&lt;b&gt;Months prior&lt;/b&gt;`, value: -24, step: 1 }\n)\n\ndomain_unit = (d3.max(select, d =&gt; d.value) - d3.min(select, d =&gt; d.value)) / 4\n\naddTooltips(\n    Plot.plot({\n        marks: [\n            Plot.frame({ fill: \"#f7f7f7\" }),\n            Plot.lineY(\n                select.filter((d) =&gt; d.month &gt; month_range),\n                { x: \"month\", y: \"value\", stroke: \"series\", strokeWidth: 2.5 }\n            ),\n            Plot.dot(\n                select.filter((d) =&gt; d.month &gt; month_range),\n                {\n                    x: \"month\",\n                    y: \"value\",\n                    title: \"value\",\n                    fill: \"series\",\n                    r: 5,\n                    stroke: \"white\",\n                }\n            ),\n            Plot.ruleX([0], {\n                strokeOpacity: 0.9,\n                strokeWidth: 1,\n                strokeDasharray: \"5,5\",\n            }),\n            Plot.text(select.slice(0, 1), {\n                text: (d) =&gt; d.domain_long,\n                textAnchor: \"start\",\n                frameAnchor: \"top-left\",\n                fontWeight: \"bold\",\n                fontSize: 15,\n                dx: 20,\n                dy: 18,\n            }),\n            Plot.text(select.slice(0, 1), {\n                text: (d) =&gt; `Top expert: ${d.team_name}`,\n                textAnchor: \"start\",\n                frameAnchor: \"top-left\",\n                fontSize: 14,\n                dx: 20,\n                dy: 39,\n            }),\n        ],\n        x: {\n            label: \"Month\",\n            labelAnchor: \"center\",\n            tickSize: 0,\n        },\n        y: {\n            label: null,\n            ticks: 5,\n            tickSize: 0,\n            domain: [\n                d3.min(select, (d) =&gt; d.value) - domain_unit,\n                d3.max(select, (d) =&gt; d.value) + domain_unit,\n            ],\n        },\n        color: {\n            legend: true,\n            range: [\"#bcbcbc\", \"#B13D70\", \"#0C6291\"],\n        },\n        width: 800,\n        height: 450,\n        insetTop: 20,\n        insetBottom: 20,\n        insetRight: 20,\n        insetLeft: 20,\n        marginBottom: 50,\n        marginLeft: 45,\n        marginRight: 0,\n    }),\n    { r: 7.5 }\n);\nIt’s interesting to see how many of these variables underwent a noticeable shift during the period under study. Negative social media affect — estimated by analyzing tweets — shot up as people stuck at home viciously argued about everything from masks to Black Lives Matter. The conversations around race following the murder of George Floyd translated to drops in the stereotyping of African-Americans and Asian-Americans (though it should be noted that these are based on online surveys and may suffer heavily from selection bias). Forecasts from top-performing experts actually did pretty well; particularly impressive was Erebuni’s anticipation of the bump in Republican support. Incidentally, all their members were non-Americans.\nWhat to make of these results? Perhaps it’s a little unfair to judge social scientists too harshly. It was a once-in-a-century pandemic, no one had any models for this. But at the same time, isn’t it precisely during periods of great uncertainty when guidance from domain experts is needed the most? Don’t tell me now that you were just a bunch of chimps with a dart!"
  },
  {
    "objectID": "posts/2023-03-12-prediction/index.html#d3-observable-code",
    "href": "posts/2023-03-12-prediction/index.html#d3-observable-code",
    "title": "Telling the future is hard",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\naddTooltips = (chart, styles) =&gt; {\n    const stroke_styles = { stroke: \"blue\", \"stroke-width\": 3 };\n    const fill_styles = { fill: \"blue\", opacity: 0.5 };\n\n    // Workaround if it's in a figure\n    const type = d3.select(chart).node().tagName;\n    let wrapper =\n        type === \"FIGURE\" ? d3.select(chart).select(\"svg\") : d3.select(chart);\n\n    // Workaround if there's a legend....\n    const svgs = d3.select(chart).selectAll(\"svg\");\n    if (svgs.size() &gt; 1) wrapper = d3.select([...svgs].pop());\n    wrapper.style(\"overflow\", \"visible\"); // to avoid clipping at the edges\n\n    // Set pointer events to visibleStroke if the fill is none (e.g., if its a line)\n    wrapper.selectAll(\"path\").each(function (data, index, nodes) {\n        // For line charts, set the pointer events to be visible stroke\n        if (\n            d3.select(this).attr(\"fill\") === null ||\n            d3.select(this).attr(\"fill\") === \"none\"\n        ) {\n            d3.select(this).style(\"pointer-events\", \"visibleStroke\");\n            if (styles === undefined) styles = stroke_styles;\n        }\n    });\n\n    if (styles === undefined) styles = fill_styles;\n\n    const tip = wrapper\n        .selectAll(\".hover\")\n        .data([1])\n        .join(\"g\")\n        .attr(\"class\", \"hover\")\n        .style(\"pointer-events\", \"none\")\n        .style(\"text-anchor\", \"middle\");\n\n    // Add a unique id to the chart for styling\n    const id = id_generator();\n\n    // Add the event listeners\n    d3.select(chart).classed(id, true); // using a class selector so that it doesn't overwrite the ID\n    wrapper.selectAll(\"title\").each(function () {\n        // Get the text out of the title, set it as an attribute on the parent, and remove it\n        const title = d3.select(this); // title element that we want to remove\n        const parent = d3.select(this.parentNode); // visual mark on the screen\n        const t = title.text();\n        if (t) {\n            parent.attr(\"__title\", t).classed(\"has-title\", true);\n            title.remove();\n        }\n        // Mouse events\n        parent\n            .on(\"pointerenter pointermove\", function (event) {\n                const text = d3.select(this).attr(\"__title\");\n                const pointer = d3.pointer(event, wrapper.node());\n                if (text) tip.call(hover, pointer, text.split(\"\\n\"));\n                else tip.selectAll(\"*\").remove();\n\n                // Raise it\n                d3.select(this).raise();\n                // Keep within the parent horizontally\n                const tipSize = tip.node().getBBox();\n                if (pointer[0] + tipSize.x &lt; 0)\n                    tip.attr(\n                        \"transform\",\n                        `translate(${tipSize.width / 2}, ${pointer[1] + 7})`\n                    );\n                else if (pointer[0] + tipSize.width / 2 &gt; wrapper.attr(\"width\"))\n                    tip.attr(\n                        \"transform\",\n                        `translate(${\n                            wrapper.attr(\"width\") - tipSize.width / 2\n                        }, ${pointer[1] + 7})`\n                    );\n            })\n            .on(\"pointerout\", function (event) {\n                tip.selectAll(\"*\").remove();\n                // Lower it!\n                d3.select(this).lower();\n            });\n    });\n\n    // Remove the tip if you tap on the wrapper (for mobile)\n    wrapper.on(\"touchstart\", () =&gt; tip.selectAll(\"*\").remove());\n\n    // Define the styles\n    chart.appendChild(html`&lt;style&gt;\n    .${id} .has-title { cursor: pointer;  pointer-events: all; }\n    .${id} .has-title:hover { ${Object.entries(styles).map(([key, value]) =&gt; `${key}: ${value};`).join(\" \")} }`);\n\n    return chart;\n};\n\nhover = (tip, pos, text) =&gt; {\n    const side_padding = 10;\n    const vertical_padding = 5;\n    const vertical_offset = 25;\n\n    // Empty it out\n    tip.selectAll(\"*\").remove();\n\n    // Append the text\n    tip.style(\"text-anchor\", \"middle\")\n        .style(\"pointer-events\", \"none\")\n        .attr(\"transform\", `translate(${pos[0]}, ${pos[1] + 7})`)\n        .selectAll(\"text\")\n        .data(text)\n        .join(\"text\")\n        .style(\"dominant-baseline\", \"ideographic\")\n        .text((d) =&gt; d)\n        .attr(\"y\", (d, i) =&gt; (i - (text.length - 1)) * 15 - vertical_offset)\n        .style(\"font-weight\", (d, i) =&gt; (i === 0 ? \"bold\" : \"normal\"));\n\n    const bbox = tip.node().getBBox();\n\n    // Add a rectangle (as background)\n    tip.append(\"rect\")\n        .attr(\"y\", bbox.y - vertical_padding)\n        .attr(\"x\", bbox.x - side_padding)\n        .attr(\"width\", bbox.width + side_padding * 2)\n        .attr(\"height\", bbox.height + vertical_padding * 2)\n        .style(\"fill\", \"white\")\n        .style(\"stroke\", \"#d3d3d3\")\n        .lower();\n};\n\nid_generator = () =&gt; {\n    var S4 = function () {\n        return (((1 + Math.random()) * 0x10000) | 0).toString(16).substring(1);\n    };\n    return \"a\" + S4() + S4();\n};"
  },
  {
    "objectID": "posts/2023-03-12-prediction/index.html#footnotes",
    "href": "posts/2023-03-12-prediction/index.html#footnotes",
    "title": "Telling the future is hard",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere was a second round that extended the forecasted period to October 2020, but I won’t be covering that in this post.↩︎\nThank you to forecasting guru Basti Ibañez for first telling me about this paper.↩︎"
  },
  {
    "objectID": "posts/2023-03-22-literary-analysis/index.html",
    "href": "posts/2023-03-22-literary-analysis/index.html",
    "title": "I just read 456 books*",
    "section": "",
    "text": "In a previous post, we charted the emotional shape of three novels by assigning them sentiment scores through the AFINN lexicon. But three is peanuts — I’m bolder now, more audacious, and subsisting on three cups of coffee a day. In this post, I chew on as many classics from the 19th century as my laptop will let me. The result is this beautiful visualization mapping the textual similarities between literary works, powered by D3’s force engine. Hover over a node to see the title and author, or click and drag to examine how each is connected to the rest.\nCode\nlibraryNetwork = FileAttachment(\n    \"../../datasets/literary/library_network.json\"\n).json({ typed: true });\n\naddTooltips(\n    ForceGraph(libraryNetwork, {\n        nodeGroup: (d) =&gt; d.nationality,\n        nodeTitle: (d) =&gt; `${d.title}\\n${d.query} (${d.nationality})`,\n        nodeStrokeOpacity: 0.7,\n        linkStrokeWidth: (l) =&gt; Math.sqrt(l.value),\n        nodeRadius: 6,\n        width: 800,\n        height: 750,\n        colors: [\"#B13D70\", \"#7fc6a4\", \"#4889ab\", \"#F7DD72\"],\n    }),\n    { r: 7, opacity: 1, \"stroke-width\": \"2px\", stroke: \"black\" }\n);\nLet’s see how we got here. To take advantage of certain packages, I’ll be using Python instead of my usual R.\nPackages\n# Standard packages\nimport numpy as np\nimport pandas as pd\nimport itertools\nimport sqlite3\nimport re\nfrom scipy.spatial.distance import pdist\nimport json\n\n# collections in Python &gt;3.9 no longer has MutableSet module so we have to get it from collections.abc for the cache download to work\nimport collections\nfrom collections.abc import MutableSet\ncollections.MutableSet = collections.abc.MutableSet\n\n# Text analysis\nfrom gutenbergpy.gutenbergcache import GutenbergCache, GutenbergCacheSettings\nimport gutenbergpy.textget\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom textblob import TextBlob\nimport umap.umap_ as umap\nAs before, our data source is Project Gutenberg, accessed via the gutenbergpy package. Downloading a work requires knowing its Gutenberg ID, which is tedious to look up if we want a ton of novels. Let’s devise a process that automatically fetches IDs given an author prompt — say, “Herman Melville”. To be able to search through the Gutenberg database, we must first generate a local cache of its records by running GutenbergCache.create(). This only needs to be done once. Once set up, we can connect to it:\nconnection = sqlite3.connect('../../datasets/literary/' + GutenbergCacheSettings.CACHE_FILENAME)\nOur SQL query will be of the following form:\nGutenberg is not a very clean library; much detritus is uploaded alongside the novels we actually want. To help focus the search, we order the query results by number of downloads and take at most the top 50. This removes some nuisance hits but, as we will see, there is much further work to be done.\nLet’s write a function that generates a SQL query given an author prompt:\nquery_author()\ndef query_author(name):\n  inputs = name.split()\n  query = (\n    'SELECT DISTINCT books.gutenbergbookid, authors.name, titles.name, books.numdownloads '\n    'FROM books, authors, book_authors, titles '\n    'WHERE authors.id = book_authors.authorid ' \n          'AND books.id = book_authors.bookid '\n          'AND books.id = titles.bookid '\n          'AND books.languageid = 1 '\n          'AND books.typeid = -1 '\n      'AND %s '\n    'ORDER BY books.numdownloads DESC '\n    'LIMIT 50'\n    % ' AND '.join([\"authors.name LIKE ('%\" + \"%s\" %n + \"%')\" for n in inputs])        \n  )\n  return query\nQuerying “Herman Melville” produces:\nresults = pd.read_sql_query(query_author('Herman Melville'), connection)\nresults.columns = ['gutid', 'author', 'title', 'downloads']\nprint(results.head().to_markdown())\n\n|    |   gutid | author            | title                                           |   downloads |\n|---:|--------:|:------------------|:------------------------------------------------|------------:|\n|  0 |    2701 | Melville, Hermann | Moby Dick; Or, The Whale                        |      148386 |\n|  1 |    2701 | Melville, Herman  | Moby Dick; Or, The Whale                        |      148386 |\n|  2 |   11231 | Melville, Hermann | Bartleby, the Scrivener: A Story of Wall-Street |        2466 |\n|  3 |   11231 | Melville, Herman  | Bartleby, the Scrivener: A Story of Wall-Street |        2466 |\n|  4 |   15859 | Melville, Hermann | The Piazza Tales                                |        1186 |\nIt is clear that duplicates are a problem. The multiple spellings of Melville’s name aren’t much of an issue since they map to the same Gutenberg IDs. We can easily remove these.\nduplicated_ids = results['gutid'].duplicated(keep='first')\nresults = results.loc[~duplicated_ids].reset_index(drop=True)\nprint(results.to_markdown())\n\n|    |   gutid | author            | title                                                                                             |   downloads |\n|---:|--------:|:------------------|:--------------------------------------------------------------------------------------------------|------------:|\n|  0 |    2701 | Melville, Hermann | Moby Dick; Or, The Whale                                                                          |      148386 |\n|  1 |   11231 | Melville, Hermann | Bartleby, the Scrivener: A Story of Wall-Street                                                   |        2466 |\n|  2 |   15859 | Melville, Hermann | The Piazza Tales                                                                                  |        1186 |\n|  3 |      15 | Melville, Hermann | Moby-Dick; or, The Whale                                                                          |        1137 |\n|  4 |   21816 | Melville, Hermann | The Confidence-Man: His Masquerade                                                                |         432 |\n|  5 |    1900 | Melville, Hermann | Typee: A Romance of the South Seas                                                                |         424 |\n|  6 |   12384 | Melville, Hermann | Battle-Pieces and Aspects of the War                                                              |         283 |\n|  7 |   34970 | Melville, Hermann | Pierre; or The Ambiguities                                                                        |         280 |\n|  8 |   28656 | Melville, Hermann | Typee                                                                                             |         216 |\n|  9 |    2489 | Melville, Hermann | Moby Dick; Or, The Whale                                                                          |         185 |\n| 10 |   10712 | Melville, Hermann | White Jacket; Or, The World on a Man-of-War                                                       |         180 |\n| 11 |    8118 | Melville, Hermann | Redburn. His First Voyage                                                                         |         160 |\n|    |         |                   | Being the Sailor Boy Confessions and Reminiscences of the Son-Of-A-Gentleman in the Merchant Navy |             |\n| 12 |    4045 | Melville, Hermann | Omoo: Adventures in the South Seas                                                                |         148 |\n| 13 |   53861 | Melville, Hermann | The Apple-Tree Table, and Other Sketches                                                          |         140 |\n| 14 |    2694 | Melville, Hermann | I and My Chimney                                                                                  |         137 |\n| 15 |   13720 | Melville, Hermann | Mardi: and A Voyage Thither, Vol. I                                                               |          97 |\n| 16 |   15422 | Melville, Hermann | Israel Potter: His Fifty Years of Exile                                                           |          69 |\n| 17 |   13721 | Melville, Hermann | Mardi: and A Voyage Thither, Vol. II                                                              |          51 |\n| 18 |   12841 | Melville, Hermann | John Marr and Other Poems                                                                         |          51 |\n| 19 |   58477 | Melville, Hermann | Index of the Project Gutenberg Works of Herman Melville                                           |          40 |\nMore problematically, title variants of the same work (“Moby Dick; Or, The Whale” vs “Moby Dick; or, The Whale”) map to different IDs. To handle these, we compute a measure for how similar two titles are based on how many case-insensitive, non-trivial words they share. Counting only non-trivial words means that the presence of “or the” in both “Moby Dick; Or, The Whale” and “Pierre; or The Ambiguities” should not count towards their similarity.\nThe measure we use is cosine similarity. Computing this pairwise for all titles produces a matrix, the upper triangular half of which we chop off since we want to prioritize removing duplicates with the lower number of downloads. Let’s demonstrate with the “Herman Melville” query results:\n# Compute cosine similarity matrix\nresults_vectorized = CountVectorizer(stop_words=\"english\").fit_transform(list(results['title']))\ncosine_sim = cosine_similarity(results_vectorized)\ncosine_sim[np.triu_indices_from(cosine_sim)] = np.nan\n\n# Print\nnp.set_printoptions(linewidth=np.inf)\ncosine_sim = np.round(cosine_sim, decimals=2)\ncosine_sim\n\narray([[ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [1.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.22, 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.  , 0.  , 0.89, 0.  ,  nan,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan,  nan],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,  nan]])\nWe can use some threshold — say, 0.5 — to select the indices of potential duplicates and remove them. Note that this method isn’t perfect: column 5 (“Typee: A Romance of the South Seas”), for instance, has similarity scores of 0.5 with both row 8 (“Typee”) and row 12 (“Omoo: Adventures in the South Seas”). Typee and Omoo are two different novels that share similar subtitles, so unfortunately our approach inadvertently removes Omoo.\nLet’s turn all this into a function and apply it to the “Herman Melville” results.\nremove_duplicates()\ndef remove_duplicates(df):\n\n  # Remove duplicates by Gutenberg book ID\n  duplicated_ids = df['gutid'].duplicated(keep='first')\n  df = df.loc[~duplicated_ids].reset_index(drop=True)\n\n  # Extract similar titles\n  vectorized = CountVectorizer(stop_words='english').fit_transform(list(df['title']))\n  cosine_sim = cosine_similarity(vectorized)\n  cosine_sim[np.triu_indices_from(cosine_sim)] = np.nan\n\n  indices = []\n  for i, row in enumerate(cosine_sim):\n    if any(not np.isnan(x) and x &gt;= 0.5 for x in row):\n      indices.append(i)\n  \n  # But keep parts of a series\n  indices_keep = np.where(df['title'].str.contains(pat='Vol|vol|Part|part'))[0]\n  indices = [i for i in indices if i not in indices_keep]\n  \n  df = df.drop(indices).reset_index(drop=True)\n\n  return df\nresults_cleaned = remove_duplicates(results)\nprint(results_cleaned.to_markdown())\n\n|    |   gutid | author            | title                                                                                             |   downloads |\n|---:|--------:|:------------------|:--------------------------------------------------------------------------------------------------|------------:|\n|  0 |    2701 | Melville, Hermann | Moby Dick; Or, The Whale                                                                          |      148386 |\n|  1 |   11231 | Melville, Hermann | Bartleby, the Scrivener: A Story of Wall-Street                                                   |        2466 |\n|  2 |   15859 | Melville, Hermann | The Piazza Tales                                                                                  |        1186 |\n|  3 |   21816 | Melville, Hermann | The Confidence-Man: His Masquerade                                                                |         432 |\n|  4 |    1900 | Melville, Hermann | Typee: A Romance of the South Seas                                                                |         424 |\n|  5 |   12384 | Melville, Hermann | Battle-Pieces and Aspects of the War                                                              |         283 |\n|  6 |   34970 | Melville, Hermann | Pierre; or The Ambiguities                                                                        |         280 |\n|  7 |   10712 | Melville, Hermann | White Jacket; Or, The World on a Man-of-War                                                       |         180 |\n|  8 |    8118 | Melville, Hermann | Redburn. His First Voyage                                                                         |         160 |\n|    |         |                   | Being the Sailor Boy Confessions and Reminiscences of the Son-Of-A-Gentleman in the Merchant Navy |             |\n|  9 |   53861 | Melville, Hermann | The Apple-Tree Table, and Other Sketches                                                          |         140 |\n| 10 |    2694 | Melville, Hermann | I and My Chimney                                                                                  |         137 |\n| 11 |   13720 | Melville, Hermann | Mardi: and A Voyage Thither, Vol. I                                                               |          97 |\n| 12 |   15422 | Melville, Hermann | Israel Potter: His Fifty Years of Exile                                                           |          69 |\n| 13 |   13721 | Melville, Hermann | Mardi: and A Voyage Thither, Vol. II                                                              |          51 |\n| 14 |   12841 | Melville, Hermann | John Marr and Other Poems                                                                         |          51 |\n| 15 |   58477 | Melville, Hermann | Index of the Project Gutenberg Works of Herman Melville                                           |          40 |\nThe list of authors whose works we will analyze is given under the fold. I’ve selected those who were most representative of English, American, French, and Russian literature during the 19th century. This list, of course, is subjective. We will be using English translations of the non-English works.\nAuthors list\nauthors = {\n  'English': [\n    'Walter Scott',\n    'Jane Austen',\n    'Mary Shelley',\n    'William Thackeray',\n    'Charles Dickens',\n    'Charlotte Bronte',\n    'Emily Bronte',\n    'George Eliot',\n    'Anthony Trollope',\n    'Thomas Hardy'\n  ], \n  'American': [\n    'Louisa May Alcott',\n    'Nathaniel Hawthorne',\n    'Herman Melville',\n    'Mark Twain',\n    'Henry James'\n  ], \n  'French': [\n    'Stendhal',\n    'Alexander Dumas',\n    'Victor Hugo',\n    'Gustave Flaubert',\n    'Honore de Balzac',\n    'Emile Zola'\n  ], \n  'Russian': [\n    'Nikolai Gogol',\n    'Ivan Turgenev',\n    'Fyodor Dostoevsky',\n    'Leo Tolstoy'\n  ]\n}\nThis loop assembles our library of IDs.\nlibrary = pd.DataFrame(columns=['gutid', 'author', 'title', 'downloads', 'nationality'])\n\nfor nationality, names in authors.items():\n  for name in names:\n    results = pd.read_sql_query(query_author(name), connection)\n    results.columns = ['gutid', 'author', 'title', 'downloads']\n    results = remove_duplicates(results)\n    results['query'] = name\n    results['nationality'] = nationality\n    library = pd.concat([library, results], ignore_index=True)\nScanning the result, I see that there’s a bunch more included that shouldn’t have been. I just remove these manually under the fold.\nFurther adjustments\nexclude_authors = [\n  'Herr, Charlotte Bronte',\n  'Stark, James Henry', \n  'Schmitz, James Henry', \n  'Maine, Henry James Sumner, Sir'\n]\n\nexclude_titles = [\n  'Gutenberg', \n  \n  # Poems\n  'Poems', \n  'Ballads', \n  'Lyrics', \n  'Verses', \n  'Marmion: A Tale Of Flodden Field',\n  'The Lady of the Lake',\n  'The Mahogany Tree',\n  'Richard Coeur de Lion and Blondel',\n  'The Loving Ballad of Lord Bateman',\n  \n  # Biographical\n  'Letters', \n  'Speeches',\n  'literary and scientific men', \n  'Biographical Notes', \n  'My Memoirs', \n  'The Memoirs of Victor Hugo', \n  'An Autobiography of Anthony Trollope', \n  'The trial of Emile Zola',\n  'The George Sand-Gustave Flaubert Letters', \n  \n  # Duplicates\n  'Les Misérables, v. 1/5: Fantine', \n  'The Grand Inquisitor', \n  'Fathers and Children',\n  'The Charterhouse of Parma, Volume', \n  'Madame Bovary: A Tale of Provincial Life',\n  'Home Life in Russia, Volumes 1 and 2'\n]\n\nlibrary = library.loc[~library['author'].str.contains('|'.join(exclude_authors))].reset_index(drop=True)\nlibrary = library.loc[~library['title'].str.contains('|'.join(exclude_titles))].reset_index(drop=True)\nThe resulting library contains 456 unique IDs of what I hope are mostly novels, short story collections, and works of creative non-fiction. I have tried to exclude all poetry, plays, and any remaining duplicates.\nArmed with these IDs, we get the actual texts from Gutenberg and perform a little cleaning on them using the function get_and_clean_text().\nget_and_clean_text()\ndef get_and_clean_text(id):\n  \n  # Get text\n  raw_text = gutenbergpy.textget.get_text_by_id(id)\n  text = gutenbergpy.textget.strip_headers(raw_text).decode()\n  \n  # Remove page-based line breaks and excessive paragraph breaks\n  text = re.sub('(?&lt;=[^\\n])\\n{1}(?=[^\\n])', ' ', text)\n  text = re.sub('[\\n]{3,}', '\\n\\n', text)\n\n  # Go paragraph by paragraph\n  df = pd.DataFrame({'paragraph': text.split('\\n\\n')})\n  patterns = [\n    '^$',                   # Empty\n    '^[A-Z\\s\\W\\d]+$',       # Contains only uppercase letters (likely a heading)\n    '^Chapter',             # Starts with \"Chapter\"\n    '^CHAPTER',             # Starts with \"Chapter\"\n    '^\\s+Chapter',          # Starts with \"Chapter\"\n    '^[A-Za-z]+$',          # Contains just one word, no punctuation\n    'Gutenberg', 'Illustration', 'Online Distributed Proofreading Team', '.jpg'\n  ]\n  df = df.loc[~df['paragraph'].str.contains(pat='|'.join(patterns), regex=True)]\n  clean_text = '\\n\\n'.join(list(df['paragraph']))\n  \n  return clean_text\ntexts = []\nfor row in range(len(library)):\n  text = get_and_clean_text(library['gutid'][row])\n  texts.append(text)\n\nlibrary['text'] = texts\n\nconnection.close()\nNow we are ready to compute some metrics on our texts. It’s easy enough to get word counts, which is useful for validating whether our library has excluded poems and plays. The textblob package also has a sentiment analyzer that we can use; this ranges from -1 to 1. Another interesting metric to look at is the average word count per paragraph, which captures a bit of the author’s style: short and punchy or long and meditative.\nlibrary_stats = library[['nationality', 'query', 'title']].copy()\n\n# Word count, sentiment, and subjectivity\nlibrary_stats['words'] = library['text'].apply(lambda n: len(n.split()))\nlibrary_stats['sentiment'] = library['text'].apply(lambda n: TextBlob(n).polarity)\n\n# Average paragraph length\ndef parlength(text):\n  df = pd.DataFrame({'paragraph': text.split('\\n\\n')})\n  df['words'] = df['paragraph'].apply(lambda n: len(re.split(r' |—', n)))\n  return df['words'].mean()\nlibrary_stats['parlength'] = library['text'].apply(lambda n: parlength(n))\nA more sophisticated metric is the extent to which works are textually akin to one another. We already did something similar to detect title duplicates in the Gutenberg database. However, amassing pairwise similarity scores across all our texts will result in far too much information to comprehend. What we will therefore do is apply a dimensionality reduction algorithm to simplify the large number of features into just two — call them x and y. These are meaningless in themselves, but if plotted on a plane, they approximate the multidimensional structure of the dataset in 2D space. The particular algorithm we use is UMAP.\nlibrary_vec = CountVectorizer(min_df=5, stop_words='english').fit_transform(library['text'])\nembeddings = umap.UMAP(random_state=42).fit_transform(library_vec)\nlibrary_stats[\"x\"] = embeddings[:,0]\nlibrary_stats[\"y\"] = embeddings[:,1]\nA technical aside: at this point, I save my results in a csv file and work off that from here on out. This ensures reproducibility should any changes occur in Project Gutenberg.\nNow let’s load up our dataset again, this time in OJS for our visualizations.\nlibraryStats = FileAttachment(\"../../datasets/literary/library_stats.csv\").csv(\n    { typed: true }\n);\nThe scatter below charts literary works on two axes: average paragraph length and sentiment. You can select a particular author from the dropdown box to highlight their works. Because latter-career Henry James forgot how to end paragraphs (and sentences), I have had to add a slider for expanding the horizontal axis.\nThe shortest paragraphs are in the works of Alexandre Dumas, the 19th century’s Tom Clancy. Most (&gt;87%) of the works in the sample generally stick to paragraphs of 100 words or less. In terms of sentiment scores, I was amused to find that Crime and Punishment has a slightly more positive sentiment than Wuthering Heights. Go figure: one explores the utter depths of murderous, depraved, hopeless insanity; the other is Crime and Punishment.\nThe next chart uses the results of the UMAP dimension-reduction algorithm. Again, the values themselves are arbitrary but the positioning of the nodes in 2D space hints at the semantic relationships across texts. There is an interesting cluster comprising Count of Monte Cristo, Les Misérables, War and Peace, and Anna Karenina. These are the blue and yellow dots to the left, somewhat isolated from the other French and Russian works in the sample. Either these books are quite English in content or the particular translations here leaned heavily on English semantics.\nCode\nviewof highlight_b = Inputs.select(\n  d3.group(libraryStats, d =&gt; d.query), \n  {label: html`&lt;b&gt;Highlight an author&lt;/b&gt;`, key: \"Herman Melville\"}\n)\n\naddTooltips(\n    Plot.plot({\n        marks: [\n            Plot.frame({ fill: \"#f7f7f7\" }),\n            Plot.dot(libraryStats, {\n                x: \"x\",\n                y: \"y\",\n                r: 6,\n                fill: \"nationality\",\n                fillOpacity: 0.75,\n                stroke: \"white\",\n                strokeWidth: 1,\n                strokeOpacity: 0.7,\n                title: (d) =&gt; `${d.title} \\n ${d.query} (${d.nationality})`,\n            }),\n            Plot.dot(highlight_b, {\n                x: \"x\",\n                y: \"y\",\n                r: 7,\n                stroke: \"black\",\n                strokeWidth: 3,\n            }),\n        ],\n        x: { label: null, ticks: 0 },\n        y: { label: null, ticks: 0 },\n        color: {\n            legend: true,\n            range: [\"#B13D70\", \"#7fc6a4\", \"#4889ab\", \"#F7DD72\"],\n        },\n        width: 800,\n        height: 500,\n        marginTop: 15,\n        marginBottom: 0,\n        marginLeft: 0,\n        insetTop: 20,\n        insetRight: 20,\n        insetBottom: 20,\n        insetLeft: 20,\n    }),\n    { r: 6, opacity: 0.8, \"stroke-width\": \"3px\", stroke: \"black\" }\n);\nThis scatter is all well and good, but a funner, more interactive way to represent these relationships is through a force-directed network chart, as shown at the top of this blog post. Note that a network chart generator finds the best node positionings given the strength of their linkages. UMAP, meanwhile, starts by defining node positions. To extract a network chart from our UMAP values, we therefore have to reverse engineer the node linkages from the node positions. The way I have done this is by computing the Euclidean distance between nodes and setting the inverse of that as their linkage strength. I then fed this to D3’s force-directed algorithm to produce the network chart above.\nConstructing a network dataset\npairs = list(set(itertools.combinations(library_stats.index.tolist(), 2)))\npairs.sort()\ndistances = pdist(library_stats[['x', 'y']].values)\nvalues = max(distances) - distances\n\nlinks = pd.DataFrame(pairs, columns=['source', 'target'])\nlinks['value'] = values\nlinks = links[~(links['value'] &lt; 9.1)]\nlinks['value'] = (links['value']-links['value'].min())*(5/(links['value'].max()-links['value'].min()))\n\nnodes = pd.DataFrame({\n  'id': library_stats.index,\n  'title': library_stats['title'],\n  'query': library_stats['query'],\n  'nationality': library_stats['nationality']\n})\n\n# Convert dataframes to dictionaries, then to json\nnodes_dict = nodes.to_dict(orient='records')\nlinks_dict = links.to_dict(orient='records')\nnetwork_dict = {'nodes': nodes_dict, 'links': links_dict}\nnetwork = json.dumps(network_dict)\nSo we have analyzed 456 books. Can we go bolder still, more audacious still? The Gutenberg library is vast. Unfortunately, it’s also a mess. There have been many attempts to tame it, including gutenbergpy, but I’m still finding that the efforts involved in data cleaning and data wrangling scale faster than the marginal value of expanding the dataset further. I’ll have to wait for a better API. Until then, this has been your sign to get back to (or start!) the habit of reading. May I suggest Moby-Dick?"
  },
  {
    "objectID": "posts/2023-03-22-literary-analysis/index.html#data-and-cleaning-script",
    "href": "posts/2023-03-22-literary-analysis/index.html#data-and-cleaning-script",
    "title": "I just read 456 books*",
    "section": "Data and cleaning script",
    "text": "Data and cleaning script\n\n\nliterary.py / library_stats.csv, library_network.json"
  },
  {
    "objectID": "posts/2023-03-22-literary-analysis/index.html#d3-observable-code",
    "href": "posts/2023-03-22-literary-analysis/index.html#d3-observable-code",
    "title": "I just read 456 books*",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\naddTooltips = (chart, styles) =&gt; {\n    const stroke_styles = { stroke: \"blue\", \"stroke-width\": 3 };\n    const fill_styles = { fill: \"blue\", opacity: 0.5 };\n\n    // Workaround if it's in a figure\n    const type = d3.select(chart).node().tagName;\n    let wrapper =\n        type === \"FIGURE\" ? d3.select(chart).select(\"svg\") : d3.select(chart);\n\n    // Workaround if there's a legend....\n    const svgs = d3.select(chart).selectAll(\"svg\");\n    if (svgs.size() &gt; 1) wrapper = d3.select([...svgs].pop());\n    wrapper.style(\"overflow\", \"visible\"); // to avoid clipping at the edges\n\n    // Set pointer events to visibleStroke if the fill is none (e.g., if its a line)\n    wrapper.selectAll(\"path\").each(function (data, index, nodes) {\n        // For line charts, set the pointer events to be visible stroke\n        if (\n            d3.select(this).attr(\"fill\") === null ||\n            d3.select(this).attr(\"fill\") === \"none\"\n        ) {\n            d3.select(this).style(\"pointer-events\", \"visibleStroke\");\n            if (styles === undefined) styles = stroke_styles;\n        }\n    });\n\n    if (styles === undefined) styles = fill_styles;\n\n    const tip = wrapper\n        .selectAll(\".hover\")\n        .data([1])\n        .join(\"g\")\n        .attr(\"class\", \"hover\")\n        .style(\"pointer-events\", \"none\")\n        .style(\"text-anchor\", \"middle\");\n\n    // Add a unique id to the chart for styling\n    const id = id_generator();\n\n    // Add the event listeners\n    d3.select(chart).classed(id, true); // using a class selector so that it doesn't overwrite the ID\n    wrapper.selectAll(\"title\").each(function () {\n        // Get the text out of the title, set it as an attribute on the parent, and remove it\n        const title = d3.select(this); // title element that we want to remove\n        const parent = d3.select(this.parentNode); // visual mark on the screen\n        const t = title.text();\n        if (t) {\n            parent.attr(\"__title\", t).classed(\"has-title\", true);\n            title.remove();\n        }\n        // Mouse events\n        parent\n            .on(\"pointerenter pointermove\", function (event) {\n                const text = d3.select(this).attr(\"__title\");\n                const pointer = d3.pointer(event, wrapper.node());\n                if (text) tip.call(hover, pointer, text.split(\"\\n\"));\n                else tip.selectAll(\"*\").remove();\n\n                // Raise it\n                d3.select(this).raise();\n                // Keep within the parent horizontally\n                const tipSize = tip.node().getBBox();\n                if (pointer[0] + tipSize.x &lt; 0)\n                    tip.attr(\n                        \"transform\",\n                        `translate(${tipSize.width / 2}, ${pointer[1] + 7})`\n                    );\n                else if (pointer[0] + tipSize.width / 2 &gt; wrapper.attr(\"width\"))\n                    tip.attr(\n                        \"transform\",\n                        `translate(${wrapper.attr(\"width\") - tipSize.width / 2}, ${\n                            pointer[1] + 7\n                        })`\n                    );\n            })\n            .on(\"pointerout\", function (event) {\n                tip.selectAll(\"*\").remove();\n                // Lower it!\n                d3.select(this).lower();\n            });\n    });\n\n    // Remove the tip if you tap on the wrapper (for mobile)\n    wrapper.on(\"touchstart\", () =&gt; tip.selectAll(\"*\").remove());\n\n    // Define the styles\n    chart.appendChild(html`&lt;style&gt;\n  .${id} .has-title { cursor: pointer;  pointer-events: all; }\n  .${id} .has-title:hover { ${Object.entries(styles).map(([key, value]) =&gt; `${key}: ${value};`).join(\" \")} }`);\n\n    return chart;\n};\n\nhover = (tip, pos, text) =&gt; {\n    const side_padding = 10;\n    const vertical_padding = 5;\n    const vertical_offset = 25;\n\n    // Empty it out\n    tip.selectAll(\"*\").remove();\n\n    // Append the text\n    tip\n        .style(\"text-anchor\", \"middle\")\n        .style(\"pointer-events\", \"none\")\n        .attr(\"transform\", `translate(${pos[0]}, ${pos[1] + 7})`)\n        .selectAll(\"text\")\n        .data(text)\n        .join(\"text\")\n        .style(\"dominant-baseline\", \"ideographic\")\n        .text((d) =&gt; d)\n        .attr(\"y\", (d, i) =&gt; (i - (text.length - 1)) * 15 - vertical_offset)\n        .style(\"font-weight\", (d, i) =&gt; (i === 0 ? \"bold\" : \"normal\"));\n\n    const bbox = tip.node().getBBox();\n\n    // Add a rectangle (as background)\n    tip\n        .append(\"rect\")\n        .attr(\"y\", bbox.y - vertical_padding)\n        .attr(\"x\", bbox.x - side_padding)\n        .attr(\"width\", bbox.width + side_padding * 2)\n        .attr(\"height\", bbox.height + vertical_padding * 2)\n        .style(\"fill\", \"white\")\n        .style(\"stroke\", \"#d3d3d3\")\n        .lower();\n};\n\nid_generator = () =&gt; {\n    var S4 = function () {\n        return (((1 + Math.random()) * 0x10000) | 0).toString(16).substring(1);\n    };\n    return \"a\" + S4() + S4();\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/disjoint-force-directed-graph\n// With edits by me\n\nfunction ForceGraph(\n    {\n        nodes, // an iterable of node objects (typically [{id}, …])\n        links, // an iterable of link objects (typically [{source, target}, …])\n    },\n    {\n        nodeId = (d) =&gt; d.id, // given d in nodes, returns a unique identifier (string)\n        nodeGroup, // given d in nodes, returns an (ordinal) value for color\n        nodeGroups, // an array of ordinal values representing the node groups\n        nodeTitle, // given d in nodes, a title string\n        nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n        nodeStroke = \"#fff\", // node stroke color\n        nodeStrokeWidth = 1.5, // node stroke width, in pixels\n        nodeStrokeOpacity = 1, // node stroke opacity\n        nodeRadius = 5, // node radius, in pixels\n        nodeStrength,\n        linkSource = ({ source }) =&gt; source, // given d in links, returns a node identifier string\n        linkTarget = ({ target }) =&gt; target, // given d in links, returns a node identifier string\n        linkStroke = \"#999\", // link stroke color\n        linkStrokeOpacity = 0.6, // link stroke opacity\n        linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n        linkStrokeLinecap = \"round\", // link stroke linecap\n        linkStrength,\n        colors = d3.schemeTableau10, // an array of color strings, for the node groups\n        width = 640, // outer width, in pixels\n        height = 400, // outer height, in pixels\n        invalidation, // when this promise resolves, stop the simulation\n    } = {}\n) {\n    // Compute values.\n    const N = d3.map(nodes, nodeId).map(intern);\n    const LS = d3.map(links, linkSource).map(intern);\n    const LT = d3.map(links, linkTarget).map(intern);\n    if (nodeTitle === undefined) nodeTitle = (_, i) =&gt; N[i];\n    const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n    const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n    const W =\n        typeof linkStrokeWidth !== \"function\"\n            ? null\n            : d3.map(links, linkStrokeWidth);\n\n    // Replace the input nodes and links with mutable objects for the simulation.\n    nodes = d3.map(nodes, (_, i) =&gt; ({ id: N[i] }));\n    links = d3.map(links, (_, i) =&gt; ({ source: LS[i], target: LT[i] }));\n\n    // Compute default domains.\n    if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n    // Construct the scales.\n    const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n    // Construct the forces.\n    const forceNode = d3.forceManyBody();\n    const forceLink = d3.forceLink(links).id(({ index: i }) =&gt; N[i]);\n    if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n    if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n    const simulation = d3\n        .forceSimulation(nodes)\n        .force(\"link\", forceLink)\n        .force(\"charge\", forceNode)\n        .force(\"x\", d3.forceX())\n        .force(\"y\", d3.forceY())\n        .alphaDecay(0)\n        .on(\"tick\", ticked)\n        .alphaDecay(0);\n\n    const svg = d3\n        .create(\"svg\")\n        .attr(\"width\", width)\n        .attr(\"height\", height)\n        .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n        .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n    const link = svg\n        .append(\"g\")\n        .attr(\"stroke\", linkStroke)\n        .attr(\"stroke-opacity\", linkStrokeOpacity)\n        .attr(\n            \"stroke-width\",\n            typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null\n        )\n        .attr(\"stroke-linecap\", linkStrokeLinecap)\n        .selectAll(\"line\")\n        .data(links)\n        .join(\"line\");\n\n    if (W) link.attr(\"stroke-width\", ({ index: i }) =&gt; W[i]);\n\n    const node = svg\n        .append(\"g\")\n        .attr(\"fill\", nodeFill)\n        .attr(\"stroke\", nodeStroke)\n        .attr(\"stroke-opacity\", nodeStrokeOpacity)\n        .attr(\"stroke-width\", nodeStrokeWidth)\n        .selectAll(\"circle\")\n        .data(nodes)\n        .join(\"circle\")\n        .attr(\"r\", nodeRadius)\n        .call(drag(simulation));\n\n    if (G) node.attr(\"fill\", ({ index: i }) =&gt; color(G[i]));\n    if (T) node.append(\"title\").text(({ index: i }) =&gt; T[i]);\n\n    // Handle invalidation.\n    if (invalidation != null) invalidation.then(() =&gt; simulation.stop());\n\n    function intern(value) {\n        return value !== null && typeof value === \"object\"\n            ? value.valueOf()\n            : value;\n    }\n\n    function ticked() {\n        link\n            .attr(\"x1\", (d) =&gt; d.source.x)\n            .attr(\"y1\", (d) =&gt; d.source.y)\n            .attr(\"x2\", (d) =&gt; d.target.x)\n            .attr(\"y2\", (d) =&gt; d.target.y);\n\n        node.attr(\"cx\", (d) =&gt; d.x).attr(\"cy\", (d) =&gt; d.y);\n    }\n\n    function drag(simulation) {\n        function dragstarted(event) {\n            if (!event.active) simulation.alphaTarget(0.3).restart();\n            event.subject.fx = event.subject.x;\n            event.subject.fy = event.subject.y;\n        }\n\n        function dragged(event) {\n            event.subject.fx = event.x;\n            event.subject.fy = event.y;\n        }\n\n        function dragended(event) {\n            if (!event.active) simulation.alphaTarget(0);\n            event.subject.fx = null;\n            event.subject.fy = null;\n        }\n\n        return d3\n            .drag()\n            .on(\"start\", dragstarted)\n            .on(\"drag\", dragged)\n            .on(\"end\", dragended);\n    }\n\n    return Object.assign(svg.node(), { scales: { color } });\n}"
  },
  {
    "objectID": "posts/2023-03-29-people-as-particles/index.html",
    "href": "posts/2023-03-29-people-as-particles/index.html",
    "title": "People as particles",
    "section": "",
    "text": "Manila is the densest city on Earth,1 fitting 1.8 million people into a 43 square-kilometer crucible. The 16 other cities that constitute Metro Manila, the Philippine capital, are extraordinarily crowded as well, resulting in an overall density of 22,000/km². This is twice that of New York and almost three times that of Singapore. Dysfunctional urban planning has failed to cope. Suburbs-style neighborhoods and private golf courses sprawl incongruously in city centers while open green spaces remain limited. The state of transportation is dystopian. A much needed subway intended for partial operability in 2022 only started construction last January.\nLiving in such a crowded place means shoving, squeezing, and cartwheeling your way through the chaos of gridlocked streets and packed trains, a daily collision of body against body that brings to mind Radiohead at their most anxious: “everyone is so near”. It’s an experience that isn’t quite captured by the metric “22,000/km²”. I wanted to make this number more evocative through a visualization, but how? I’ve seen population density plotted on bar charts, on choropleth maps, even on a 3D histogram, but none of these, I feel, do justice to the absolute pressure cooker that is Manila.\nI decided to try something novel. I call it a particles chart, and it consists of a D3 force simulation of balls bouncing off each other in a box. It’s relatively simple to construct — I am indebted to Vasco Asturiano’s modules in particular — yet it captures so effectively what “densest city on the planet” means. It means countless agitated bodies jockeying and jittering in a tight space, searching endlessly for room to breathe.2\nI’ve set the balls to generate at various sizes, reflecting the fact that some people take up more space than others. Think private vehicles versus public transport, detached homes versus high-rise condominiums. The balls are also colored in proportion to ethnic makeup, as recorded in Putterman and Weil’s World Migration Matrix. I’ve written about this dataset here and here, but to recap, the matrix breaks down a country’s population according to where their ancestors were in the year 1500. Migrant ancestor balls are colored by originating continent, ordered from largest to smallest shares.\nTo be clear, density is not inherently bad. In fact, density is indicative of a successful city since it means people want to move there. Density itself also confers benefits through agglomeration effects: proximity among firms and laborers brings down production costs and increases knowledge spillovers. But these benefits surely fall short of potential in Metro Manila. How great can proximity advantages be if it takes two hours to get anywhere? If there were an optimal level of density for a given level of infrastructure quality, Manila has blown way past it.\nThe particles chart can be used in any number of applications, with three levers (the number, colors, and sizes of the particles) available for mapping to variables. I’ll end this post with an additional example, this time tackling a different aspect of modern city living. It’s not a statistic, but a feeling. The kind that creeps up on you late at night under certain moods, when the veil lifts and you momentarily perceive the Camusian absurdity of all your life’s endeavors. A feeling best encapsulated, I think, by another song lyric:\nCode\n{\n    // Generate points\n    const widthFishbowl = width\n    const rFishbowl = widthFishbowl * .01\n    const vFishbowl = rFishbowl * .1\n    \n    const dummynodes = Array.from(\n        { length: 300 }, (_, i) =&gt; ({\n            x: d3.randomUniform((widthFishbowl * .05), (widthFishbowl * .95))(),\n            y: d3.randomUniform(height * .05, height * .95)(),\n            r: d3.randomNormal(rMean, rSD)(),\n            vx: d3.randomUniform(-1, 1)() * velocity,\n            vy: d3.randomUniform(-1, 1)() * velocity,\n            color: \"#eeeeee\"\n        })\n    );\n    \n    dummynodes.push(\n        { x: widthFishbowl * .05, y: height * .95, r: rFishbowl, vx: vFishbowl, vy: -vFishbowl, color: \"#4889ab\" },\n        { x: widthFishbowl * .95, y: height * .05, r: rFishbowl, vx: -vFishbowl, vy: vFishbowl, color: \"#C85B89\" }\n    );\n    \n    const nodes = dummynodes.map(Object.create);\n\n    // Panel\n    const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n\n    const svg = container.append(\"svg\")\n        .attr(\"width\", widthFishbowl)\n        .attr(\"height\", height)\n        .attr(\"viewBox\", [0, 0, widthFishbowl, height])\n        .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic\");\n\n    // Chart box\n    svg.append(\"rect\")\n        .attr(\"width\", widthFishbowl)\n        .attr(\"height\", height)\n        .attr(\"fill\", \"#f7f7f7\");\n\n    const node = svg.append(\"g\")\n        .selectAll(\"circle\")\n        .data(nodes)\n        .join(\"circle\")\n        .attr(\"cx\", d =&gt; d.x)\n        .attr(\"cy\", d =&gt; d.y)\n        .attr(\"r\", d =&gt; d.r)\n        .attr(\"fill\", (d) =&gt; d.color);\n    \n    // Define forces\n    const simulation = d3.forceSimulation(nodes)\n        .force(\"bounce\", d3.forceBounce()\n            .radius(d =&gt; d.r + .5))\n        .force(\"surface\", d3.forceSurface()\n            .surfaces(bbox([[0, 0], [widthFishbowl, height]]))\n            .oneWay(true)\n            .radius(d =&gt; d.r + 1))\n        .force('limit', d3.forceLimit()\n            .x0(0).x1(widthFishbowl).y0(0).y1(height))\n        .alphaDecay(0)\n        .velocityDecay(0)\n        .on(\"tick\", () =&gt; { node.attr(\"cx\", d =&gt; d.x).attr(\"cy\", d =&gt; d.y) });\n    \n    return container.node()\n}\nWe’re just two lost souls swimming in a fish bowlyear after year"
  },
  {
    "objectID": "posts/2023-03-29-people-as-particles/index.html#data-and-cleaning-script",
    "href": "posts/2023-03-29-people-as-particles/index.html#data-and-cleaning-script",
    "title": "People as particles",
    "section": "Data and cleaning script",
    "text": "Data and cleaning script\n\n\ndensity.csv\nparticles.R / group_assign.csv"
  },
  {
    "objectID": "posts/2023-03-29-people-as-particles/index.html#d3-observable-code",
    "href": "posts/2023-03-29-people-as-particles/index.html#d3-observable-code",
    "title": "People as particles",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\nd3 = require('d3@7', 'd3-force-bounce', 'd3-force-surface', 'd3-force-limit');\n\n// Import data\ndensity = FileAttachment('../../datasets/particles/density.csv').csv({ typed: true });\ndensityManila = density.filter(d =&gt; d.country === \"Philippines\");\ndensityOthers = density.filter(d =&gt; d.country !== \"Philippines\");\ngroupAssign = FileAttachment('../../datasets/particles/group_assign.csv').csv({ typed: true });\n\n// Parameters\nheight = width * .49;                // Height of particle chart\nrMean = (width * .49 / 40) / 2;      // Mean radius\nrSD = rMean * .75;                   // SD radius\nvelocity = rMean * .8;               // Particle velocity\n\ncolors = [\"#4889ab\", \"#7fc6a4\", \"#FCB13B\", \"#B13D70\", \"#f697bb\"];\n\ncolor = d3.scaleOrdinal()\n    .domain([1, 2, 3, 4, 5])\n    .range(colors);\n\nbbox = ([[x1, y1], [x2, y2]]) =&gt; [\n    { from: { x: x1, y: y1 }, to: { x: x1, y: y2 } },\n    { from: { x: x1, y: y2 }, to: { x: x2, y: y2 } },\n    { from: { x: x2, y: y2 }, to: { x: x2, y: y1 } },\n    { from: { x: x2, y: y1 }, to: { x: x1, y: y1 } }\n];\n\n// Function to generate particles for a given city\n\nfunction genpoints(city) {\n\n    const density = Math.round(city[0].density / 100);\n    \n    const groupAssignCity = groupAssign.filter(d =&gt; d.city === city[0].city);\n    const counts = groupAssignCity.map(row =&gt; row.points_ingroup);\n    const groups = [1, 2, 3, 4, 5];\n    const groupArray = counts.flatMap((count, i) =&gt;\n        Array.from({ length: count }, () =&gt; groups[i])\n    );\n    \n    const points = Array.from(\n        { length: density },\n        (_, i) =&gt; ({\n            x: d3.randomUniform((width * .49 * .15), (width * .49 * .85))(),\n            y: d3.randomUniform(height * .15, height * .85)(),\n            r: d3.randomNormal(rMean, rSD)(),\n            vx: d3.randomUniform(-1, 1)() * velocity,\n            vy: d3.randomUniform(-1, 1)() * velocity,\n            group: groupArray[i]\n        })\n    );\n\n    return points;\n}\n\n// Function to generate particles chart\n\nfunction particles(selection, city) {\n\n    // Read data\n    const nodes = genpoints(city).map(Object.create);\n\n    // Panel\n    const svg = selection.append(\"svg\")\n        .attr(\"width\", width * .49)\n        .attr(\"height\", height * 1.1)\n        .attr(\"viewBox\", [0, 0, width * .49, height * 1.1])\n        .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic\");\n\n    // Chart box\n    svg.append(\"rect\")\n        .attr(\"width\", width * .49)\n        .attr(\"height\", height)\n        .attr(\"fill\", \"#f7f7f7\")\n        .attr(\"stroke\", \"#bcbcbc\")\n        .attr(\"stroke-width\", 1);\n\n    // Bottom label\n    const densityStat = d3.format(\",.2r\")(city[0].density);\n    svg.append(\"text\")\n        .attr(\"id\", \"chart-text\")\n        .attr(\"x\", width * .49 / 2)\n        .attr(\"y\", height * 1.075)\n        .attr(\"text-anchor\", \"middle\")\n        .text(`${densityStat} people/km²`);\n\n    // Draw particles\n    const node = svg.append(\"g\")\n        .selectAll(\"circle\")\n        .data(nodes)\n        .join(\"circle\")\n        .attr(\"cx\", d =&gt; d.x)\n        .attr(\"cy\", d =&gt; d.y)\n        .attr(\"r\", d =&gt; d.r)\n        .attr(\"fill\", (d) =&gt; color(d.group));\n    \n    // Define forces\n    const simulation = d3.forceSimulation(nodes)\n        .force(\"bounce\", d3.forceBounce()\n            .radius(d =&gt; d.r + .5))\n        .force(\"surface\", d3.forceSurface()\n            .surfaces(bbox([[0, 0], [width * .49, height]]))\n            .oneWay(true)\n            .radius(d =&gt; d.r + 1))\n        .force('limit', d3.forceLimit()\n            .x0(0).x1(width * .49).y0(0).y1(height))\n        .alphaDecay(0)\n        .velocityDecay(0)\n        .on(\"tick\", () =&gt; { node.attr(\"cx\", d =&gt; d.x).attr(\"cy\", d =&gt; d.y) });\n}\n\n// Function to generate legend\n\nfunction legend(selection) {\n    \n    const legendWidth = 390;\n    const legendHeight = 34;\n    const rLegend = .5;\n    \n    const legendBox = selection.append(\"svg\")\n        .attr(\"width\", legendWidth)\n        .attr(\"height\", legendHeight)\n        .attr(\"viewBox\", [0, 0, legendWidth, legendHeight])\n        .attr(\"style\", \"max-width: 90%; height: auto; height: intrinsic;\");\n    \n    legendBox.append(\"circle\")\n        .attr(\"cx\", rLegend + \"rem\")\n        .attr(\"cy\", \".5rem\")\n        .attr(\"fill\", \"#4889ab\")\n        .attr(\"r\", rLegend + \"rem\");\n\n    legendBox.append(\"text\")\n        .attr(\"x\", (rLegend * 3) + \"rem\")\n        .attr(\"y\", \".85rem\")\n        .attr(\"text-anchor\", \"left\")\n        .text(\"Native ancestors\");\n\n    legendBox.append(\"g\")\n        .selectAll(\"circle\")\n        .data([1, 2, 3, 4])\n        .join(\"circle\")\n        .attr(\"cx\", d =&gt; (9 + rLegend + (d - 1) * rLegend * 3) + \"rem\")\n        .attr(\"cy\", \".5rem\")\n        .attr(\"fill\", d =&gt; color(d + 1))\n        .attr(\"r\", rLegend + \"rem\");\n\n    legendBox.append(\"text\")\n        .attr(\"x\", (9 + rLegend * 3 * 4) + \"rem\")\n        .attr(\"y\", \".85rem\")\n        .attr(\"text-anchor\", \"left\")\n        .text(\"Migrant ancestors\");\n}"
  },
  {
    "objectID": "posts/2023-03-29-people-as-particles/index.html#footnotes",
    "href": "posts/2023-03-29-people-as-particles/index.html#footnotes",
    "title": "People as particles",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOther sources may differ depending on how city boundaries are defined.↩︎\nCity density data were taken from Wikipedia. Comparisons are only suggestive given idiosyncrasies in how administrative boundaries are defined. For example, Metro Manila is 624 km², comparable to Jakarta (664 km²) and New York (778 km²) but not so much to Paris (105 km²) and Beijing (16,411 km²).↩︎"
  },
  {
    "objectID": "posts/2023-04-06-bikes/index.html",
    "href": "posts/2023-04-06-bikes/index.html",
    "title": "That’ll be ₱1 billion please",
    "section": "",
    "text": "The pandemic provoked a lot of experimentation in Philippine urban transport policy. Some were sensible, like rationalizing bus stops along EDSA. Some were, uh, destined to be hallmarks of the time. One of the more forward-thinking was the elevation of bicycles as a bona fide mode of transport. What’s not to love: they take little road space, they’re cheap, they’re green, and they keep you fit.1 Biking infrastructure is an actionable investment while waiting for the big-ticket rail projects to crawl towards completion.\nFunding for the construction of bike lanes in Metro Manila, Metro Cebu, and Metro Davao was included in the pandemic recovery bill. The transportation and public works departments, tasked with implementation, received technical assistance from the World Bank and the Netherlands Embassy to ensure a “Safe System approach” and “Dutch Cycling Infrastructure principles”. Contracts were drawn up and opened to the private sector for bidding. By June 2021, almost 500 kilometers of bike lanes were completed at the cost of over ₱1 billion ($19.6 million), or about ₱2.1 million ($40,000) per kilometer.\nWell. Here’s what the lane closest to where I live looks like:\nIt’s a little underwhelming? No bollards, no buffers, just some hard-to-see paint on the ground and a dash of prayer. Granted, there are sections that are less brutalist, but this is not unrepresentative either.\nAs a tax-funded project, it’s worthwhile to look closely into the procurement process that resulted in these bike lanes. This is exactly the subject of an illuminating paper from WeSolve Foundation, published last week. They’ve made their dataset available, and in this post, I’d like to visualize some of its more interesting aspects. The authors attach a disclaimer that their findings “cannot and should not be used to conclude fraud or corruption”, and indeed, the work was made in partnership with the Philippine Government Electronic Procurement System, who provided some data. I do believe that an imperfect system need not necessarily imply deliberate wrongdoing, so the same disclaimer applies in this post.\nLet’s load up the dataset in R.\nlibrary(tidyverse)\nlibrary(here)\nlibrary(readxl)\n\nfile &lt;- \"[PUBLIC DATASET] Empowering Citizens to Build Better Bike Lanes through Open Contracting.xlsx\"\n\ncontract &lt;- here(\"datasets\", \"bikelanes\", file) %&gt;% read_excel(sheet = \"contract\", skip = 1)\nitem &lt;- here(\"datasets\", \"bikelanes\", file) %&gt;% read_excel(sheet = \"item\")\nbidder &lt;- here(\"datasets\", \"bikelanes\", file) %&gt;% read_excel(sheet = \"bidder\")\nThe following table contains key information on the 12 contracts the study covered. There are 10 in Metro Manila and one each in Cebu and Davao. The contract advertising date (date_ad), the notice-to-proceed date (date_ntp), the winning bidder (noa_supplier), and the approved final value (noa_award_value) are given for each contract.\nCode\nlibrary(reactable)\n\ncontract %&gt;%\n  select(contract_no, contract_title, contract_location, proc_entity, date_ad, date_ntp, noa_supplier, noa_award_value) %&gt;% \n  reactable(\n    defaultColDef = colDef(\n      minWidth = 125,\n      align = \"left\",\n      headerStyle = list(fontFamily = \"Karla\", background = \"#f7f7f8\"),\n    ),\n    columns = list(\n      contract_title = colDef(minWidth = 350),\n      contract_location = colDef(minWidth = 175),\n      proc_entity = colDef(minWidth = 175),\n      date_ad = colDef(align = \"center\", cell = function(x) format(x, \"%Y-%m-%d\")),\n      date_ntp = colDef(align = \"center\", cell = function(x) format(x, \"%Y-%m-%d\")),\n      noa_supplier = colDef(minWidth = 225),\n      noa_award_value = colDef(minWidth = 150, align = \"right\", format = colFormat(prefix = \"₱\", separators = TRUE, digits = 0))\n    ),\n    defaultPageSize = 4,\n    bordered = TRUE,\n    highlight = TRUE\n  )\nLet’s start by visualizing where these bike lanes are located. The dataset does not actually have information on routes, so I’ve had to infer them from the contract title, the stipulated length, and my educated guesses. I drew the routes on Google My Maps and exported them as a KML file, which I then uploaded on mapshaper to consolidate the features and convert to topoJSON format. Because this took a bit of work, I’m focusing here only on the Metro Manila contracts. One of the contracts (20O0096) has an uninformative title so I was unable to draw it, leaving me with nine routes in all. For the administrative boundaries of Metro Manila and surrounding areas, I used the topoJSON files of James Faeldon.\nThe network is certainly comprehensive, covering most major roads in the metro. These do not yet include bike lanes built by local government units, which traverse secondary roads. On paper at least, cycling infrastructure in Metro Manila has become fairly well-connected. But things are not so rosy on the ground. As shown in the picture above, these lanes are often unprotected for long stretches, even in major highways. Fatal accidents are frequent. And without the vigilance of activists, there is a tendency for car-centric policies to creep back in.\nYou may notice that several of the contracts were won by one company, Philippine Chemsteel Industries. The idea of a public bidding is meant to ensure transparency and competitiveness in government procurement. Following economic theory, the presence of many sellers helps drive prices down to marginal cost. The fact that one company seems to have dominated these bids hints at the possible breakdown of this assumption. We can check this by visualizing WeSolve’s data in a network chart.\nbidders &lt;- bidder %&gt;% \n  filter(!is.na(total_calc_bid)) %&gt;% \n  select(contract_no, bidder_name, total_calc_bid, flag_lcb)\n\nnodes &lt;- c(unique(bidders$bidder_name), unique(bidders$contract_no))\nbiddersNodes &lt;- tibble(\n  id = 1:length(nodes),\n  name = nodes,\n  type = case_when(\n    str_detect(name, \"20\") ~ \"contract\",\n    TRUE ~ \"bidder\"\n  ))\n\nbiddersLinks &lt;- bidders %&gt;% \n  left_join(biddersNodes, by = c(\"contract_no\" = \"name\")) %&gt;% \n  left_join(biddersNodes, by = c(\"bidder_name\" = \"name\")) %&gt;% \n  select(source = id.y, target = id.x, bid = total_calc_bid, win = flag_lcb)\n\n# Correction\nbiddersLinks$source[biddersLinks$target == 18] &lt;- c(1, 6, 5)\nbiddersLinks$source[biddersLinks$target == 20] &lt;- c(1, 5)\nDisqualified bids (due to, for example, incomplete requirements) are excluded. I am also correcting what looks like an encoding error in the WeSolve dataset where Philippine Chemsteel Industries and Newbig Four J Construction were switched by mistake. The official documents confirm that it was Philippine Chemsteel, not Newbig, who won in the two contracts they competed in.\nSeven of the 11 contracts with bidders data2 had more than one valid bid, which, by WeSolve’s reckoning, saved the government an average of 1.6%. It’s not exactly a blockbuster amount, and looking at the network, it’s pretty clear why. Adam Smith’s marketplace this is not. The ten Metro Manila contracts received just 1-3 bidders each; Philippine Chemsteel won all six contracts for which it submitted a bid. The Metro Davao contract was the most competitive at four bidders, though the winning bid was a mere 0.1% less than the budgeted amount.\nWhat exactly did these companies spend on? Luckily, the WeSolve dataset also contains item-level price and quantity information for each winning bid. Let’s prep these for charting on a stacked bar plot.\nitems &lt;- item %&gt;% \n  select(contract_no, item_description, item_amt) %&gt;% \n  group_by(contract_no) %&gt;% \n  arrange(desc(item_amt), .by_group = TRUE) %&gt;% \n  mutate(\n    rank = 1:n(),\n    item = case_when(\n      rank &lt;= 9 ~ item_description,\n      TRUE ~ \"Others\"\n    )) %&gt;% \n  group_by(contract_no, item) %&gt;% \n  summarize(\n    value = sum(item_amt),\n    rank = sum(rank)\n  ) %&gt;% \n  mutate(value_norm = value / sum(value)) %&gt;% \n  arrange(rank, .by_group = TRUE) %&gt;% \n  mutate(rank = 1:n()) %&gt;% \n  ungroup()\n\nitemsWide &lt;- items %&gt;% \n  select(contract_no, rank, value_norm) %&gt;% \n  pivot_wider(names_from = rank, values_from = value_norm)\n\nitemsDesc &lt;- items %&gt;% \n  select(contract_no, rank, item, value, value_norm)\nTo keep the chart manageable, I’m only identifying the nine biggest items in each contract, with the rest aggregated into an “others” category. Those steeped in the philosophy of tidy data might be wondering what sort of abomination am I trying to create with itemsWide. This step is necessary because making stacked bar charts in D3 requires data in wide format.\nAmong the largest components are solar pavement markers, “reflectorized thermoplastic pavement markings” (read: paint), and an assortment of road signs. Here and there are provisions for constructing bicycle racks, though I don’t think I’ve ever seen one in the wild. It’s clear from these line items that the plan had always been to build bike lanes of the most basic sort: painted strips that awkwardly take up two-thirds of the rightmost car lane.\nWith this bike lane building program, the government has seemingly spent ₱1 billion to make everyone unhappy — cyclists because they find the lanes inadequate, motorists because they resent the intrusion into their space. But that’s fine! It’s a start! There are bike lanes now where there weren’t before. Making cycling a truly viable mode of transport will take several more billions yet. And in those future rounds of procurement, I hope that the government commits to improving its policy of transparency. The WeSolve paper notes several gaps in officially available data; even the very routes these contracts covered, I was frustrated to learn, are nowhere to be found. Let the data flow free! Don’t you know I love nothing more than learning how much fancy paint my taxes were able to buy?"
  },
  {
    "objectID": "posts/2023-04-06-bikes/index.html#data",
    "href": "posts/2023-04-06-bikes/index.html#data",
    "title": "That’ll be ₱1 billion please",
    "section": "Data",
    "text": "Data\n\n\nEmpowering Citizens to Build Better Bike Lanes through Open Contracting.xlsx\nphilippine-json-maps (source: faeldon/philippines-json-maps)\ncontracts.csv, contractsMap.json, biddersNodes.csv, biddersLinks.csv, itemsWide.csv, itemsDesc.csv"
  },
  {
    "objectID": "posts/2023-04-06-bikes/index.html#d3-observable-code",
    "href": "posts/2023-04-06-bikes/index.html#d3-observable-code",
    "title": "That’ll be ₱1 billion please",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\nd3 = require(\"d3@7\", \"d3-force-limit\");\n\n// Data\nncr1339 = FileAttachment(\"../../datasets/philippines-json-maps/municities-province-ph133900000.topo.0.1.json\").json();\nncr1374 = FileAttachment(\"../../datasets/philippines-json-maps/municities-province-ph137400000.topo.0.1.json\").json();\nncr1375 = FileAttachment(\"../../datasets/philippines-json-maps/municities-province-ph137500000.topo.0.1.json\").json();\nncr1376 = FileAttachment(\"../../datasets/philippines-json-maps/municities-province-ph137600000.topo.0.1.json\").json();\ncentralLuzon = FileAttachment(\"../../datasets/philippines-json-maps/provinces-region-ph030000000.topo.0.1.json\").json();\ncalabarzon = FileAttachment(\"../../datasets/philippines-json-maps/provinces-region-ph040000000.topo.0.1.json\").json();\n\nncrFeatures = {\n  const ncr1339Feature = topojson.feature(ncr1339, ncr1339[\"objects\"][\"municities-province-ph133900000.0.1\"]).features\n  const ncr1374Feature = topojson.feature(ncr1374, ncr1374[\"objects\"][\"municities-province-ph137400000.0.1\"]).features\n  const ncr1375Feature = topojson.feature(ncr1375, ncr1375[\"objects\"][\"municities-province-ph137500000.0.1\"]).features\n  const ncr1376Feature = topojson.feature(ncr1376, ncr1376[\"objects\"][\"municities-province-ph137600000.0.1\"]).features\n  return [...ncr1339Feature, ...ncr1374Feature, ...ncr1375Feature, ...ncr1376Feature];\n}\n\nbgFeatures = {\n  const r3Features = topojson.feature(centralLuzon, centralLuzon[\"objects\"][\"provinces-region-ph030000000.0.1\"]).features\n  const r4AFeatures = topojson.feature(calabarzon, calabarzon[\"objects\"][\"provinces-region-ph040000000.0.1\"]).features\n  return [...r3Features, ...r4AFeatures];\n}\n\ncontractsMap = FileAttachment(\"../../datasets/bikelanes/contractsMap.json\").json();\ncontractsFeatures = topojson.feature(contractsMap, contractsMap.objects.contractsMap).features;\ncontractNames = d3.map(contractsFeatures, d =&gt; d.properties.contract).sort();\ncontractsDF = FileAttachment(\"../../datasets/bikelanes/contracts.csv\").csv({ typed: true });\ncontractDetails = contractsDF.filter(d =&gt; contractNames.includes(d.contract_no));\n\nbiddersNodes = FileAttachment(\"../../datasets/bikelanes/biddersNodes.csv\").csv({ typed: true });\nbiddersLinks = FileAttachment(\"../../datasets/bikelanes/biddersLinks.csv\").csv({ typed: true });\n\nitemsWide = FileAttachment(\"../../datasets/bikelanes/itemsWide.csv\").csv({ typed: true });\nitemsDesc = FileAttachment(\"../../datasets/bikelanes/itemsDesc.csv\").csv({ typed: true });\n\n// Drag function\n// Source: https://observablehq.com/@d3/mobile-patent-suits\n\ndrag = simulation =&gt; {\n  \n  function dragstarted(event, d) {\n    if (!event.active) simulation.alphaTarget(0.3).restart();\n    d.fx = d.x;\n    d.fy = d.y;\n  }\n  \n  function dragged(event, d) {\n    d.fx = event.x;\n    d.fy = event.y;\n  }\n  \n  function dragended(event, d) {\n    if (!event.active) simulation.alphaTarget(0);\n    d.fx = null;\n    d.fy = null;\n  }\n  \n  return d3.drag()\n    .on(\"start\", dragstarted)\n    .on(\"drag\", dragged)\n    .on(\"end\", dragended);\n}"
  },
  {
    "objectID": "posts/2023-04-06-bikes/index.html#footnotes",
    "href": "posts/2023-04-06-bikes/index.html#footnotes",
    "title": "That’ll be ₱1 billion please",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSo I’ve heard. I don’t actually know how to ride a bike.↩︎\nThe one contract without bidders data was for Metro Cebu.↩︎"
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html",
    "href": "posts/2023-04-14-learning-curves/index.html",
    "title": "Learning curves",
    "section": "",
    "text": "Economics is a strange field, a social science with pretensions of a natural science that manages to annoy both. I have been its student and its teacher and I can tell you that it’s weird inside and out. Many a night have I spent working through the mathematics of a world where people are immortal and shops sell 0.000001 of anything. Yet for all its peculiarities, I do think everyone can profit from a little economic knowledge. Economics, to me, is about clarifying trade-offs given a set of goals and rules over how the world works. Notice that this definition doesn’t actually include the economy (over which economics courses dwell astonishingly little!) but focuses rather on an economic way of thinking. Econ 101 may not teach you much about stocks, taxes, or running a business, but it does train you to tackle problems methodically, systematically.\nAnyone who’s taken an undergraduate economics course knows that the subject is taught mainly through charts. From my experience, these are both the boon and bane of the would-be student. Charts are great — we here at Two Points Make a Line are big fans — but working through them can be challenging. The problem is that students typically see charts as frozen images, whereas their power is in visualizing the interrelations among variables in a dynamic sense. Whenever charts are discussed, there is always talk of moving along the curve, or shifting the curve, or pivoting the curve. Students are expected to hallucinate movement where there is none.\nTake this cost curve diagram from Hal Varian’s popular microeconomics textbook.\nNevermind for now what it means; suppose I simply asked you to imagine how the shaded rectangle would change if you moved \\(p^*\\) down, moved \\(y^*\\) to the left, and shifted the AC curve up. Too easy? Now reverse that and compare the two pictures. Such exercises quickly become a headache. And this neat textbook chart is the best-case scenario too: many have to make do with the hand-drawn, Basquiat-looking diagrams their professors etch on the blackboard.\nGiven that more and more students are consuming their learning materials digitally, it is opportune to embrace interactivity in economics diagrams. By this I mean charts that the student can actually manipulate in a guided setting, shifting mental resources away from hallucinating movement and towards understanding the concepts conveyed. This blog post serves as something of a proof-of-concept for how an interactive module can be done. I’ll be covering cost curves, one of the major stumbling blocks in an Econ 101 course."
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#firm-foundations",
    "href": "posts/2023-04-14-learning-curves/index.html#firm-foundations",
    "title": "Learning curves",
    "section": "Firm foundations",
    "text": "Firm foundations\nEconomists model the economy as having two types of entities: households and firms. Households maximize their utility by buying goods and services from firms, with money they earn by working for firms. Firms maximize profits by buying inputs from households, turning them into goods and services, and then selling them back to households.\nLet’s zoom in on a firm in a particular market. Its behavior proceeds in two steps. First, it looks at its technological capabilities and decides on the best (i.e. cheapest) mix of inputs to purchase for every possible level of output. This results in a cost function \\(C(q)\\), which gives the costs associated with producting \\(q\\) units of output. Armed with this, it moves on to the second step, where it decides on the level of output that maximizes its profits.\nWe’ll skip the first step here and assume the firm has already derived its cost function. It would typically be something of the following form:\n\\[\n\\text{Cost}(q, \\text{FixedCosts}) = aq^3 - bq^2 + cq + \\text{FixedCosts}\n\\]\nYou don’t have to worry so much about the math, but pay attention to the fact that total cost is composed of a fixed cost (does not change with \\(q\\)) and a variable cost (varies with \\(q\\)). This cost function is plotted below.\n\n\nCode\nviewof q0 = Inputs.range([0, qMax], { label: \"Output\", step: 1, value: 50 })\nviewof fc0 = Inputs.range([0, fcMax], { label: \"Fixed cost\", step: 1, value: 250 })\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q0;\n  params.fc = fc0;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitles = ({ x: \"Output\", y: \"$\" });\n  \n  const yScaler = d3.scaleLinear()\n    .domain([0, costFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n        \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", panelHeight + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, panelHeight + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  const panel = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panel.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, cost, params, yScaler)\n    .call(yGuide, cost, params, yScaler);\n  \n  panel.append(\"g\")\n    .call(panelAxes, axisTitles)\n    .call(xGuides, cost, params, yScaler, 1);\n  \n  panel.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Cost\", xScaler(85) + 10, yScaler(costFxn({ q: 85, fc: params.fc })) + 10);\n   \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\nhtml`&lt;div class=\"ojs-caption\"&gt;The checkbox at the corner toggles whether labels are visible, a feature that will be useful later as our charts get more crowded. You can always hover over a curve to see its name.&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that the cost curve has a vague S shape. This captures the idea that at a small enough scale, costs don’t rise all that quickly with output. Imagine you started a food truck business. Your initial outlays for the truck, the stove, the ingredients, and so on will comprise the bulk of your total costs, and any extra burger, taco, or kebab you produce won’t raise this by a lot. As you expand however, you start hitting the limits of your capacity and each extra unit of output becomes more and more expensive to produce. Thus we see the cost curve growing steeper and steeper.\nPlay around with the sliders to see how changing output and fixed costs changes the chart. Observe that as long as there are fixed costs, we can never bring total costs down to zero, even with zero output. Also observe that raising fixed costs shifts the whole curve up, so that costs are higher for all levels of output. In the long run, fixed costs approach zero since all inputs can be varied given a long enough time frame.\nOur goal as the firm is to figure out what the optimal level of output is from a profit-maximizing standpoint. To do this, we’ll need to look at things from a per unit perspective. The charts below introduce three useful curves: the average cost curve, the average variable cost curve, and the marginal cost curve.\n\n\nCode\nviewof q1 = Inputs.range([0, qMax], { label: \"Output\", step: 1, value: 50 })\nviewof fc1 = Inputs.range([0, fcMax], { label: \"Fixed cost\", step: 1, value: 250 })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAverage costAverage variable costMarginal cost\n\n\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q1;\n  params.fc = fc1;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([0, costFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n        \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, cost, params, yScalerTop)\n    .call(yGuide, cost, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxes, axisTitlesTop)\n    .call(xGuides, cost, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Cost\", xScaler(85) + 10, yScalerTop(costFxn({ q: 85, fc: params.fc })) + 10);\n    \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurve, id, ac, params, yScalerBottom)\n    \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, ac, params, yScalerBottom);\n  \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom);\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\");\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`);\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q1;\n  params.fc = fc1;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([0, costFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n        \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n    \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, cost, params, yScalerTop)\n    .call(yGuide, cost, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxes, axisTitlesTop)\n    .call(xGuides, cost, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Cost\", xScaler(85) + 10, yScalerTop(costFxn({ q: 85, fc: params.fc })) + 10);\n    \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, ac, params, yScalerBottom, gray)\n    .call(addCurve, id, avc, params, yScalerBottom)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, avc, params, yScalerBottom);\n  \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom);\n    \n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"AVC\", xScaler(95) + 10, yScalerBottom(avcFxn({ q: 95 })) + 10);\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`);\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q1;\n  params.fc = fc1;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([0, costFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n        \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n    \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, cost, params, yScalerTop)\n    .call(yGuide, cost, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxes, axisTitlesTop)\n    .call(xGuides, cost, params, yScalerTop);\n    \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Cost\", xScaler(85) + 10, yScalerTop(costFxn({ q: 85, fc: params.fc })) + 10);\n    \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, ac, params, yScalerBottom, gray)\n    .call(addCurveFull, id, avc, params, yScalerBottom, gray)\n    .call(addCurve, id, mc, params, yScalerBottom)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, mc, params, yScalerBottom);\n  \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom);\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"AVC\", xScaler(95) + 10, yScalerBottom(avcFxn({ q: 95 })) + 10)\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10);\n    \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`);\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\nThe average cost or AC curve simply plots total costs divided by output. It is U-shaped, shooting up at both very low and very high output levels. In fact, in the presence of fixed costs, AC goes to infinity as output approaches zero. Notice that this no longer happens if we set fixed costs to zero.\nThe second panel plots the average variable cost or AVC curve. This is just the AC curve minus the fixed costs component. The AVC curve is also U-shaped, but it doesn’t shoot to infinity when output is zero. As output gets larger and larger, the share of fixed costs in total costs gets smaller and smaller; thus we see the AC and AVC curves converging. Setting fixed costs to zero merges the AC and AVC curves, which is to say, the AC and AVC curves are only distinct quantities in the short run.\nThe marginal cost or MC curve is on the third panel. Of the three, it is probably the trickiest to grasp, but as marginalist reasoning abounds in economics, it’s worthwhile to really think it through. The MC curve plots the incremental change in total cost given one additional unit of output. It is not an average quantity. It is also U-shaped, but it is a much thinner U than either AC or AVC. This is because it tracks incremental change and is not bogged down by the running tally of costs like AC and AVC are. The slope of the MC curve goes from downward to upward at the precise moment the total cost curve turns from flattening to steepening.\nHere’s a useful tip: every time two curves intersect in economics, make note of it. More often than not, something special is happening. In this case, notice how the MC curve crosses AVC and AC at the point when they are at their minimum. In other words, the intersection with MC marks the point where they go from downward-sloping to upward-sloping. That is no coincidence. The reason is that as long as MC is below AC/AVC, then the incremental change in costs is lower than the running average, which pulls the average down. Conversely, if MC is above AC/AVC, then it is pulling the average up. By analogy, suppose your average grade from three exams is 80. If your fourth exam is lower than 80, then it will pull your average down, but if it is higher than 80, it will pull your average up. The same principle is at work in our cost curves."
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#deriving-the-supply-curve",
    "href": "posts/2023-04-14-learning-curves/index.html#deriving-the-supply-curve",
    "title": "Learning curves",
    "section": "Deriving the supply curve",
    "text": "Deriving the supply curve\nWith a good understanding of AC, AVC, and MC, let’s move on to how they’re used to get the firm’s optimal output level. We will be assuming that the market is perfectly competitive, which means that the firm is a price-taker. Later we will explore what happens when this assumption breaks down. For now, let’s say the price the firm is facing is $17. Profits are computed straightforwardly as revenues (price times quantity) minus costs; in the per unit panel, this is represented by the shaded rectangle. Move the output slider around until you find the profit-maximizing level.\n\n\nCode\nviewof q2 = Inputs.range([0, qMax], {label: \"Output\", step: 1, value: 50})\nviewof fc2 = Inputs.range([0, fcMax], {label: \"Fixed cost\", step: 1, value: 250, disabled: true})\nviewof p2 = Inputs.range([0, pMax], {label: \"Price\", step: .1, value: 17, disabled: true})\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q2;\n  params.fc = fc2;\n  params.p = p2;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-800, 800])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n\n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profit, params, yScalerTop)\n    .call(yGuide, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitFxn({ q: 70, p: params.p, fc: params.fc })) - 10);\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profit, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurve, id, avc, params, yScalerBottom)\n    .call(addCurve, id, mc, params, yScalerBottom)\n    .call(addCurve, id, ac, params, yScalerBottom)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, price, params, yScalerBottom)\n    .call(addCurveFull, id, price, params, yScalerBottom)\n    .call(yGuide, ac, params, yScalerBottom);\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"AVC\", xScaler(95) + 10, yScalerBottom(avcFxn({ q: 95 })) + 10)\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10);\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see that an output of about 59 units maximizes profits.1 Notice anything interesting? This level of \\(q\\) just so happens to be the point where the price line intersects the MC curve!  This is a key insight in economics. It says that at the optimum, the last additional unit of output you produce should yield you as much revenue as the costs it incurs. This is best understood by considering the alternatives. If we’ve chosen an output level such that MC is below price, then producing one more unit should give us more revenue than costs, and thus increase our profits. Conversely, if MC is above price, then cutting back production by one unit reduces costs more than it reduces revenues, which again increases profits. The state of optimality is reached when price is equal to MC, or, stated more generally, when marginal revenue is equal to marginal costs.\nWell, a small caveat: notice that the price line actually intersects MC on two points, first in its downward-sloping region and second in its upward-sloping region. Setting output where price crosses MC at its downward-sloping region actually minimizes profits. Naturally, if MC is below price and is falling, then we’d want to keep expanding output. Let’s clarify then that the optimal output level is where price meets the MC curve in its upward-sloping region.\nDoes our rule still work when the price is so low that profits are negative no matter what output level we choose? Let’s investigate. The chart below sets the price at $10.\n\n\nCode\nviewof q3 = Inputs.range([0, qMax], {label: \"Output\", step: 1, value: 50})\nviewof fc3 = Inputs.range([0, fcMax], {label: \"Fixed cost\", step: 1, value: 250, disabled: true })\nviewof p3 = Inputs.range([0, pMax], {label: \"Price\", step: .1, value: 10, disabled: true })\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q3;\n  params.p = p3;\n  params.fc = fc3;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-800, 800])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n\n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profit, params, yScalerTop)\n    .call(yGuide, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitFxn({ q: 70, p: params.p, fc: params.fc })) - 10);\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profit, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, avc, params, yScalerBottom, gray)\n    .call(addCurveFull, id, ac, params, yScalerBottom, gray)\n    .call(addCurve, id, mc, params, yScalerBottom)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, mr, params, yScalerBottom)\n    .call(addCurveFull, id, mr, params, yScalerBottom)\n    .call(yGuide, ac, params, yScalerBottom);\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"AVC\", xScaler(95) + 10, yScalerBottom(avcFxn({ q: 95 })) + 10)\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10);\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis time, the \\(MR=MC\\) condition gives us an output level of about 51 and profits of –$99. If my profits are going to be negative, why don’t I just produce zero and call it a day? Well, if you tried to set \\(q=0\\), you’ll see that it yields profits of –$250, which is more negative than at the optimal level. The number 250, of course, is our fixed costs, and the insight here is that since we have to pay for fixed costs anyway, it’s better to produce something rather than nothing, even if we never do earn positive profits.\nThe price can be so low, however, that it does make more sense to quit production altogether. As an exercise, use the chart below to try and find prices for which the optimal output level is zero. Formulate a rule for what these prices must be.\n\n\nCode\nviewof q4 = Inputs.range([0, qMax], {label: \"Output\", step: 1, value: 50 })\nviewof fc4 = Inputs.range([0, fcMax], {label: \"Fixed cost\", step: 1, value: 250, disabled: true })\nviewof p4 = Inputs.range([0, pMax], {label: \"Price\", step: .1, value: 15 })\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q4;\n  params.p = p4;\n  params.fc = fc4;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-800, 800])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profit, params, yScalerTop)\n    .call(yGuide, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitFxn({ q: 70, p: params.p, fc: params.fc })) - 10);\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profit, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, avc, params, yScalerBottom, gray)\n    .call(addCurveFull, id, ac, params, yScalerBottom, gray)\n    .call(addCurve, id, mc, params, yScalerBottom)\n    \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, mr, params, yScalerBottom)\n    .call(addCurveFull, id, mr, params, yScalerBottom)\n    .call(yGuide, ac, params, yScalerBottom);\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"AVC\", xScaler(95) + 10, yScalerBottom(avcFxn({ q: 95 })) + 10)\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10);\n  \n  // Shutdown point\n  panelBottom.append(\"g\")\n    .append(\"circle\")\n    .attr(\"cx\", xScaler(36))\n    .attr(\"cy\", yScalerBottom(mcFxn({ q: 36 })))\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe rule is that any price below the AVC curve makes zero output optimal. In these cases, each unit of output you produce cannot even pay for itself, much less your fixed costs. It is better for you to shut your business down; the point where MC and AVC intersect is known as the shutdown point.\nTo recap what we have established:\n\nGiven a price, the firm will choose the output level that corresponds to where the price line intersects with the upward-sloping region of the MC curve.\nNegative profits can still be optimal if the price is enough to pay for average variable costs.\nThe firm will not produce anything for any price below the AVC curve.\n\nThese conditions trace out our firm’s supply curve, which gives its optimal output decision for every conceivable price level. In the chart below, move the price slider around to see how output changes. You can also vary fixed costs to see how this does not affect the firm’s decision, though it does affect realized profits.\n\n\nCode\nviewof p5 = Inputs.range([0, pMax], {label: \"Price\", step: .1, value: 15 })\nviewof fc5 = Inputs.range([0, fcMax], {label: \"Fixed cost\", step: 1, value: 250 })\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.p = p5;\n  params.fc = fc5;\n  \n  const qShutDown = Math.floor(.56 / (.006 * 2));\n  const q = (p) =&gt; {\n    if (p &lt; avcFxn({ q: qShutDown })) return 0;\n    else return Math.floor((1.12 + Math.pow(.072 * p - .1856, .5)) / .036);\n  };\n  \n  params.q = q(p5);\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-800, 800])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profit, params, yScalerTop)\n    .call(yGuide, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitFxn({ q: 70, p: params.p, fc: params.fc })) - 10);\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profit, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, avc, params, yScalerBottom, gray)\n    .call(addCurveFull, id, ac, params, yScalerBottom, gray)\n    .call(addCurveFull, id, mc, params, yScalerBottom, gray)\n  \n   panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, mr, params, yScalerBottom)\n    .call(addCurveFull, id, mr, params, yScalerBottom)\n    .call(addCurve, id, supply, params, yScalerBottom)\n    .call(yGuide, ac, params, yScalerBottom)\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n  \n  // Vertical portion of supply curve\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `${supply.id}-${id}`)\n    .attr(\"pointer-events\", \"visibleStroke\")\n    .call(clipWide, id)\n    .append(\"path\")\n    .attr(\"class\", \"curve colored\")\n    .attr(\"d\", line([[0, panelHeight], [0, yScalerBottom(avcFxn({ q: qShutDown }))], [1, yScalerBottom(avcFxn({ q: qShutDown }))]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", blue.base)\n    .style(\"stroke-width\", strokeWidth)\n    .on(\"mousemove\", (event) =&gt; {\n      d3.selectAll(`#${supply.id}-${id} .curve`)\n        .transition().duration(50)\n        .style(\"stroke-width\", strokeWidth + 2)\n        .style(\"stroke\", supply.scheme.baseSelect);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(supply.label);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", (event) =&gt; {\n      d3.selectAll(`#${supply.id}-${id} .curve`)\n        .transition().duration(100)\n        .style(\"stroke-width\", strokeWidth)\n        .style(\"stroke\", supply.scheme.base);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"AVC\", xScaler(95) + 10, yScalerBottom(avcFxn({ q: 95 })) + 10)\n    .call(addLabel, \"Supply\", xScaler(69) + 5, yScalerBottom(mcFxn({ q: 69 })) - 25, \"middle\");\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the long run, fixed costs reach zero and the AC and AVC curves converge. This would imply that profits cannot be negative in the long run — firms are either participating in the market with positive profits or else have shut down their business (use the chart above to verify). This actually extends to a broader and more surprising prediction: in the long run, profits can neither be positive nor negative. They must always be zero!"
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#in-the-room-the-firms-come-and-go",
    "href": "posts/2023-04-14-learning-curves/index.html#in-the-room-the-firms-come-and-go",
    "title": "Learning curves",
    "section": "In the room the firms come and go",
    "text": "In the room the firms come and go\nThis prediction stems from the assumption that without the hindrance of fixed costs, firms can freely enter and exit the market. Any market where participating firms are enjoying positive profits will attract the entry of more firms, which increases supply and drives down the price. Firms will keep entering until it makes no more economic sense to do so, which is the point when prevailing profits have reached zero. Likewise, firms will exit markets where profits are negative, reducing supply and raising prices until profits are brought to zero. The chart below depicts the long-run equilibrium for a firm in our perfectly competitive market.\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  const qShutDown = Math.floor(.56 / (.006 * 2));\n  params.p = 6.9;\n  params.fc = 0;\n  params.q = 46;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-800, 800])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profit, params, yScalerTop)\n\n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profit, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitFxn({ q: 70, p: params.p, fc: params.fc })) - 10);\n\n  panelTop.append(\"g\")\n    .append(\"text\")\n    .text(0)\n    .attr(\"x\", 0)\n    .attr(\"y\", data(profit.fxn, params, yScalerTop)[params.q][1])\n    .attr(\"dx\", -10)\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\");\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profit, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, ac, params, yScalerBottom, gray)\n    .call(addCurveFull, id, mc, params, yScalerBottom, gray)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, mr, params, yScalerBottom)\n    .call(addCurveFull, id, mr, params, yScalerBottom)\n    .call(addCurve, id, supply, params, yScalerBottom)\n\n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n  \n  // Vertical portion of supply curve\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `${supply.id}-${id}`)\n    .attr(\"pointer-events\", \"visibleStroke\")\n    .call(clipWide, id)\n    .append(\"path\")\n    .attr(\"class\", \"curve colored\")\n    .attr(\"d\", line([[0, panelHeight], [0, yScalerBottom(avcFxn({ q: qShutDown }))], [1, yScalerBottom(avcFxn({ q: qShutDown }))]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", blue.base)\n    .style(\"stroke-width\", strokeWidth)\n    .on(\"mousemove\", (event) =&gt; {\n      d3.selectAll(`#${supply.id}-${id} .curve`)\n        .transition().duration(50)\n        .style(\"stroke-width\", strokeWidth + 2)\n        .style(\"stroke\", supply.scheme.baseSelect);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(supply.label);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", (event) =&gt; {\n      d3.selectAll(`#${supply.id}-${id} .curve`)\n        .transition().duration(100)\n        .style(\"stroke-width\", strokeWidth)\n        .style(\"stroke\", supply.scheme.base);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"Supply\", xScaler(69) + 5, yScalerBottom(mcFxn({ q: 69 })) - 25, \"middle\");\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\nIt’s important to clarify a couple of things with regard to interpretation. “Costs” here are understood broadly, meaning they include the wages that businessowners pay to themselves. It’s better to think of “zero” profits in a normalized sense, as in firms are not making any outsized profits relative to what firms on average can make.\nSecond, this result only applies to perfectly competitive markets, which are idealized scenarios that do not describe anything found in reality. The key assumption here is that firms are numerous enough and small enough that their actions have no influence on prevailing prices. But this seldom holds. Let’s now turn to the opposite extreme, the case where the market is dominated by just a single seller."
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#the-only-game-in-town",
    "href": "posts/2023-04-14-learning-curves/index.html#the-only-game-in-town",
    "title": "Learning curves",
    "section": "The only game in town",
    "text": "The only game in town\nFacing no competitors, a monopoly exercises full control over its price. Of course, this doesn’t mean it can force people to buy its product, so there’s still an optimality decision to be made. Given its cost structure and the demand it faces, how much and at what price should it produce so as to maximize profits?\nLet’s first look at how price-setting power can be included in our model. In the chart below, the first panel shows what we have been working with. This actually reflects a special case where the demand curve, the MR curve, and the price line all coincide, such that no matter what output level the firm operates at, demand, marginal revenue, and price will all remain the same.\n\n\nCode\nviewof q6 = Inputs.range([0, qMax], {label: \"Output\", step: 1, value: 50 });\n\n\n\n\n\n\n\n\nPrice-takerPrice-setter\n\n\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q6;\n  params.p = 15;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitles = ({ x: \"Output\", y: \"$\" });\n\n  const yScaler = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n        \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", panelHeight + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, panelHeight + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  const panel = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`);\n  \n  panel.append(\"g\")\n    .call(panelAxes, axisTitles)\n    .call(yGuide, mr, params, yScaler)\n    .call(xGuides, mr, params, yScaler, 1)\n    .call(addCurve, id, mr, params, yScaler);\n  \n  panel.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price = Demand = MR\", xScaler(55), yScaler(params.p) - 20);\n   \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`);\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.q = q6;\n  const p6 = demandMonoFxn({ q: q6 });\n  params.p = p6;\n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitles = ({ x: \"Output\", y: \"$\" });\n  \n  const yScaler = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n        \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", panelHeight + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, panelHeight + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  const panel = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n    \n  panel.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, mrMono, params, yScaler)\n    .call(yGuide, demandMono, params, yScaler);\n  \n  panel.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, mr, params, yScaler, gray)\n    .call(addCurve, id, mrMono, params, yScaler)\n    .call(addCurve, id, demandMono, params, yScaler)\n  \n  panel.append(\"g\")\n    .call(panelAxes, axisTitles)\n    .call(xGuides, demandMono, params, yScaler, 1);\n  \n  panel.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Price\", width + 10, yScaler(params.p))\n    .call(addLabel, \"Demand\", xScaler(66) + 10, yScaler(demandMonoFxn({ q: 66 })) - 10)\n    .call(addLabel, \"MR\", xScaler(33) + 10, yScaler(mrMonoFxn({ q: 33 })) - 10);\n   \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\nThe second panel depicts what would happen if the firm was influential enough to affect demand. Faced with downward-sloping demand, its output decision now has an impact on price: more output depresses it, less output increases it. The MR curve is now also downward-sloping, with a rate of change that is twice as fast as demand.2\nLet’s now combine our new demand and MR curves with our cost curves. Take a deep breath — the chart below may look quite complicated at first. But if you’ve made it this far, you already have all the tools you need to understand it.\n\n\nCode\nviewof p7 = Inputs.range([0, pMax], {label: \"Price\", step: .1, value: 15 })\nviewof fc7 = Inputs.range([0, fcMax], {label: \"Fixed cost\", step: 1, value: 180 })\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  const q = (p) =&gt; Math.floor((27 - p) / (27/95));\n  params.q = q(p7);\n  params.p = p7;\n  params.fc = fc7;\n  \n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-1000, 400])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profitMono, params, yScalerTop)\n    .call(yGuide, profitMono, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profitMono, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitMonoFxn({ q: 70, fc: params.fc })) - 10);\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profitMono, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, mr, params, yScalerBottom, gray)\n    .call(addCurve, id, ac, params, yScalerBottom)\n    .call(addCurve, id, mc, params, yScalerBottom)\n    .call(addCurve, id, demandMono, params, yScalerBottom)\n    .call(addCurve, id, mrMono, params, yScalerBottom)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, ac, params, yScalerBottom)\n    .call(yGuide, mc, params, yScalerBottom)\n    .call(yGuide, mrMono, params, yScalerBottom)\n    .call(yGuide, demandMono, params, yScalerBottom);\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10)\n    .call(addLabel, \"Demand\", xScaler(84) + 10, yScalerBottom(demandMonoFxn({ q: 84 })) - 10)\n    .call(addLabel, \"MR\", xScaler(45) + 10, yScalerBottom(mrMonoFxn({ q: 45 })) - 10);\n\n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStart by playing around with the price level. How does it affect profits? Recall that in the perfectly competitive case, we found that maximum profits are attained at the output level that equates marginal revenue with marginal cost. Can we find the same condition here? It turns out yes! Maximum profits in the monopoly case are still attained when \\(MR = MC\\), except this time, prices are set at the point where output meets the demand curve.\nHere is the big difference with a monopoly: the equilibrium price is set above marginal cost. Moreover, since there is no free entry and exit, there is no mechanism by which the profits of a monopoly can be brought down to zero. Barring any non-market intervention like regulation, these profits are just something monopolies can keep forever.\nWhat’s wrong with all this? It’s beyond the scope of this humble blog post, but to give the broad strokes, economic theory suggests that it is socially optimal for the prices of goods and services to be set as close as possible to the marginal cost of producing those goods and services. Whenever prices are above marginal costs, there is an efficiency loss in the economy. The chart below illustrates this for the case of a monopoly. Toggle between the monopoly outcome and the social optimum to see that monopolies result in lower output at higher prices.\n\n\nCode\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  const q = (p) =&gt; Math.floor((27 - p) / (27/95));\n  const pMonopoly = 15.5;\n  const pCompetitive = 11.5;\n  params.fc = 180;\n  \n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-1000, 400])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurveFull, id, profitMono, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitMonoFxn({ q: 70, fc: params.fc })) - 10);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `guides-monopoly-${id}`)\n    .call(yGuide, profitMono, ({ q: q(pMonopoly), fc: 180, p: pMonopoly }), yScalerTop)\n    .call(xGuides, profitMono, ({ q: q(pMonopoly), fc: 180, p: pMonopoly }), yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `guides-competitive-${id}`)\n    .call(yGuide, profitMono, ({ q: q(pCompetitive), fc: 180, p: pCompetitive }), yScalerTop)\n    .call(xGuides, profitMono, ({ q: q(pCompetitive), fc: 180, p: pCompetitive }), yScalerTop);\n    \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, mc, params, yScalerBottom)\n    .call(addCurveFull, id, demandMono, params, yScalerBottom)\n    .call(addCurveFull, id, mrMono, params, yScalerBottom);\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom);\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10)\n    .call(addLabel, \"Demand\", xScaler(84) + 10, yScalerBottom(demandMonoFxn({ q: 84 })) - 10)\n    .call(addLabel, \"MR\", xScaler(45) + 10, yScalerBottom(mrMonoFxn({ q: 45 })) - 10);\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `guides-monopoly-${id}`)\n    .call(yGuide, demandMono, ({ q: q(pMonopoly), fc: 180, p: pMonopoly }), yScalerBottom);\n\n  panelBottom.append(\"g\")\n    .attr(\"id\", `guides-competitive-${id}`)\n    .call(yGuide, demandMono, ({ q: q(pCompetitive), fc: 180, p: pCompetitive }), yScalerBottom);\n  \n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.selectAll(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  // Chart event listeners ////////////////////////////////////////////////////////////////////////\n  \n  const checkboxMonopoly = svg.append(\"foreignObject\")\n    .attr(\"x\", 400)\n    .attr(\"y\",  475)\n    .attr(\"width\", 20)\n    .attr(\"height\", 20);\n  \n  checkboxMonopoly.append(\"xhtml:input\")\n    .attr(\"type\", \"checkbox\")\n    .attr(\"id\", `checkbox-monopoly-${id}`)\n    .property(\"checked\", true);\n  \n  svg.append(\"g\")\n    .append(\"text\")\n    .text(\"Monopoly outcome\")\n    .attr(\"x\", 400 + 20)\n    .attr(\"y\", 475 + 5)\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .style(\"fill\", \"black\");\n    \n  const checkboxCompetitive = svg.append(\"foreignObject\")\n    .attr(\"x\", 400)\n    .attr(\"y\",  475 + 25)\n    .attr(\"width\", 20)\n    .attr(\"height\", 20);\n  \n  checkboxCompetitive.append(\"xhtml:input\")\n    .attr(\"type\", \"checkbox\")\n    .attr(\"id\", `checkbox-competitive-${id}`)\n    .property(\"checked\", false);\n  \n  svg.append(\"g\")\n    .append(\"text\")\n    .text(\"Social optimum\")\n    .attr(\"x\", 400 + 20)\n    .attr(\"y\", 475 + 5 + 25)\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .style(\"fill\", \"black\");\n  \n  const cbMonopoly = svg.selectAll(\"foreignObject\").select(`input#checkbox-monopoly-${id}`);\n  const cbCompetitive = svg.selectAll(\"foreignObject\").select(`input#checkbox-competitive-${id}`);\n  svg.selectAll(`g#guides-competitive-${id}`).style(\"visibility\", \"hidden\");\n  \n  cbMonopoly.on(\"click\", () =&gt; {\n    const isChecked = cbMonopoly.property(\"checked\");\n    const guidesMonopoly = svg.selectAll(`g#guides-monopoly-${id}`);\n    isChecked ? guidesMonopoly.style(\"visibility\", \"visible\") : guidesMonopoly.style(\"visibility\", \"hidden\");\n  });\n  \n  cbCompetitive.on(\"click\", () =&gt; {\n    const isChecked = cbCompetitive.property(\"checked\");\n    const guidesCompetitive = svg.selectAll(`g#guides-competitive-${id}`);\n    isChecked ? guidesCompetitive.style(\"visibility\", \"visible\") : guidesCompetitive.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\nJust as with with perfect competition, complete monopolies are extremely rare in the real world. Barring natural monopolies like transport terminals and utilities, it’s near impossible for a firm to control the production of a good so exclusively that no one else can sell anything even remotely similar. It’s more often the case that a firm has a monopoly on a brand, but not on a product. While it’s true that Apple has a monopoly on selling the iPhone, it doesn’t have a monopoly on smartphones in general. Or to take a more topical example, the proposed acquisition by Microsoft of Activision Blizzard has raised alarm bells over the monopolization of the video game industry, but while the new entity would control several popular franchises, the video game market in general would still have plenty of sellers.\nThis cross between perfect competition and monopolies is its own class of market structure called monopolistic competition. Its defining trait is that while each firm holds a monopoly over its product, the product itself is substitutable to varying degrees with similar products made by other firms. Firms are free to enter and exit the market for the product class. This has wide application to many of the industries we as consumers care about: smartphones, search engines, streaming services, clothes, appliances, and so on.\nMonopolistic competition is easy to incorporate in our model of the monopoly. All the curves will remain the same; the only difference is that in the long run, the entry of new firms in a profitable monopolistic market will diminish the demand our monopolist faces. As with perfect competition, this entry will go on until the monopoly’s profits dwindle to zero. Try it yourself by sliding the market size down in the chart below.\n\n\nCode\nviewof demandCoef = Inputs.range([16.8, 25], {label: \"Market size\", step: .1, value: 27 })\nviewof fc8 = Inputs.range([0, fcMax], {label: \"Fixed cost\", step: 1, value: 0, disabled: true })\n\n{\n  const params = ({ q: null, fc: null, p: null, c: null });\n  params.fc = fc8;\n  params.c = demandCoef;\n  \n  const b = 54/95 - 1.12;\n  const qFxn = ({ c }) =&gt; Math.floor( (1/.036) * (-b + Math.pow( Math.pow(b, 2) - 1.44 + .072 * c, .5 ) ) );\n  const demandMonoCompFxn = ({ q, c } = {}) =&gt; c - (27/95) * q;\n  const mrMonoCompFxn = ({ q, c } = {}) =&gt; c - 2 * (27/95) * q;\n  const profitMonoCompFxn = ({ q, fc, c } = {}) =&gt; {\n    return Math.ceil(demandMonoCompFxn({ q, c }) * q - costFxn({ q, fc }));\n  }\n  const p = ({ q, c }) =&gt; demandMonoCompFxn({ q: qFxn({ c: params.c }), c: params.c });\n  \n  params.q = qFxn({ c: params.c });\n  params.p = p({ q: qFxn({ c: params.c }), c: params.c });\n  \n  demandMonoComp.fxn = demandMonoCompFxn;\n  mrMonoComp.fxn = mrMonoCompFxn;\n  profitMonoComp.fxn = profitMonoCompFxn;\n  \n  const id = d3.randomInt(100000, 1000000)();\n  const axisTitlesTop = ({ x: \"Output\", y: \"$\" });\n  const axisTitlesBottom = ({ x: \"Output\", y: \"$/unit\" });\n  \n  const yScalerTop = d3.scaleLinear()\n    .domain([-1000, 400])\n    .range([panelHeight, 0]);\n  const yScalerBottom = d3.scaleLinear()\n    .domain([0, acFxn({ q: qMax, fc: fcMax })])\n    .range([panelHeight, 0]);\n    \n  const demandMonoCompInvFxn = ({ dmd, c } = {}) =&gt; (95/27) * (c - dmd);\n  const mrMonoCompInvFxn = ({ mr, c } = {}) =&gt; (95/(27*2)) * (c - mr);\n  const corners = ({ x1: 0, y1: yScalerBottom(params.p), x2: xScaler(params.q), y2: yScalerBottom(acFxn(params)) });\n  \n  const container = d3.create(\"div\")\n        .attr(\"style\", \"display: flex; justify-content: center\");\n    \n  const svg = container.append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .attr(\"viewBox\", [0, 0, width + margin.left + margin.right, height + margin.top + margin.bottom])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\")\n    .call(background)\n    .call(labelsToggle, id);\n  \n  // Top panel ////////////////////////////////////////////////////////////////////////////////////\n  \n  const panelTop = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top})`)\n  \n  panelTop.append(\"g\")\n    .call(clipWide, id)\n    .call(addCurve, id, profitMonoComp, params, yScalerTop)\n    .call(yGuide, profitMonoComp, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .call(panelAxesT, axisTitlesTop, yScalerTop)\n    .call(xGuides, profitMonoComp, params, yScalerTop);\n  \n  panelTop.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(clipWide, id)\n    .call(addLabel, \"Profit\", xScaler(70) + 10, yScalerTop(profitMonoCompFxn({ q: 70, fc: params.fc, c: params.c })) - 10);\n  \n  // Bottom panel /////////////////////////////////////////////////////////////////////////////////\n  \n  const panelBottom = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left}, ${margin.top + panelHeight + margin.between})`);\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(addArea, id, profitMono, corners)\n    .select(\"path\")\n    .style(\"fill\", corners.y1 &lt; corners.y2 ? \"#7fc6a4\" : \"#f697bb\");\n    \n  panelBottom.append(\"g\")\n    .call(clip, id)\n    .call(addCurveFull, id, price, params, yScalerBottom, gray)\n    .call(addCurve, id, ac, params, yScalerBottom)\n    .call(addCurve, id, mc, params, yScalerBottom)\n    .call(addCurve, id, demandMonoComp, params, yScalerBottom)\n    .call(addCurve, id, mrMonoComp, params, yScalerBottom)\n  \n  panelBottom.append(\"g\")\n    .call(clipWide, id)\n    .call(yGuide, ac, params, yScalerBottom)\n    .call(yGuide, demandMonoComp, params, yScalerBottom);\n    \n  panelBottom.append(\"g\")\n    .call(panelAxes, axisTitlesBottom)\n  \n  panelBottom.append(\"g\")\n    .attr(\"id\", `labels-${id}`)\n    .call(addLabel, \"Price\", width + 10, yScalerBottom(params.p))\n    .call(addLabel, \"AC\", xScaler(95) - 10, yScalerBottom(acFxn({ q: 95, fc: params.fc })) - 10, \"end\")\n    .call(addLabel, \"MC\", xScaler(63) + 10, yScalerBottom(mcFxn({ q: 63 })) + 10)\n    .call(addLabel, \"Demand\", xScaler(demandMonoCompInvFxn({ dmd: 1, c: params.c})) + 10, yScalerBottom(1) - 10)\n    .call(addLabel, \"MR\", xScaler(mrMonoCompInvFxn({ mr: 1, c: params.c })) + 10, yScalerBottom(1) - 10);\n\n  // Toggle event listener ////////////////////////////////////////////////////////////////////////\n  \n  const cb = svg.select(\"foreignObject\").select(`input#checkbox-${id}`)\n  \n  cb.on(\"click\", () =&gt; {\n    const isChecked = cb.property(\"checked\");\n    const chartLabels = svg.selectAll(`g#labels-${id}`);\n    isChecked ? chartLabels.style(\"visibility\", \"visible\") : chartLabels.style(\"visibility\", \"hidden\");\n  });\n  \n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice however that the long-run equilibrium under monopolistic competition still enatils lower output at higher prices compared with perfect competition. While Apple and its friends do face competitive pressures from each other, product differentiation means that their profit-maximizing level of output is below the social optimum. Do note that this takes a very narrow conception of the social optimum, in that it only accounts for prices and output. An argument can be made that while a monopolistic competitor can reap more monopoly profits by further differentiating its product, the fact that it results in better smartphones, video games, and appliances redounds ultimately to the consumer’s benefit. But that’s a topic for another day."
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#concluding-thoughts",
    "href": "posts/2023-04-14-learning-curves/index.html#concluding-thoughts",
    "title": "Learning curves",
    "section": "Concluding thoughts",
    "text": "Concluding thoughts\nThis blog post demonstrates how interactive charts can be used to enrich the teaching of economics. I have used D3 and Quarto’s built-in Observable engine here, but more broadly, the use of webpages in constructing learning modules lets us take full advantage of HTML, CSS, and Javascript functionality. We can spice the text up by adding highlighting, animation, and gratuitous  Pikachu  faces .\nEconomists are always referring to “toy models” of the economy. It’s time we get to play with them."
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#d3-observable-code",
    "href": "posts/2023-04-14-learning-curves/index.html#d3-observable-code",
    "title": "Learning curves",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\ncostFxn = ({ q, fc } = {}) =&gt; {\n  return .006 * Math.pow(q, 3) - .56 * Math.pow(q, 2) + 20 * q + fc\n};\nacFxn = ({ q, fc } = {}) =&gt; {\n  if (isNaN(costFxn({ q, fc }) / q)) return .006 * Math.pow(q, 2) - .56 * q + 20\n  else if (q === 0) return null\n  else return costFxn({ q, fc }) / q\n};\navcFxn = ({q} = {}) =&gt; .006 * Math.pow(q, 2) - .56 * q + 20;\nmcFxn = ({q} = {}) =&gt; .006 * 3 * Math.pow(q, 2) - .56 * 2 * q + 20;\nprofitFxn = ({ q, p, fc } = {}) =&gt; p * q - costFxn({ q, fc });\nsupplyFxn = ({q} = {}) =&gt; {\n  const minAVCq = Math.floor(.56 / (.006 * 2));\n  if (q &lt; minAVCq + 1) return avcFxn({ q: minAVCq });\n  else return mcFxn({ q });\n}\nmrFxn = ({p} = {}) =&gt; p;\ndemandMonoFxn = ({q} = {}) =&gt; 27 - (27/95) * q;\nmrMonoFxn = ({q} = {}) =&gt; 27 - 2 * (27/95) * q;\nprofitMonoFxn = ({ q, fc } = {}) =&gt; {\n  return demandMonoFxn({q}) * q - costFxn({ q, fc })\n};\n\ncost = ({ fxn: costFxn, label: \"Cost\", id: \"cost-curve\", scheme: red });\nac = ({ fxn: acFxn, label: \"Average cost\", id: \"ac-curve\", scheme: blue });\navc = ({ fxn: avcFxn, label: \"Average variable cost\", id: \"avc-curve\", scheme: blue });\nmc = ({ fxn: mcFxn, label: \"Marginal cost\", id: \"mc-curve\", scheme: blue });\nprofit = ({ fxn: profitFxn, label: \"Profit\", id: \"profit-curve\", scheme: red });\nprice = ({ fxn: mrFxn, label: \"Price\", id: \"mr-curve\", scheme: green });\nmr = ({ fxn: mrFxn, label: \"Marginal revenue\", id: \"mr-curve\", scheme: green });\nsupply = ({ fxn: supplyFxn, label: \"Supply\", id: \"supply-curve\", scheme: blue });\n\ndemandMono = ({ fxn: demandMonoFxn, label: \"Demand\", id: \"demand-mono-curve\", scheme: green });\nmrMono = ({ fxn: mrMonoFxn, label: \"Marginal revenue\", id: \"mr-mono-curve\", scheme: green });\nprofitMono = ({ fxn: profitMonoFxn, label: \"Profit\", id: \"profit-mono-curve\", scheme: red });\n\ndemandMonoComp = ({ fxn: null, label: \"Demand\", id: \"demand-monocomp-curve\", scheme: green });\nmrMonoComp = ({ fxn: null, label: \"Marginal revenue\", id: \"mr-monocomp-curve\", scheme: green });\nprofitMonoComp = ({ fxn: null, label: \"Profit\", id: \"profit-monocomp-curve\", scheme: red });\n\nmargin = ({ top: 50, right: 100, bottom: 40, left: 70, between: 60 });\nwidth = 400;\nheight = panelHeight * 2 + margin.between;\npanelHeight = 280;\nfcMax = 500;\nqMax = 100;\npMax = 27;\n\nbgColor = \"#EDF8FF\";\nblue = ({ base: \"#4889ab\", dull: \"#A2C4D2\", baseSelect: \"#0C6291\", dullSelect: \"#669DB8\"});\nred = ({ base: \"#C85B89\", dull: \"#E29FBC\", baseSelect: \"#B13D70\", dullSelect: \"#D1729A\" });\ngreen = ({ base: \"#71B795\", dull: \"#B4D7C6\", baseSelect: \"#418462\", dullSelect: \"#73AA8E\" });\ngray = ({ base: \"#DDDDDD\", dull: \"#DDDDDD\", baseSelect: \"#D0D0D0\", dullSelect: \"##D0D0D0\" });\ndashed = \"#999999\";\nstrokeWidth = 5;\n\ntooltip = d3.select(\"body\")\n  .append(\"div\")\n  .attr(\"class\", \"toolTip\")\n  .style(\"display\", \"none\")\n  .style(\"position\", \"absolute\")\n  .style(\"width\", 100)\n  .style(\"height\", 20)\n  .style(\"background\", \"#f7f7f7\")\n  .style(\"border\", \"1px solid #cecece\")\n  .style(\"opacity\", .9)\n  .style(\"padding\", \".2em .45em\")\n  .style(\"font-size\", \".85rem\");\n\nline = d3.line().curve(d3.curveBasis);\n\nxScaler = d3.scaleLinear()\n  .domain([0, qMax])\n  .range([0, width]);\n\ndata = (fxn, params, yScaler) =&gt; {\n  const q = params.q, p = params.p, fc = params.fc, c = params.c;\n  return Array.from({ length: q + 1 }, (_, i) =&gt; {\n    const y = yScaler(fxn({ q: i, p, fc, c })) ?? -500;\n    const x = (y == null) ? null : xScaler(i);\n    return [x, y];\n  })\n};\n\ndataMax = (fxn, params, yScaler) =&gt; {\n  const q = qMax, p = params.p, fc = params.fc, c = params.c;\n  return Array.from({ length: q + 1 }, (_, i) =&gt; {\n    const y = yScaler(fxn({ q: i, p, fc, c })) ?? -500;\n    const x = (y == null) ? null : xScaler(i);\n    return [x, y];\n  })\n};\n\nbackground = selection =&gt; {\n  selection.append(\"rect\")\n    .attr(\"x\", 0).attr(\"y\", 0)\n    .attr(\"width\", selection.attr(\"width\"))\n    .attr(\"height\", selection.attr(\"height\"))\n    .style(\"fill\", bgColor)\n    .style(\"stroke\", \"#E0EDFB\")\n    .style(\"stroke-width\", 8);\n  return selection.node()\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddCurve = (selection, id, fxnInfo, params, yScaler) =&gt; {\n\n  const point = data(fxnInfo.fxn, params, yScaler)[params.q]\n\n  const curves = selection.append(\"g\")\n    .attr(\"id\", `${fxnInfo.id}-${id}`)\n    .attr(\"pointer-events\", \"visibleStroke\")\n  \n  // Non-highlighted portion\n  curves.append(\"path\")\n    .attr(\"class\", \"curve dulled\")\n    .attr(\"d\", line(dataMax(fxnInfo.fxn, params, yScaler)))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", fxnInfo.scheme.dull)\n    .style(\"stroke-width\", strokeWidth)\n  \n  // Highlighted portion\n  curves.append(\"path\")\n    .attr(\"class\", \"curve colored\")\n    .attr(\"d\", line(data(fxnInfo.fxn, params, yScaler)))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", fxnInfo.scheme.base)\n    .style(\"stroke-width\", strokeWidth)\n  \n  // Add hover effects\n  curves\n    .on(\"mousemove\", (event) =&gt; {\n      d3.selectAll(`#${fxnInfo.id}-${id} .curve.colored`)\n        .transition().duration(50)\n        .style(\"stroke-width\", strokeWidth + 2)\n        .style(\"stroke\", fxnInfo.scheme.baseSelect);\n      d3.selectAll(`#${fxnInfo.id}-${id} .curve.dulled`)\n        .transition().duration(50)\n        .style(\"stroke-width\", strokeWidth + 2)\n        .style(\"stroke\", fxnInfo.scheme.dullSelect);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(fxnInfo.label);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", (event) =&gt; {\n      d3.selectAll(`#${fxnInfo.id}-${id} .curve.colored`)\n        .transition().duration(100)\n        .style(\"stroke-width\", strokeWidth)\n        .style(\"stroke\", fxnInfo.scheme.base);\n      d3.selectAll(`#${fxnInfo.id}-${id} .curve.dulled`)\n        .transition().duration(100)\n        .style(\"stroke-width\", strokeWidth)\n        .style(\"stroke\", fxnInfo.scheme.dull);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n\n  return selection.node()\n}\n\naddCurveFull = (selection, id, fxnInfo, params, yScaler, scheme = fxnInfo.scheme) =&gt; {\n  \n  const curves = selection.append(\"g\")\n    .attr(\"id\", `${fxnInfo.id}-${id}`)\n    .attr(\"pointer-events\", \"visibleStroke\");\n  \n  curves.append(\"path\")\n    .attr(\"class\", \"curve\")\n    .attr(\"d\", line(dataMax(fxnInfo.fxn, params, yScaler)))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", scheme.base)\n    .style(\"stroke-width\", strokeWidth)\n\n  // Add hover effects\n  curves\n    .on(\"mousemove\", (event) =&gt; {\n      d3.selectAll(`#${fxnInfo.id}-${id} .curve`)\n        .transition().duration(50)\n        .style(\"stroke-width\", strokeWidth + 2)\n        .style(\"stroke\", scheme.baseSelect);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(fxnInfo.label);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", (event) =&gt; {\n      d3.selectAll(`#${fxnInfo.id}-${id} .curve`)\n        .transition().duration(100)\n        .style(\"stroke-width\", strokeWidth)\n        .style(\"stroke\", scheme.base);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n\n  return selection.node()\n}\n\naddArea = (selection, id, info, corners) =&gt; {\n  \n  const area = selection.append(\"path\")\n    .attr(\"id\", `area-${info.id}-${id}`)\n    .attr(\"d\", d3.line()([ \n      [corners.x1, corners.y1], \n      [corners.x2, corners.y1],\n      [corners.x2, corners.y2],\n      [corners.x1, corners.y2]\n    ]))\n    .style(\"opacity\", .25)\n    .style(\"fill\", \"#7fc6a4\")\n  \n  // Add hover effects\n  area\n    .on(\"mousemove\", (event) =&gt; {\n      d3.selectAll(`#area-${info.id}-${id}`)\n        .transition().duration(50)\n        .style(\"opacity\", .5);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(info.label);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", (event) =&gt; {\n      d3.selectAll(`#area-${info.id}-${id}`)\n        .transition().duration(50)\n        .style(\"opacity\", .25);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n\n  return selection.node()\n}\n\nclip = (selection, id) =&gt; {\n  \n  selection.attr(\"clip-path\", `url(#clip-${id})`);\n  \n  const clip = selection.append(\"clipPath\")\n    .attr(\"id\", `clip-${id}`);\n  clip.append(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", 0)\n    .attr(\"width\", width + margin.right)\n    .attr(\"height\", panelHeight)\n    .style(\"fill\", \"white\");\n    \n  return selection.node();\n}\n\nclipWide = (selection, id) =&gt; {\n  \n  selection.attr(\"clip-path\", `url(#clip-wide-${id})`);\n  \n  const clip = selection.append(\"clipPath\")\n    .attr(\"id\", `clip-wide-${id}`);\n  clip.append(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", 0)\n    .attr(\"width\", width + margin.right)\n    .attr(\"height\", panelHeight)\n    .style(\"fill\", \"white\");\n  clip.append(\"rect\")\n    .attr(\"x\", -margin.left)\n    .attr(\"y\", -10)\n    .attr(\"width\", margin.left)\n    .attr(\"height\", panelHeight + 20)\n    .style(\"fill\", \"white\");\n  \n  return selection.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npanelAxes = (selection, titles) =&gt; {\n  \n  const axes = selection.append(\"g\")\n  \n  // Axis lines\n  axes.append(\"path\")\n    .attr(\"d\", d3.line()([[width, panelHeight], [0, panelHeight], [0, 0]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", \"black\")\n    .style(\"stroke-width\", 2);\n  \n  // Axis titles    \n  axes.append(\"text\")\n    .text(titles.x)\n    .attr(\"x\", width + 10)\n    .attr(\"y\", panelHeight)\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"text-anchor\", \"start\")\n    .style(\"alignment-baseline\", \"middle\");\n  axes.append(\"text\")\n    .text(titles.y)\n    .attr(\"x\", 0)\n    .attr(\"y\", -15)\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"text-anchor\", \"middle\");\n\n  return selection.node()\n}\n\npanelAxesT = (selection, titles, yScaler) =&gt; {\n  \n  const axes = selection.append(\"g\")\n  \n  // Axis lines\n  axes.append(\"path\")\n    .attr(\"d\", d3.line()([[0, yScaler(0)], [width, yScaler(0)]]))\n    .style(\"stroke\", \"black\")\n    .style(\"stroke-width\", 2);\n  axes.append(\"path\")\n    .attr(\"d\", d3.line()([[0, 0], [0, panelHeight]]))\n    .style(\"stroke\", \"black\")\n    .style(\"stroke-width\", 2);\n  \n  // Axis titles\n  axes.append(\"text\")\n    .text(titles.x)\n    .attr(\"x\", width + 10)\n    .attr(\"y\", yScaler(0))\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"text-anchor\", \"start\")\n    .style(\"alignment-baseline\", \"middle\");\n  axes.append(\"text\")\n    .text(titles.y)\n    .attr(\"x\", 0)\n    .attr(\"y\", -15)\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"text-anchor\", \"middle\");\n\n  return selection.node()\n}\n\nxGuides = (selection, fxnInfo, params, yScaler, panels = 2) =&gt; {\n  \n  const point = data(fxnInfo.fxn, params, yScaler)[params.q];\n  const guide = selection.append(\"g\");\n  \n  // Dashed line\n  const dashedLine = guide.append(\"path\")\n    .attr(\"d\", line([[point[0], point[1]], [point[0], panelHeight * 2 + margin.between]]))\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", dashed)\n    .attr(\"stroke-dasharray\", \"4 4\");\n  \n  // Tick\n  const tick = guide.append(\"text\")\n    .text(d3.format(\",.0f\")(params.q))\n    .attr(\"x\", xScaler(params.q))\n    .attr(\"y\", panelHeight * 2 + margin.between)\n    .attr(\"dy\", 10)\n    .attr(\"text-anchor\", \"middle\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\");\n    \n  if (panels === 1) {\n    dashedLine.attr(\"d\", line([[point[0], point[1]], [point[0], panelHeight]]));\n    tick.attr(\"y\", panelHeight)\n  }\n   \n  return selection.node()\n}\n  \nyGuide = (selection, fxnInfo, params, yScaler, format = \",.0f\") =&gt; {\n  \n  const point = data(fxnInfo.fxn, params, yScaler)[params.q]\n  const guide = selection.append(\"g\")\n  \n  // Dashed line\n  guide.append(\"g\")\n    .append(\"path\")\n    .attr(\"d\", line([[point[0], point[1]], [0, point[1]]]))\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke\", dashed)\n    .attr(\"stroke-dasharray\", \"4 4\")\n  \n  // Axis tick\n  guide.append(\"g\")\n    .append(\"text\")\n    .text(d3.format(format)(fxnInfo.fxn(params)))\n    .attr(\"x\", 0)\n    .attr(\"y\", point[1])\n    .attr(\"dx\", -10)\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\");\n  \n  return selection.node()\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddLabel = (selection, label, x, y, anchor = \"start\") =&gt; {\n  selection.append(\"text\")\n    .text(label)\n    .attr(\"x\", x)\n    .attr(\"y\", y)\n    .attr(\"text-anchor\", anchor)\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"font-weight\", \"bold\");\n  return selection.node()\n}\n\nlabelsToggle = (selection, id) =&gt; {\n\n  const checkbox = selection.append(\"foreignObject\")\n    .attr(\"x\", width + margin.left + 10)\n    .attr(\"y\",  15)\n    .attr(\"width\", 20)\n    .attr(\"height\", 20);\n  \n  checkbox.append(\"xhtml:input\")\n    .attr(\"type\", \"checkbox\")\n    .attr(\"id\", `checkbox-${id}`)\n    .property(\"checked\", true);\n  \n  selection.append(\"g\")\n    .append(\"text\")\n    .text(\"Labels\")\n    .attr(\"x\", width + margin.left + margin.right - 25)\n    .attr(\"y\", 20)\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .style(\"fill\", \"#84b0c5\");\n  \n  return selection.node()\n}"
  },
  {
    "objectID": "posts/2023-04-14-learning-curves/index.html#footnotes",
    "href": "posts/2023-04-14-learning-curves/index.html#footnotes",
    "title": "Learning curves",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe numbers in this and all the charts are a little imprecise. This is because, for simplicity, I’m only letting \\(q\\) take integer values whereas the mathematics of optimization assumes we can pick any \\(q\\) we want, be it 59 or 59.000001.↩︎\nWhy the MR curve’s slope should specifically be twice that of the demand curve’s stems from the fact that MR takes twice the impact of each additional increase in \\(q\\). If \\(q\\) increases by 1, the price associated with that level of demand falls by, let’s say, \\(b\\) units. Meanwhile, for every unit of \\(b\\), MR loses one unit from the price drop and one unit from the price adjustment via the demand curve. Thus it falls by twice \\(b\\).↩︎"
  },
  {
    "objectID": "posts/2023-04-22-the-tales-we-tell/index.html",
    "href": "posts/2023-04-22-the-tales-we-tell/index.html",
    "title": "The tales we tell",
    "section": "",
    "text": "In the bittersweet finale of Stephen Sondheim’s Into the Woods, as the Baker quiets his child with yet another story, the Witch steps forward to deliver the musical’s central thesis:\nFor those who aren’t familiar, Into the Woods is a retelling of Grimm fairy tales — Cinderella, Little Red Riding Hood, and the like.1 Each character starts with a wish that, through cunning, daring, and a fair bit of magic, they attain, whereupon they join hands in triumph to sing “happily ever after”. But that is a feint, for only first act is done. In the unhinged second act, the characters find themselves fleeing from the consequences of their wishes, culminating in their murder of the very Narrator who has been telling their story. It demonstrates metaphorically and literally how stories, once told, can take a life of their own. And thus: careful the tale you tell.\nIt has long been known that narratives shape social and political outcomes, but measuring this quantitatively can be tricky. In this post, I’ll cover a paper by Stelios Michalopoulos and Melanie Meng Xue that does just this. Their primary dataset is Yuri Berezkin’s Folklore and Mythology Catalog, an ambitious project that attempts to document the motifs found in folklore around the world. A motif is some distinctive episode, idea, or image; folklore is the body of traditional stories passed orally among an ethnolinguistic group. The version of the Catalog I’ll be working with logs 2,564 motifs for about 900 groups.2\nIn the interactive map below, you can pull up a random motif and see which oral traditions have it. You’ll find that some motifs are universal, others are very niche. The ones in between are the most intruiging: the chart initializes on a motif about hidden identities (f64a), found in North America and Southeast Asia but hardly anywhere else.\nCode\n{\n  const dim = ({ width: 990, height: 660 });\n  const motif = \"f64a\";\n  \n  const container = d3.create(\"div\");\n  \n  // Chart title //////////////////////////////////////////////////////////////\n  \n  container.append(\"div\")\n    .attr(\"class\", \"ojs-title\")\n    .html(`Plot points`);\n    \n  container.append(\"div\")\n    .attr(\"class\", \"ojs-subtitle\")\n    .style(\"margin-bottom\", \"1rem\")\n    .html(`Presence of a motif in the folklore of linguistic groups`);\n  \n  // Chart proper /////////////////////////////////////////////////////////////\n  \n  const svg = container.append(\"svg\")\n    .attr(\"width\", dim.width)\n    .attr(\"height\", dim.height)\n    .attr(\"viewBox\", [0, 0, dim.width, dim.height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  svg.call(addMap);\n  \n  svg.append(\"g\")\n    .selectAll(\"dotsLatent\")\n    .data(coords)\n    .join(\"circle\")\n    .attr(\"cx\", d =&gt; d.coordinates[0])\n    .attr(\"cy\", d =&gt; d.coordinates[1])\n    .attr(\"r\", 2)\n    .style(\"fill\", colorDotsLatent);\n    \n  svg.append(\"g\").attr(\"id\", \"dots-highlighted\").call(dotsSelect, motif);\n  \n  // Motif randomizer\n  svg.append(\"g\").attr(\"id\", \"motif-id\").call(motifSelectId, motif);\n  svg.append(\"g\").attr(\"id\", \"motif-title\").call(motifSelectTitle, motif);\n  svg.append(\"g\").attr(\"id\", \"motif-description\").call(motifSelectDesc, motif);\n  svg.append(\"g\").attr(\"id\", \"button\").call(addButton);\n  \n  // Chart sources ////////////////////////////////////////////////////////////\n\n  container.append(\"div\")\n    .attr(\"class\", \"ojs-source\")\n    .style(\"margin\", \".5rem 0\")\n    .html(`Source: Y. Berezkin, &lt;i&gt;Folklore and Mythology Catalog&lt;/i&gt; (2019).`);\n    \n  return container.node();\n}\nThere are obviously a lot of caveats here. The same motif may not necessarily mean the same thing across different cultures. Presence or absence does not capture how central a motif is in a group’s folklore. Groups whose oral traditions have been studied more would tend to have greater representation. And on top of everything, the texts in the Catalog were originally in Russian; here I am using the English translations provided by Berezkin himself. What you’re reading above, then, is often a translation of a translation.3\nYet despite all that, Berezkin’s Catalog remains an enlightening resource for uncovering patterns in the world’s body of folklore. Mapping the presence of a motif can mean mapping ancient trade and migration routes long forgotten by history. Or where no such routes existed, it suggests the stirring notion that humans, though leagues and cultures apart, can look at the same world and arrive at the same ideas, or imagine the same fictions.\nBut folklore across cultures do also differ, often tremendously. This may arise from random chance, or perhaps to something more fundamental, like the physical environment. To investigate this, Michalopoulos and Xue use ConceptNet to attach concepts to motifs. ConceptNet is a semantic network that, among other things, provides a list of related words from a seed word. This is useful when gathering all motifs related to the concept of, say, fire, since simply taking motifs with the word “fire” may cause you to miss those with the words “burn”, “smoke”, “flame”, and so on. ConceptNet offers a systematic way to assemble the words that form the contours of a concept. They can then be used to shortlist motifs exhibiting that concept.\nWith this concept-tagging approach, Michalopoulos and Xue can test whether features of a linguistic group’s physical environment and mode of subsistence correlate with the motifs in their folklore. For instance, do groups near earthquake-prone regions tend to have more earthquake-related motifs? It turns out, yes. Toggle the concepts in the map below to see where that concept most saturates the oral tradition.\nCode\n{\n  const dim = ({ width: 990, height: 580 });\n  \n  const container = d3.create(\"div\");\n  \n  // Chart title //////////////////////////////////////////////////////////////\n  \n  container.append(\"div\")\n    .attr(\"class\", \"ojs-title\")\n    .html(`Planted ideas`);\n    \n  container.append(\"div\")\n    .attr(\"class\", \"ojs-subtitle\")\n    .style(\"margin-bottom\", \"1rem\")\n    .html(`Share of motifs related to various concepts in the folklore of linguistic groups`);\n  \n  // Map base layer ///////////////////////////////////////////////////////////\n  \n  const svg = container.append(\"svg\")\n    .attr(\"width\", dim.width)\n    .attr(\"height\", dim.height)\n    .attr(\"viewBox\", [0, 0, dim.width, dim.height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n  \n  svg.call(addMap);\n  \n  // Radio buttons ////////////////////////////////////////////////////////////\n   \n  const radio = svg.append(\"g\")\n    .attr(\"id\", \"radio\")\n    .attr(\"transform\", \"translate(30,410)\");\n  \n  const radioButtons = radio.append(\"foreignObject\")\n    .attr(\"x\", 0)\n    .attr(\"y\",  0)\n    .attr(\"width\", 250)\n    .attr(\"height\", 500);\n  \n  const radioTitle = radioButtons.append(\"xhtml:div\")\n    .append(\"text\")\n    .text(\"Share of motifs related to\")\n    .style(\"font-weight\", \"bold\")\n    .style(\"font-size\", \".9rem\");\n  \n  radioButtons\n    .call(addRadio, \"farming\", true)\n    .call(addRadio, \"pastoral\")\n    .call(addRadio, \"fishing\")\n    .call(addRadio, \"coldness\")\n    .call(addRadio, \"earthquakes\");\n    \n  radioButtons.on(\"click\", () =&gt; {\n    const selectedNew = d3.select('input[name=\"concepts\"]:checked').node().value;\n    svg.select(\"#bubbles\").call(addBubbles, selectedNew);\n  });\n  \n  // Points ///////////////////////////////////////////////////////////////////\n  \n  const selectInit = \"farming\"\n  svg.append(\"g\")\n    .attr(\"id\", \"bubbles\")\n    .call(addBubbles, selectInit);\n  \n  // Chart sources ////////////////////////////////////////////////////////////\n\n  container.append(\"div\")\n    .attr(\"class\", \"ojs-source\")\n    .style(\"margin\", \".5rem 0\")\n    .html(`Sources: Y. Berezkin, &lt;i&gt;Folklore and Mythology Catalog&lt;/i&gt; (2019); S. Michalopoulos and M. Xue, \"Folklore\", &lt;i&gt;Quarterly Journal of Economics&lt;/i&gt;, vol. 136, no. 4 (2021).`);\n    \n  return container.node();\n}\nThis sheds light on how folklore was formed. Folklore, in turn, can influence the constellation of attitudes, beliefs, norms, and prejudices that prevail in modern-day society. Michalopoulos and Xue look at three areas in particular: trust, risk appetite, and gender equality. They seek to establish whether folklore that emphasizes these traits are more likely to be found in societies that exhibit these traits. To do this, they employ human readers to manually categorize the content of motifs. They also aggregate the linguistic groups up to the country level following modern borders. Where significant migration has taken place, they adjust populations using Putterman and Weil’s World Migration Matrix.\nThe estimated relationships — all with slopes that are statistically significant — are plotted below.\nhtml`\n  &lt;div class=\"ojs-title\" style=\"margin-top:1rem;\"&gt;A nightmare on the brains of the living&lt;/div&gt;\n  &lt;div class=\"ojs-subtitle\"&gt;Relationship between folklore content and present-day attitudes and beliefs&lt;/div&gt;\n`\nhtml`\n  &lt;div class=\"ojs-caption\" style=\"margin-bottom: 1rem;\"&gt;Trendlines are from multivariate cross-country regressions with two other control variables: the log number of publications Berezkin consulted for a group and the log year of the earliest publication cited for a group.&lt;/div&gt;\n  &lt;div class=\"ojs-source\" style=\"margin-bottom: 1rem;\"&gt;GPS = Global Preference Survey, WVS = World Value Surveys&lt;br&gt;Source: S. Michalopoulos and M. Xue, \"Folklore\", &lt;i&gt;Quarterly Journal of Economics&lt;/i&gt;, vol. 136, no. 4 (2021).&lt;/div&gt;\n`\nFor the trust variable, the authors look at motifs that involve a trickster or deceiver, and whether they are punished for their mischief. They find that countries with folklore that punishes its tricksters have people today who are more trusting, as measured in surveys. For risk appetite meanwhile, Michalopoulos and Xue look at motifs that involve challenges or competitions, regardless of whether the characters succeed or not. Countries with such folklore are found to have people who are more risk tolerant, again as measured in surveys. Finally, the extent to which a country’s folklore stereotypes men as violent/strong/dominant and women as emotional/beautiful/submissive correlates negatively with its female labor force participation rate.\nThese findings are interesting not just in themselves but also from the standpoint of economic development. Trust facilitates cooperation among disparate groups. Risk-taking is essential for entrepreneurship. And of course, shutting out women from the workforce means cutting your labor pool in half. That folklore appears to have influenced these outcomes adds to our understanding for how deep historical forces shaped the comparative wealth of nations, something we have talked about before.\nStories are entertainment — bits of made-up nonsense we pass around to pass the time. But they also have a furtive sort of power, planting ideas that harden into truths. They are all the more perilous from being inconspicuous, as water is to fish. So when the time comes to pass them down to our children as our parents passed them down to us, let us beware. Children will listen."
  },
  {
    "objectID": "posts/2023-04-22-the-tales-we-tell/index.html#data-and-cleaning-scripts",
    "href": "posts/2023-04-22-the-tales-we-tell/index.html#data-and-cleaning-scripts",
    "title": "The tales we tell",
    "section": "Data and cleaning scripts",
    "text": "Data and cleaning scripts\n\n\nMichalopoulos and Xue (2021) replication files\ncountries-110m.json (source: topojson/world-atlas)\ncoords.json (source: macleginn/mythology-queries)\nclean.ipynb / match_names_to_coords.csv, match_names_to_mx.csv, coords_clean.json, motifs.csv, groups_motifs.csv, groups_concepts.csv, regressions.csv"
  },
  {
    "objectID": "posts/2023-04-22-the-tales-we-tell/index.html#d3-observable-code",
    "href": "posts/2023-04-22-the-tales-we-tell/index.html#d3-observable-code",
    "title": "The tales we tell",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\ncountries110m = FileAttachment(\"../../datasets/folklore/countries-110m.json\").json();\nworldAll = topojson.feature(countries110m, countries110m.objects.countries).features;\nworld = worldAll.filter(d =&gt; d.properties.name !== \"Antarctica\");\n\ncoordsRaw = FileAttachment(\"../../datasets/folklore/coords_clean.json\").json();\ncoords = coordsRaw.map(d =&gt; ({ group: d.group, coordinates: projection([d.longitude, d.latitude]) }));\nmotifs = FileAttachment(\"../../datasets/folklore/motifs.csv\").csv({ typed: true });\ngroupsMotifs = FileAttachment(\"../../datasets/folklore/groups_motifs.csv\").csv({ typed: true });\n\ngroupsConceptsRaw = FileAttachment(\"../../datasets/folklore/groups_concepts.csv\").csv({ typed: true });\ngroupsConcepts = groupsConceptsRaw.map(d =&gt; ({ \n  group: d.group, \n  coordinates: projection([d.longitude, d.latitude]),\n  concept: d.concept,\n  share: d.share\n}));\n\nregressions = FileAttachment(\"../../datasets/folklore/regressions.csv\").csv({ typed: true });\n\n// Parameters\n\ncolorDotsLatent = \"#84b0c5\";\ncolorDotsSelect = \"#B13D70\";\ncolorLand = \"#eeeeee\";\ncolorBorders = \"#c0d7df\";\ncolorBG = \"#c0d7df\";\n\ntooltip = d3.select(\"body\")\n  .append(\"div\")\n  .attr(\"class\", \"toolTip\")\n  .style(\"display\", \"none\")\n  .style(\"position\", \"absolute\")\n  .style(\"z-index\", 999)\n  .style(\"width\", 100)\n  .style(\"height\", 20)\n  .style(\"background\", \"#f7f7f7\")\n  .style(\"border\", \"1px solid #cecece\")\n  .style(\"opacity\", .9)\n  .style(\"padding\", \".2em .45em\")\n  .style(\"font-size\", \".85rem\");\n\n// Helper functions\n\nprojection = d3.geoMercator().scale([155]).center([-5, 40]);\nrandMotif = () =&gt; motifs[d3.randomInt(0, motifs.length-1)()].motif_id;\nmotifSelect = (motif) =&gt; motifs.filter(d =&gt; d.motif_id === motif);\n\ncoordsSelect = (motif) =&gt; {\n  const groups = groupsMotifs.filter(d =&gt; d.motif_id === motif);\n  const coordsSelect = coords.filter(d =&gt; groups.map(obj =&gt; obj.group).includes(d.group));\n  return coordsSelect;\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddMap = (selection) =&gt; {\n\n  selection.append(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", 0)\n    .attr(\"width\", selection.attr(\"width\"))\n    .attr(\"height\", selection.attr(\"height\"))\n    .style(\"fill\", colorBG);\n    \n  const pathGenerator = d3.geoPath(projection);\n  const map = selection.append(\"g\");\n  \n  map.selectAll(\"bg\")\n    .data(world)\n    .join(\"path\")\n    .attr(\"d\", pathGenerator)\n    .attr(\"fill\", colorLand);\n\n  map.selectAll(\"borders\")\n    .data(world)\n    .join(\"path\")\n    .attr(\"d\", pathGenerator)\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", colorBorders)\n    .style(\"stroke-width\", 1);\n    \n    return selection.node()\n}\n\ndotsSelect = (selection, motif) =&gt; {\n\n  const dots = selection.selectAll(\"circle\")\n    .data(coordsSelect(motif), d =&gt; d.group)\n    .join(\n      enter =&gt; enter\n        .append(\"circle\")\n          .attr(\"cx\", d =&gt; d.coordinates[0])\n          .attr(\"cy\", d =&gt; d.coordinates[1])\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr(\"r\", 5)\n          .style(\"stroke\", \"white\")\n          .style(\"fill\", colorDotsSelect)\n          .style(\"opacity\", 1)\n        .selection(),\n      update =&gt; update,\n      exit =&gt; exit\n        .transition().duration(300)\n          .style(\"opacity\", 0)\n          .remove()\n    );\n    \n  dots\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .attr(\"r\", 6)\n        .style(\"fill\", \"#f697bb\");\n      tooltip\n        .style(\"display\", \"inline\")\n        .style(\"left\", event.pageX + 15 + \"px\")\n        .style(\"top\", event.pageY + 15 + \"px\")\n        .text(d.group);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event) {\n      d3.select(\"#dots-highlighted\")\n        .selectAll(\"circle\")\n        .transition().duration(100)\n        .attr(\"r\", 5)\n        .style(\"fill\", colorDotsSelect);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n    \n  return selection.node()\n};\n\nmotifSelectId = (selection, motif) =&gt; {\n    \n  selection.selectAll(\"text\")\n    .data(motifSelect(motif), d =&gt; d.motif_id)\n    .join(\n      enter =&gt; enter\n        .append(\"text\")\n          .text(d =&gt; d.motif_id)\n          .attr(\"x\", -500)\n          .attr(\"y\", 553)\n          .style(\"fill\", \"black\")\n          .style(\"font-size\", \".7rem\")\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr(\"x\", 30)\n          .style(\"opacity\", 1)\n        .selection(),\n      update =&gt; update\n          .attr(\"x\", -500)\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr(\"x\", 30)\n          .style(\"opacity\", 1)\n        .selection(),\n      exit =&gt; exit\n        .transition().duration(500)\n          .attr(\"x\", 1500)\n          .remove()\n    );\n    \n  return selection.node();\n};\n\nmotifSelectTitle = (selection, motif) =&gt; {\n    \n  selection.selectAll(\"text\")\n    .data(motifSelect(motif), d =&gt; d.title)\n    .join(\n      enter =&gt; enter\n        .append(\"text\")\n          .text(d =&gt; d.title)\n          .attr(\"x\", -500)\n          .attr(\"y\", 580)\n          .style(\"fill\", \"black\")\n          .style(\"font-size\", \"1.5rem\")\n          .style(\"font-family\", \"Karla, Helvetica, Arial, sans-serif\")\n          .style(\"font-weight\", \"bold\")\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr(\"x\", 30)\n          .style(\"opacity\", 1)\n        .selection(),\n       update =&gt; update\n          .attr(\"x\", -500)\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr(\"x\", 30)\n          .style(\"opacity\", 1)\n        .selection(),\n      exit =&gt; exit\n        .transition().duration(500)\n          .attr(\"x\", 1500)\n          .remove()\n    );\n    \n  return selection.node();\n};\n\nmotifSelectDesc = (selection, motif) =&gt; {\n  \n  selection.selectAll(\"text\")\n    .data(motifSelect(motif), d =&gt; d.description)\n    .join(\n      enter =&gt; enter\n        .append(\"text\")\n          .attr('transform', \"translate(-500,605)\")\n          .attr(\"x\", 0)\n          .attr(\"y\", 0)\n          .text(d =&gt; d.description)\n          .call(wrapText)\n          .style(\"fill\", \"#2A769E\")\n          .style(\"font-size\", \".8rem\")\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr('transform', \"translate(30,605)\")\n          .style(\"opacity\", 1)\n        .selection(),\n       update =&gt; update\n          .attr('transform', \"translate(-500,605)\")\n          .style(\"opacity\", 0)\n        .transition().duration(500)\n          .attr(\"x\", 30)\n          .attr('transform', \"translate(30,605)\")\n          .style(\"opacity\", 1)\n        .selection(),\n      exit =&gt; exit\n        .transition().duration(500)\n          .attr('transform', \"translate(1500,605)\")\n          .remove()\n    );\n    \n  return selection.node();\n};\n\naddButton = (selection) =&gt; {\n  \n  const pos = ({ x: 30, y: 507 });\n  const dim = ({ width: 160, height: 25 });\n  const color = ({ base: \"#B13D70\", hover: \"#C85B89\", click: \"#991E56\" });\n  \n  selection.append(\"rect\")\n    .attr(\"x\", pos.x)\n    .attr(\"y\", pos.y)\n    .attr(\"width\", dim.width)\n    .attr(\"height\", dim.height)\n    .style(\"rx\", 3)\n    .style(\"fill\", color.base);\n\n  selection.append(\"text\")\n    .text(\"GET A RANDOM MOTIF\")\n    .attr(\"x\", pos.x + dim.width/2)\n    .attr(\"y\", pos.y + dim.height/2 + 1)\n    .attr(\"text-anchor\", \"middle\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"fill\", \"white\")\n    .style(\"font-size\", \".8rem\")\n    .style(\"font-weight\", \"bold\")\n    .style(\"font-family\", \"Karla, Arial, Helvetica, sans-serif\");\n\n  selection.on(\"mouseenter\", function(event) {\n    d3.select(event.target).style(\"cursor\", \"pointer\");\n    d3.select(this).selectAll(\"rect\")\n      .transition().duration(200)\n      .style(\"fill\", color.hover);\n  });\n\n  selection.on(\"mouseleave\", (event) =&gt; {\n    d3.select(\"#button\")\n      .selectAll(\"rect\")\n      .transition().duration(100)\n      .style(\"fill\", color.base);\n  });\n\n  selection.on(\"click\", () =&gt; {\n    const newMotif = randMotif();\n    d3.select(\"#dots-highlighted\").call(dotsSelect, newMotif);\n    d3.selectAll(\"#motif-id\").call(motifSelectId, newMotif);\n    d3.selectAll(\"#motif-title\").call(motifSelectTitle, newMotif);\n    d3.select(\"#motif-description\").call(motifSelectDesc, newMotif);\n    d3.select(\"#button\")\n      .selectAll(\"rect\").style(\"fill\", color.click)\n      .transition().style(\"fill\", color.hover);\n  });\n  \n  return selection.node();\n};\n\n\naddBubbles = (selection, selected) =&gt; {\n   \n  const shareMax = Math.max(...Object.values(groupsConcepts).map(item =&gt; item.share));\n  const dataSelect = groupsConcepts.filter(d =&gt; d.concept === `${selected}`);\n  const rScaler = d3.scaleLinear()\n    .domain([0, shareMax])\n    .range([0, 20]);\n  \n  const bubbles = selection.selectAll(\"circle\")\n    .data(dataSelect)\n    .join(\"circle\")\n      .attr(\"cx\", d =&gt; d.coordinates[0])\n      .attr(\"cy\", d =&gt; d.coordinates[1])\n    .transition().duration(500)\n      .attr(\"r\", d =&gt; rScaler(d.share))\n      .style(\"fill\", colorDotsSelect)\n      .style(\"fill-opacity\", .2)\n      .style(\"stroke\", colorDotsSelect)\n    .selection();\n  \n  bubbles\n    .on(\"mousemove\", function(event, d) {\n      console.log(\"Hey!\")\n      d3.select(this)\n        .transition().duration(50)\n        .attr(\"r\", d =&gt; rScaler(d.share) + 1)\n        .style(\"fill-opacity\", .4);\n      tooltip\n        .style(\"display\", \"inline\")\n        .style(\"left\", event.pageX + 15 + \"px\")\n        .style(\"top\", event.pageY + 15 + \"px\")\n        .text(d.group);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event) {\n      d3.select(\"#bubbles\")\n        .selectAll(\"circle\")\n        .transition().duration(100)\n        .attr(\"r\", d =&gt; rScaler(d.share))\n        .style(\"fill-opacity\", .2)\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n    \n  return selection.node();\n}\n\naddRadio = (selection, concept, checked = false) =&gt; {\n  \n  const conceptTitle = concept.charAt(0).toUpperCase() + concept.slice(1)\n  \n  const radio = selection.append(\"xhtml:div\")\n  radio.append(\"xhtml:input\")\n    .attr(\"type\", \"radio\")\n    .attr(\"name\", \"concepts\")\n    .attr(\"value\", concept)\n    .property(\"checked\", checked)\n    .style(\"margin-right\", \".5rem\")\n  radio.append(\"xhtml:label\")\n    .text(conceptTitle)\n  \n  return selection.node()\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddScatter = (selection, data, lm, titles) =&gt; {\n  \n  const id = d3.randomInt(100000, 1000000)();\n  \n  const margin = ({ top: 50, right: 40, bottom: 45, left: 50 });\n  const width = 790 - margin.left - margin.right;\n  const height = 500 - margin.top - margin.bottom;\n  const padding = 40;\n  \n  const xMin = Math.min(...data.map(d =&gt; d.x));\n  const xMax = Math.max(...data.map(d =&gt; d.x));\n  const yMin = Math.min(...data.map(d =&gt; d.y));\n  const yMax = Math.max(...data.map(d =&gt; d.y));\n  \n  const xScaler = d3.scaleLinear()\n    .domain([xMin, xMax])\n    .range([padding, width - padding]);\n    \n  const yScaler = d3.scaleLinear()\n    .domain([yMin, yMax])\n    .range([height - padding, padding]);\n    \n  selection.append(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", 0)\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .style(\"fill\", \"#f7f7f7\");\n    \n  const dots = selection.append(\"g\")\n    .attr(\"id\", `scatter-${id}`)\n    .selectAll(\"circle\")\n    .data(data)\n    .join(\"circle\")\n    .attr(\"cx\", d =&gt; xScaler(d.x))\n    .attr(\"cy\", d =&gt; yScaler(d.y))\n    .attr(\"r\", 7)\n    .style(\"opacity\", .5)\n    .style(\"fill\", \"#0C6291\");\n  \n  dots\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .attr(\"r\", 8)\n        .style(\"opacity\", .7)\n      tooltip\n        .style(\"display\", \"inline\")\n        .style(\"left\", event.pageX + 15 + \"px\")\n        .style(\"top\", event.pageY + 15 + \"px\")\n        .text(d.cntry);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event) {\n      d3.select(`#scatter-${id}`)\n        .selectAll(\"circle\")\n        .transition().duration(100)\n        .attr(\"r\", 7)\n        .style(\"opacity\", .5)\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n  \n  selection.append(\"g\")\n    .append(\"path\")\n    .attr(\"d\", d3.line()([\n      [padding, yScaler(lm.intercept)], \n      [width - padding, yScaler(lm.intercept) + width * yScaler(lm.slope) / xScaler(1)]\n    ]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", \"#B13D70\")\n    .style(\"stroke-width\", 2);\n  \n  selection.append(\"g\")\n    .append(\"path\")\n    .attr(\"d\", d3.line()([[width, height], [0, height], [0, 0]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", \"black\");\n  \n  selection.append(\"g\")\n    .append(\"text\")\n    .attr(\"x\", width / 2)\n    .attr(\"y\", height + 20)\n    .attr(\"text-anchor\", \"middle\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .text(titles.xAxis)\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \"1rem\")\n    \n  selection.append(\"g\")\n    .append(\"text\")\n    .attr(\"transform\", \"rotate(-90)\")\n    .attr(\"x\", -height / 2)\n    .attr(\"y\", -20)\n    .attr(\"text-anchor\", \"middle\")\n    .attr(\"alignment-baseline\", \"baseline\")\n    .text(titles.yAxis)\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", \"1rem\")\n  \n  return selection.node()\n}\n\naddLegend = (selection, position) =&gt; {\n  \n  selection.append(\"path\")\n    .attr(\"d\", d3.line()([[position.x, position.y], [position.x + 30, position.y]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", \"#B13D70\")\n    .style(\"stroke-width\", 2);\n  \n  selection.append(\"text\")\n    .attr(\"x\", position.x + 40)\n    .attr(\"y\", position.y)\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .text(\"Estimated relationship from a multivariate linear model\")\n    .style(\"font-size\", \"1rem\")\n    .style(\"fill\", \"black\")\n  \n  return selection.node()\n}\n\naddStats = (selection, lm, positionStats) =&gt; {\n  \n  const stats = selection.append(\"g\")\n    .attr(\"transform\", `translate(${positionStats.x},${positionStats.y})`)\n    .attr(\"x\", 0)\n    .attr(\"y\", 0)\n    .style(\"font-size\", \".8rem\")\n    .style(\"fill\", \"black\")\n    .style(\"fill-opacity\", .5);\n  \n  stats.append(\"text\")\n    .text(`n = ${lm.n}`)\n  \n  stats.append(\"text\")\n    .attr(\"dy\", 18)\n    .text(`R² = ${lm.r2}`)\n  \n  return selection.node()\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nwrapText = (textElement) =&gt; {\n  \n  // Word parameters\n  let words = textElement.text().split(\" \").reverse(),\n      word,\n      line = [],\n      lineNumber = 0;\n  \n  // Styling parameters\n  const lineHeight = 1.2;\n  const maxWidth = 650;\n  const x = textElement.attr(\"x\"),\n        y = textElement.attr(\"y\");\n  \n  // Clear textElement text\n  textElement.text(null);\n  \n  // Append first tspan element (to fill as we build the lines)\n  let tspan = textElement.append(\"tspan\")\n    .attr(\"x\", x)\n    .attr(\"y\", y)\n    .attr(\"dy\", 0);\n  \n  // Loop through all words and make new lines when we exceed our maxWidth\n  while (word = words.pop()) {\n    \n    line.push(word);\n    tspan.text(line.join(\" \"));\n    \n    if (measureWidth(tspan.text()) &gt; maxWidth && lineNumber &lt; 2) {\n      line.pop();\n      tspan.text(line.join(\" \"));\n      line = [word];\n      tspan = textElement.append(\"tspan\")\n        .attr(\"x\", x)\n        .attr(\"y\", y)\n        .attr(\"dy\", `${++lineNumber * lineHeight}em`)\n        .text(word);\n    }\n    \n    if (measureWidth(tspan.text()) &gt; maxWidth - 10 && lineNumber === 2) {\n      line.pop();\n      line.push(\"[...]\");\n      tspan.text(line.join(\" \"));\n      break;\n    }\n  }\n};\n\nmeasureWidth = {\n  const context = document.createElement(\"canvas\").getContext(\"2d\");\n  return text =&gt; context.measureText(text).width;\n};"
  },
  {
    "objectID": "posts/2023-04-22-the-tales-we-tell/index.html#footnotes",
    "href": "posts/2023-04-22-the-tales-we-tell/index.html#footnotes",
    "title": "The tales we tell",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSkip the misguided Disney version — the 1989 taping with the original Broadway cast is available on YouTube.↩︎\nThe replication files of Michalopoulos and Xue (MX) don’t contain location information for the linguistic groups, so I dug around and found it in a repo from one Dmitry Nikolayev. Nikolayev appears to have worked on an older version of the Berezkin catalog, so his list does not exactly match MX’s list. I’ve harmonized them as best as I could; see my cleaning script for details.↩︎\nThere are also some typos and grammatically errors. I have left these as they are.↩︎"
  },
  {
    "objectID": "posts/2023-04-30-population/index.html",
    "href": "posts/2023-04-30-population/index.html",
    "title": "Babies and boomers",
    "section": "",
    "text": "In a Manila hospital in 1991, I was born to a world of 5.4 billion people. Thirty-one years later, in another Manila hospital down the road from mine, the symbolic 8 billionth baby was born, a girl named Vinice. When hospital staff brought the family cake to mark the occasion, her father, sleep-deprived, thought they were being sold an 8-billion-peso cake.\nThe United Nations expects the world to welcome its 9 billionth baby in 2037 and its 10 billionth in 2058. But it is not expected to welcome an 11 billionth. According to the UN’s latest baseline projections, world population will peak at 10.43 billion in 2085. This will be the high watermark of humanity on planet Earth. Henceforth, fertility rates are expected to drop to such an extent that births will roughly equal deaths, keeping overall population steady. The era of explosive human multiplication — ordered by God in Genesis but only really got going in the Industrial Revolution — will come to an end.\nThis demographic transition carries huge implications for the makeup of Earth’s citizens. As people live longer and have fewer babies, the world will become a lot grayer. See it for yourself by scrolling forward and backward in time in the population pyramid below. Tellingly, the chart in the decades ahead will look less like a pyramid and more like an urn.\nThis aging is already occurring in many places in the rich world; see in particular Japan, South Korea, Germany, and Italy. It is also occurring in the not-so-rich world, most notably China, whose billion-strong population shrank last year for the first time since the Mao-induced famines of the 1960s. This is the result of what might possibly be the most far-reaching, most consequential policy misadventure of our time: the one-child policy. Imposed needlessly and kept for far too long, it amplified the rising costs of child-rearing to engineer a spectacular collapse in fertility rates. The economic repercussions of a shrinking workforce having to support a growing pool of retirees will be dire. Selecting China above and fast-forwarding a few decades reveals a chart that is neither a pyramid nor an urn, but a mushroom.\nTo add salt to the wound, it was reported last week that geopolitical rival India has surpassed it to become the world’s largest, a distinction China had held ever since the UN began keeping records in 1950. Comparing the population pyramids of the two makes it clear that the gap is only set to widen further: the median Indian is 10 years younger than the median Chinese.\nTo be clear, China’s economy remains far larger, its citizens far richer. Still, this eclipsing by a fellow titan throws a seed of doubt in the narrative of a relentless and unparalleled rise. The Chinese Communist Party is sensitive, as it is wont to be. “India won’t overtake China in economy even if it becomes world’s most populous nation” is the testy headline from state tabloid Global Times.\nNevertheless, both India and China may ultimately end up as side-plots to the foremost demographic story of the coming decades, which is Africa. While Asia stands as the largest continent, its fertility rates have dropped tremendously and its people are aging rapidly. In 2022, there were 1.9 live births for every woman in Asia, well below the 2.1 needed to keep population stable. In Africa meanwhile, the number is 4.2. Nigeria, the largest country in Africa, is even more fertile at 5.1 births per woman. These trends may result in a doubling of Africa’s population to 400 million by 2050. In fact, of the 2.4 billion people the planet will add from now until world population peaks in the 2080s, a good 91% will be contributed by Africa.\nYet high as they are, Africa’s fertility rates are falling too, possibly even at a faster pace than current projections indicate. The causes are complex, but a role is no doubt played by widening opportunities for women in school and in the workforce. This lends hope for the economic development of the world’s poorest continent. The median African is just under 19 years old, meaning the vast majority of Africa’s population will be in the most productive years of their lives for decades to come.\nBy the year 2100, Earth’s population would have undergone its 15th year of negative annual growth. The median Earthling will be 42 years old, compared with 30 today. China will have a mere 760 million people, half that of India’s 1.5 billion. More than one-third of all people will be African; just 5% will be European. In hospitals across Manila, babies will be born to a world that neither I nor Vinice can scarcely imagine — a world that is getting smaller."
  },
  {
    "objectID": "posts/2023-04-30-population/index.html#data-and-cleaning-scripts",
    "href": "posts/2023-04-30-population/index.html#data-and-cleaning-scripts",
    "title": "Babies and boomers",
    "section": "Data and cleaning scripts",
    "text": "Data and cleaning scripts\n\n\nUN World Population Prospects 2022 csv files\nclean.ipynb / pyramid.csv, median_age.csv, fertility_regions.csv, fertility_countries.csv, countries.csv, age_groups.csv"
  },
  {
    "objectID": "posts/2023-04-30-population/index.html#d3-observable-code",
    "href": "posts/2023-04-30-population/index.html#d3-observable-code",
    "title": "Babies and boomers",
    "section": "D3 / Observable code",
    "text": "D3 / Observable code\n\n\n\nCode\npyramid = FileAttachment(\"../../datasets/population/pyramid.csv\").csv({ typed: true });\nmedianAge = FileAttachment(\"../../datasets/population/median_age.csv\").csv({ typed: true });\nfertilityRegions = FileAttachment(\"../../datasets/population/fertility_regions.csv\").csv({ typed: true });\nfertilityCountries = FileAttachment(\"../../datasets/population/fertility_countries.csv\").csv({ typed: true });\ncountries = FileAttachment(\"../../datasets/population/countries.csv\").csv({ typed: true });\nageGroups = FileAttachment(\"../../datasets/population/age_groups.csv\").csv({ typed: true });\n\n// Parameters\n\nrectHeight = 20;\nmargin = ({ top: 10, bottom: 10, between: 80 });\npadding = ({ top: 10, bottom: 10, between: 5, inner: 40 });\ndim = ({ \n  width: 790 - margin.between, \n  height: padding.top + 21 * (rectHeight + padding.between)  - padding.between + padding.bottom });\n\ndimLine = ({ width: 790, height: 550 });\nmarginLine = ({ top: 10, right: 20, bottom: 35, left: 35, inner: 20 });\n\ncolors = ({ \n  men: \"#84b0c5\", menSurplus: \"#2A769E\", \n  women: \"#DF79A2\", womenSurplus: \"#991E56\",\n  totalLeft: \"#4889ab\", totalRight: \"#C85B89\",\n  medianLine: \"black\", dependents: \"#F6F0EC\"\n})  \n\ntooltip = d3.select(\"body\")\n  .append(\"div\")\n  .attr(\"class\", \"toolTip\")\n  .style(\"display\", \"none\")\n  .style(\"position\", \"absolute\")\n  .style(\"z-index\", 999)\n  .style(\"width\", 100)\n  .style(\"height\", \"auto\")\n  .style(\"background\", \"#f7f7f7\")\n  .style(\"border\", \"1px solid #cecece\")\n  .style(\"opacity\", .9)\n  .style(\"padding\", \".2em .45em\")\n  .style(\"font-size\", \".85rem\");\n\n// Helper functions\n\nround5 = n =&gt; Math.floor(n / 5) * 5;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddBarsShareLeft = (selection, data, scaler) =&gt; {\n  \n  selection.append(\"g\")\n    .selectAll(\"rect\")\n    .data(data)\n    .join(\"rect\")\n    .attr(\"x\", d =&gt; (dim.width / 2) - scaler(d.PopShareMale + d.PopShareFemale))\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight + i * (rectHeight + padding.between)))\n    .attr(\"width\", d =&gt; scaler(d.PopShareMale + d.PopShareFemale))\n    .attr(\"height\", rectHeight)\n    .style(\"fill\", colors.totalLeft)\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .style(\"opacity\", .7);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .html(`${ d3.format(\",.0f\")(1000 * (d.PopMale + d.PopFemale)) } people&lt;br&gt;${ d3.format(\",.1f\")(d.PopShareMale + d.PopShareFemale) }%`);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event, d) {\n      d3.select(this)\n        .transition().duration(100)\n        .style(\"opacity\", 1);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n  \n  return selection.node();\n};\n\naddBarsShareRight = (selection, data, scaler) =&gt; {\n\n  selection.append(\"g\")\n    .selectAll(\"rect\")\n    .data(data)\n    .join(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight + i * (rectHeight + padding.between)))\n    .attr(\"width\", d =&gt; scaler(d.PopShareMale + d.PopShareFemale))\n    .attr(\"height\", rectHeight)\n    .style(\"fill\", colors.totalRight)\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .style(\"opacity\", .7);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .html(`${ d3.format(\",.0f\")(1000 * (d.PopMale + d.PopFemale)) } people&lt;br&gt;${ d3.format(\",.1f\")(d.PopShareMale + d.PopShareFemale) }%`);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event, d) {\n      d3.select(this)\n        .transition().duration(100)\n        .style(\"opacity\", 1);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n  \n  return selection.node();\n};\n\naddMedianLineLeft = (selection, dataMedian, dataPop, scaler) =&gt; {\n  \n  const paddingInner = padding.inner - 10;\n  const i = round5(dataMedian[0].MedianAgePop) / 5;\n  const y = dim.height - (padding.bottom + rectHeight/2 + i * (rectHeight + padding.between));\n  const stop = (dim.width / 2) - scaler(dataPop[i].PopShareMale + dataPop[i].PopShareFemale) - 5;\n  \n  const line = selection.append(\"g\");\n  \n  line.append(\"path\")\n    .attr(\"d\", d3.line()([[paddingInner, y], [stop, y]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", colors.medianLine)\n    .style(\"stroke-dasharray\", \"4 4\")\n    .style(\"stroke-width\", 2);\n  \n  line.append(\"text\")\n    .attr(\"x\", paddingInner)\n    .attr(\"y\", y)\n    .attr(\"dx\", \"-.4rem\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"font-weight\", \"bold\")\n    .style(\"fill\", colors.medianLine)\n    .text(d3.format(\".0f\")(dataMedian[0].MedianAgePop));\n  \n  return selection.node();\n};\n\naddMedianLineRight = (selection, dataMedian, dataPop, scaler) =&gt; {\n  \n  const paddingInner = padding.inner - 10;\n  const i = round5(dataMedian[0].MedianAgePop) / 5;\n  const y = dim.height - (padding.bottom + rectHeight/2 + i * (rectHeight + padding.between));\n  const start = scaler(dataPop[i].PopShareMale + dataPop[i].PopShareFemale) + 5;\n  \n  const line = selection.append(\"g\");\n  \n  line.append(\"path\")\n    .attr(\"d\", d3.line()([[start, y], [dim.width / 2 - paddingInner, y]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", colors.medianLine)\n    .style(\"stroke-dasharray\", \"4 4\")\n    .style(\"stroke-width\", 2);\n  \n  line.append(\"text\")\n    .attr(\"x\", dim.width / 2 - paddingInner)\n    .attr(\"y\", y)\n    .attr(\"dx\", \".4rem\")\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"font-size\", \".9rem\")\n    .style(\"font-weight\", \"bold\")\n    .style(\"fill\", colors.medianLine)\n    .text(d3.format(\".0f\")(dataMedian[0].MedianAgePop));\n  \n  return selection.node();\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddBarsShareMale = (selection, data, scaler) =&gt; {\n\n  selection.append(\"g\")\n    .selectAll(\"rect\")\n    .data(data)\n    .join(\"rect\")\n    .attr(\"x\", d =&gt; (dim.width / 2) - scaler(d.PopShareMale))\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight + i * (rectHeight + padding.between)))\n    .attr(\"width\", d =&gt; scaler(d.PopShareMale))\n    .attr(\"height\", rectHeight)\n    .style(\"fill\", colors.men)\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .style(\"opacity\", .7);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(`${d3.format(\",.0f\")(1000 * d.PopMale)} men`);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event, d) {\n      d3.select(this)\n        .transition().duration(100)\n        .style(\"opacity\", 1);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    })\n  \n  return selection.node();\n};\n\naddBarsSurplusMale = (selection, data, scaler) =&gt; {\n\n  selection.append(\"g\")\n    .selectAll(\"rect\")\n    .data(data)\n    .join(\"rect\")\n    .attr(\"x\", d =&gt; (dim.width / 2) - scaler(d.PopShareMale))\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight + i * (rectHeight + padding.between)))\n    .attr(\"width\", d =&gt; scaler(d.SurplusShareMale))\n    .attr(\"height\", rectHeight)\n    .style(\"fill\", colors.menSurplus)\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .style(\"opacity\", .7);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(`${d3.format(\",.0f\")(1000 * d.SurplusMale)} surplus men`);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event, d) {\n      d3.select(this)\n        .transition().duration(100)\n        .style(\"opacity\", 1);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    })\n  \n  return selection.node();\n};\n\naddLabelsMale = (selection, data, scaler) =&gt; {\n\n  selection.append(\"g\")\n    .selectAll(\"text\")\n    .data(data)\n    .join(\"text\")\n    .attr(\"x\", d =&gt; (dim.width / 2) - scaler(d.PopShareMale))\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight/2 + i * (rectHeight + padding.between)))\n    .attr(\"dx\", \"-.25rem\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"font-size\", \".7rem\")\n    .style(\"fill\", \"black\")\n    .text(d =&gt; d3.format(\".1f\")(d.PopShareMale))\n\n  return selection.node();\n};\n\naddBarsShareFemale = (selection, data, scaler) =&gt; {\n\n  selection.append(\"g\")\n    .selectAll(\"rect\")\n    .data(data)\n    .join(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight + i * (rectHeight + padding.between)))\n    .attr(\"width\", d =&gt; scaler(d.PopShareFemale))\n    .attr(\"height\", rectHeight)\n    .style(\"fill\", colors.women)\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .style(\"opacity\", .7);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(`${d3.format(\",.0f\")(1000 * d.PopFemale)} women`);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event, d) {\n      d3.select(this)\n        .transition().duration(100)\n        .style(\"opacity\", 1);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n  \n  return selection.node();\n};\n\naddBarsSurplusFemale = (selection, data, scaler) =&gt; {\n  \n  selection.append(\"g\")\n    .selectAll(\"rect\")\n    .data(data)\n    .join(\"rect\")\n    .attr(\"x\", d =&gt; scaler(d.PopShareFemale - d.SurplusShareFemale))\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight + i * (rectHeight + padding.between)))\n    .attr(\"width\", d =&gt; scaler(d.SurplusShareFemale))\n    .attr(\"height\", rectHeight)\n    .style(\"fill\", colors.womenSurplus)\n    .on(\"mousemove\", function(event, d) {\n      d3.select(this)\n        .transition().duration(50)\n        .style(\"opacity\", .7);\n      tooltip\n        .style(\"left\", event.pageX + 18 + \"px\")\n        .style(\"top\", event.pageY + 18 + \"px\")\n        .style(\"display\", \"block\")\n        .text(`${d3.format(\",.0f\")(1000 * d.SurplusFemale)} surplus women`);\n      d3.select(event.target).style(\"cursor\", \"pointer\");\n    })\n    .on(\"mouseleave\", function(event, d) {\n      d3.select(this)\n        .transition().duration(100)\n        .style(\"opacity\", 1);\n      tooltip.style(\"display\", \"none\");\n      d3.select(event.target).style(\"cursor\", \"default\");\n    });\n  \n  return selection.node();\n};\n\naddLabelsFemale = (selection, data, scaler) =&gt; {\n\n  selection.append(\"g\")\n    .selectAll(\"text\")\n    .data(data)\n    .join(\"text\")\n    .attr(\"x\", d =&gt; scaler(d.PopShareFemale))\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight/2 + i * (rectHeight + padding.between)))\n    .attr(\"dx\", \".25rem\")\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"font-size\", \".7rem\")\n    .style(\"fill\", \"black\")\n    .text(d =&gt; d3.format(\".1f\")(d.PopShareFemale));\n  \n  return selection.node();\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddDependents = (selection) =&gt; {\n  \n  const area = selection.append(\"g\")\n    .attr(\"transform\", `translate(0, ${ margin.top })`)\n  \n  area.append(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", dim.height - (padding.bottom - padding.between/2) - 3 * (rectHeight + padding.between))\n    .attr(\"width\", dim.width + margin.between)\n    .attr(\"height\", 3 * (rectHeight + padding.between) + padding.between/2)\n    .style(\"fill\", colors.dependents);\n    \n  area.append(\"rect\")\n    .attr(\"x\", 0)\n    .attr(\"y\", padding.top - padding.between)\n    .attr(\"width\", dim.width + margin.between)\n    .attr(\"height\", 8 * (rectHeight + padding.between) + padding.between/2)\n    .style(\"fill\", colors.dependents);\n  \n  area.append(\"text\")\n    .attr(\"x\", 0)\n    .attr(\"y\", padding.top - padding.between)\n    .attr(\"dx\", 10)\n    .attr(\"dy\", 10)\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .style(\"font-size\", \".8rem\")\n    .style(\"fill\", \"#CB946B\")\n    .text(\"Economic dependents\");\n    \n  return selection.node()\n};\n\naddAgeGroups = (selection) =&gt; {\n  \n  selection.append(\"g\")\n    .attr(\"transform\", `translate(${ (dim.width + margin.between) / 2 }, ${ margin.top })`)\n    .selectAll(\"text\")\n    .data(ageGroups)\n    .join(\"text\")\n    .text(d =&gt; d.AgeGrp)\n    .attr(\"x\", 0)\n    .attr(\"y\", (d, i) =&gt; dim.height - (padding.bottom + rectHeight/2 + i * (rectHeight + padding.between)))\n    .attr(\"text-anchor\", \"middle\")\n    .attr(\"alignment-baseline\", \"middle\")\n    .style(\"font-size\", \".8rem\")\n    .style(\"opacity\", .35)\n    .style(\"fill\", \"black\");\n    \n  return selection.node();\n};\n\nmeasureWidth = {\n  const context = document.createElement(\"canvas\").getContext(\"2d\");\n  return text =&gt; context.measureText(text).width;\n};\n\naddLegendPyramid = (selection) =&gt; {\n  \n  const addItem = (selection, color, label) =&gt; {\n    \n    const dim = ({ width: 40 + 1.5 * measureWidth(label), height: 15 });\n    \n    const containerItem = selection.append(\"div\")\n      .append(\"svg\")\n      .attr(\"width\", `${dim.width}`)\n      .attr(\"height\", `${dim.height}`)\n      .attr(\"viewBox\", [0, 0, `${dim.width}`, `${dim.height}`])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n  \n    containerItem.append(\"rect\")\n      .attr(\"x\", 0)\n      .attr(\"y\", 0)\n      .attr(\"width\", `${dim.height}`)\n      .attr(\"height\", `${dim.height}`)\n      .style(\"fill\", color);\n\n    containerItem.append(\"text\")\n      .attr(\"x\", `${ dim.height + 5 }`)\n      .attr(\"y\", 0)\n      .attr(\"dy\", 1)\n      .attr(\"text-anchor\", \"start\")\n      .attr(\"alignment-baseline\", \"hanging\")\n      .style(\"fill\", \"black\")\n      .style(\"font-size\", `${dim.height}`)\n      .text(label);\n  \n    return selection.node();\n  }\n  \n  const container = selection.append(\"div\")\n    .attr(\"style\", \"margin-bottom: 1rem; display: flex; justify-content: center\");\n  \n  container\n    .call(addItem, colors.men, \"Men\")\n    .call(addItem, colors.menSurplus, \"Surplus men\")\n    .call(addItem, colors.women, \"Women\")\n    .call(addItem, colors.womenSurplus, \"Surplus women\");\n  \n  return selection.node();\n};\n\naddLegendMedian = (selection) =&gt; {\n  \n  const label = \"Median age\";\n  const dim = ({ width: 40 + 1.5 * measureWidth(label), height: 15 });\n  \n  const container = selection.append(\"div\")\n    .attr(\"style\", \"margin-bottom: 1rem; display: flex; justify-content: center\");\n  \n  const containerItem = container.append(\"div\")\n    .append(\"svg\")\n    .attr(\"width\", `${dim.width}`)\n    .attr(\"height\", `${dim.height}`)\n    .attr(\"viewBox\", [0, 0, `${dim.width}`, `${dim.height}`])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n  \n  containerItem.append(\"path\")\n    .attr(\"d\", d3.line()([[0, dim.height / 2], [dim.height * 2, dim.height / 2]]))\n    .style(\"fill\", \"none\")\n    .style(\"stroke\", colors.medianLine)\n    .style(\"stroke-dasharray\", \"4 4\")\n    .style(\"stroke-width\", 2);\n    \n  containerItem.append(\"text\")\n    .attr(\"x\", `${ dim.height * 2 + 5 }`)\n    .attr(\"y\", 0)\n    .attr(\"dy\", 1)\n    .attr(\"text-anchor\", \"start\")\n    .attr(\"alignment-baseline\", \"hanging\")\n    .style(\"fill\", \"black\")\n    .style(\"font-size\", `${dim.height}`)\n    .text(label);\n  \n  return selection.node();\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\naddLines = (selection, data, color, xScale, yScale) =&gt; {\n  \n  const id = d3.randomInt(100000, 1000000)();\n  \n  // Compute values\n  const ind = d3.map(data, d =&gt; d.LocID);\n  const X = d3.map(data, d =&gt; d.Time);\n  const Y = d3.map(data, d =&gt; d.TFR);\n  const Z = d3.map(data, d =&gt; d.Location);\n  const I = d3.range(X.length);\n  \n  // Construct a line generator\n  const line = d3.line()\n    .curve(d3.curveBasis)\n    .x(i =&gt; xScale(X[i]))\n    .y(i =&gt; yScale(Y[i]));\n  \n  const mapData = d3.group(I, i =&gt; ind[i]);\n    \n  const path = selection.append(\"g\")\n    .selectAll(\"path\")\n    .data(mapData)\n    .join(\"path\")\n      .style(\"fill\", \"none\")\n      .style(\"stroke\", color)\n      .style(\"stroke-width\", 3)\n      .style(\"mix-blend-mode\", \"multiply\")\n      .attr(\"d\", ([, I]) =&gt; line(I))\n      .attr(\"id\", (d, i) =&gt; `path-${ [...mapData.keys()][i] }`)\n      .attr(\"class\", `paths-${id}`);\n    \n  const pathGhost = selection.append(\"g\")\n    .selectAll(\"path\")\n    .data(mapData)\n    .join(\"path\")\n      .style(\"fill\", \"none\")\n      .style(\"stroke\", color)\n      .style(\"stroke-width\", 15)\n      .style(\"opacity\", 0)\n      .attr(\"d\", ([, I]) =&gt; line(I));\n  \n  pathGhost\n    .on(\"mousemove\", mousemove)\n    .on(\"mouseleave\", mouseleave);\n  \n  function mousemove(event) {\n    \n    const [xm, ym] = d3.pointer(event);\n    const i = d3.least(I, i =&gt; Math.hypot(xScale(X[i]) - xm, yScale(Y[i]) - ym)); // closest point\n    \n    d3.selectAll(`.paths-${id}`)\n      .transition().duration(100)\n      .style(\"stroke\", color)\n      .style(\"stroke-width\", 3);\n      \n    d3.select(`#path-${ ind[i] }`)\n      .transition().duration(50)\n      .style(\"stroke\", \"#307351\")\n      .style(\"stroke-width\", 5);\n      \n    tooltip\n      .style(\"left\", event.pageX + 18 + \"px\")\n      .style(\"top\", event.pageY + 18 + \"px\")\n      .style(\"display\", \"block\")\n      .html(`&lt;b&gt;${ Z[i] }&lt;/b&gt;&lt;br&gt;${ X[i] }: ${ d3.format(\".2f\")(Y[i]) }`);\n    \n    d3.select(event.target).style(\"cursor\", \"pointer\");\n  };\n\n  function mouseleave(event) {\n    d3.selectAll(`.paths-${id}`)\n      .transition().duration(100)\n      .style(\"stroke\", color)\n      .style(\"stroke-width\", 3);\n    tooltip.style(\"display\", \"none\");\n    d3.select(event.target).style(\"cursor\", \"default\");\n  };\n  \n  return selection.node();\n}"
  },
  {
    "objectID": "subscribe.html",
    "href": "subscribe.html",
    "title": "Subscribe",
    "section": "",
    "text": "Subscribe\n\n\nYou will receive an email whenever there is a new post. Unsubscribe anytime.\n\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n          \n        \n        \n                          Oops! Something's wrong.\n                      \n      \n    \n    \n    \n      \n        \n          \n        \n        \n                          Confirmation link sent!\n                      \n      \n    \n    \n    \n      \n        \n          \n            \n              \n\n                \n                  \n                \n              \n\n              \n              \n            \n          \n        \n        \n          \n            \n              \n\n                \n                  \n                \n              \n\n              \n              \n            \n          \n        \n        \n          \n            \n              \n\n                \n                  \n                \n              \n\n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n                \n              \n              \n              \n            \n          \n        \n        \n          \n            \n              \n                \n              \n              SIGN ME UP!\n            \n          \n        \n        \n          \n            \n          \n        \n        \n          \n            \n              \n                \n                  \n                    \n                  \n                \n              \n              \n                \n              \n            \n            \n              We use Sendinblue as our marketing platform. By submitting this form, you acknowledge that the information you provided will be transferred to Sendinblue for processing in accordance with their terms of use"
  },
  {
    "objectID": "subscribed.html",
    "href": "subscribed.html",
    "title": "Subscription confirmed",
    "section": "",
    "text": "Subscription confirmed\n\n\nYou’re all set!"
  }
]